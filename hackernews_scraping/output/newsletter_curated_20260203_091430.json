{
  "schema_version": "3.1",
  "curated_at": "2026-02-03T09:14:30.969961",
  "source": "hackernews",
  "curation_config": {
    "min_relevance": 0.2,
    "pool_size": 25,
    "publish_count": 8
  },
  "stats": {
    "input_items": 142,
    "pool_items": 25,
    "published_items": 8,
    "filtered_noise": 31,
    "filtered_low_relevance": 45,
    "filtered_flamewar": 1,
    "filtered_low_quality": 0,
    "themes": {
      "üíª Developer Tools": 5,
      "ü§ñ AI & LLMs": 2,
      "‚öñÔ∏è AI Ethics & Policy": 1
    }
  },
  "themes": {
    "üíª Developer Tools": [
      {
        "id": "42b5f4ecae2032cd5e411c80cdc103b9",
        "source": "hackernews",
        "source_id": "46849258",
        "title": "My iPhone 16 Pro Max produces garbage output when running MLX LLMs",
        "content": "TL;DR:\n\nMy iPhone 16 Pro Max produces garbage output when running MLX LLMs. An iPhone 15 Pro runs the same code perfectly. A MacBook Pro also runs the same code perfectly. The tensor outputs on the 16 show numerical values an order of magnitude wrong. I suspect it points to a hardware defect in the Neural Engine or some other ML-needed system.\n\nIt was a PITA to debug, but at least I got a blog post out of it.\n\nHow did I get there?\n\nThis was supposed to be a simple, unwinding-time project.\n\nFor the past few months I've been working on aClawdbotMoltbot clone that I've been calling Schmidt. It basically does the same kind of thing but with a custom chat UI instead of using Telegram, WhatsApp or other \"I-can't-afford-to-be-banned-from\" Service. This project has been consuming early days and late nights, so, to unwind, I decided that it may be a good idea to do something simpler. Since I recently subscribed to MiniMax M2.1, I thought I would do what many do and build a simple expense tracking app to test out the model.\n\nThe core functionality is simple:\n\nAutomatically, upon each payment, add the expense to my app\n\nUpdate an Apple Watch complication with the % of my monthly budget spent\n\nCategorize the purchase for later analysis\n\nThis all comes from being basically orphaned by Nubank's amazing native app (since replaced by a less-full-featured Flutter version).\n\nIntegrating with Shortcuts is manual, but reliable. Within 15 minutes I had a version of the app that could register purchases. The Apple Watch complication, the main goal, can come later. I'd rather get the classification feature, which should be easy, done quickly ‚Äì so I figured.\n\nApple Intelligence\n\nGiven the new LLM-bonanza we've been living through, it's no surprise that Apple has their own set of APIs developers such as me can use. Reading up on the documentation, it's a matter of checking for the availability of the feature and then asking the model to either reply to a textual query or, in my case, categorize a request.\n\nMiniMax raced through it in a single prompt and then I ran it on my iPhone. First expense was a purchase at a shop called \"Kasai Kitchin\", classified as...unknown.Weird.\n\nChecking the logs, it was clear: the model support was downloading. The feature hadn't been enabled. Again, weird. I should have it on. Anyway, I go into settings, do the weird dance of toggling it on and off ‚Äì sadly, that's not surprising on Apple's services. Maybe my Settings.app got stuck in a weird state, who knows? ‚Äì and wait for it to download.\n\nAfter 4h I realized it was not going anywhere. Looking it up, it seems that many have the same issue (thisthread shows 12 pages of frustrated users). Again, not a surprise for Apple's services recently.\n\nOh well, time to give up on the Apple Intelligence approach. Let's move on to the next one.\n\nMLX LLM\n\nWell, the iOS framework engineers don't seem to be the only engineers at Apple capable of coming up with Machine Learning APIs in Swift. Apparently, there's a whole separate way of doing it ‚Äì with models downloaded to your app. Not great for the user's storage, but great for me!\n\nAgain, MiniMax does it in a heartbeat, specially after being given documentation and one or two Medium posts. Time to run on my iPhone and... gibberish.\n\nThe CPU spins to 100% and the model starts generating. But it's all gibberish. And no \"stop\" token is generated, so this goes on for long.\n\nAt this point, the only explanation is: I'm completely incompetent and can't even get a simple \"ready made\" framework to execute what I want. Or, rather,MiniMax is! The good thing about offloading your work to an LLM is that you can blame it for your shortcomings. Time to get my hands dirty and do it myself, typing code on my keyboard, like the ancient Mayan and Aztec programmers probably did.\n\nMy own MLX implementation\n\nI went back to the documentation, to the Medium posts and, much to my surprise: MiniMax had followed it to the letter. Even went back to some deprecated methods of generation and it also was gibberish. And now there's no one to blame, but myself. I go to work everyday and this impostor-syndrome inducing problem silently consumes me.After 3 days of trying to get it to work, I'm ready to give up......until, on a Tuesday morning, at 7-8 AM, I have an idea: let me, just in case, run this on my old iPhone 15 Pro. Up to this point, I was running it on my daily driver, an iPhone 16 Pro Max that was a replacement phone sent by Apple Care after a small clubbing mishap (in which my iPhone was irreparably crashed). I rush to get everything ready before it's time to go to work and: it works! Gemma, Qwen, and all other models generate coherent responses!\n\nI stop and think: this cannot be a hardware issue,right? Of course not. The iPhone 15 is still running iOS 18. The iPhone 16 is running 26. Itmust be an OS issue. Well, time to be late for my work standup and update the old phone. The curiosity is too much. Many minutes later... same results, now on iOS 26. The plot is thickening.\n\nFinding the smoking gun: breakpoints in MLX's implementations of Gemma\n\nAfter that work day, and after many lunch and coffee discussions with coworkers about the sources of my troubles, I get home and immediately set myself on debugging MLX as it runs, if possible. The game plan is:\n\nUse a known-to-be-reliable model, that fits in RAM (I went with quantized Gemma)\n\nUse a simple prompt, in my case \"What is 2+2?\"To bereallypedantic: the prompt was<start_of_turn>user\\nWhat is 2+2?<end_of_turn>\\n<start_of_turn>model\n\nTo bereallypedantic: the prompt was<start_of_turn>user\\nWhat is 2+2?<end_of_turn>\\n<start_of_turn>model\n\nRun everything with temperature set to0.0‚Äì maybe that's enough to remove variability\n\nFind the model implementation\n\nFind where the model iterates through the layers and\n\nPrint out the MLXArray/Tensor with the values on each layer as the input goes through\n\nA few moments later and I find where I need to be. Added the breakpoints, added the logs and off to the races.\n\nI run it on my iPhone 16 Pro Max. The model loads and the prompt is \"What is 2+2?\". The tensors start printing out, line after line after line. For once, the logs aren'tcompletegibberish ‚Äì they're numbers. Floating point values representing the model's internal state as it processes the input. I save the output to a file and do the same on my iPhone 15 Pro. Same model, same prompt, same code. Time to compare.\n\nWelp, now it's definitely out of my expertise\n\nI grep for a pattern I know should be consistent ‚Äì an array at log-line 58, right before the values get normalized/softmaxed. On a working device, I hypothesize this should be the same every time.On the iPhone 15 Pro:3: \"[[[[53.875, 62.5625, -187.75, ..., 42.625, 6.25, -21.5625]]]]\"On the iPhone 16 Pro Max:3: \"[[[[191.5, 23.625, 173.75, ..., 1298, -147.25, -162.5]]]]\"Huh. Not close. Not at all. These values are orders of magnitude off. I double check the start of the logs and both phones show the same:1: \"array([[[0.162842, -0.162842, -0.48877, ..., -0.176636, 0.0001297, 0.088501],\\n [-0.348633, -2.78906, 0, ..., 0.84668, 0, -1.69336],\\n [-1.30957, 1.57324, -1.30957, ..., -0.0010376, -0.0010376, 1.12305],\\n ...,\\n [-0.348633, -2.78906, 0, ..., 0.84668, 0, -1.69336],\\n [0.296875, 0.59375, 0.890625, ..., -0.59375, 0.296875, -0.890137],\\n [1.02734, -0.616211, -0.616211, ..., -0.275879, -0.551758, 0.275879]]], dtype=float16)\"\n\nOK, so the model receives the same thing as input, but at some point, the values start to go off. Like,way off. In order to make sure I'm not crazy, I do one last thing: run the same thing on my Mac. Make the app run on iPad compatibility mode and...3: \"[[[[53.875, 62.5625, -187.75, ..., 42.625, 6.25, -21.5625]]]]\"\n\nBingo! Same as iPhone 15!\n\nThe model isn't broken. The code isn't broken. Most importantly, I'm not broken*. Myphoneis broken.*arguable, but besides the point here\n\nWhat's going on?\n\nLet me explain what I think it's going on here: the iPhone 16 Pro Max contains Apple's A18 chip with its Neural Engine‚Äîa specialized accelerator for machine learning operations. MLX uses Metal to compile tensor operations for this accelerator. Somewhere in that stack, the computations are goingverywrong. I don't think it's a widespread issue but, I do get disappointed that a relatively newly replaced iPhone from Apple Care came with such an issue.\n\nHowever, if my Apple Intelligence troubles are related ‚Äì and they might as well be, I'd assume that code and MLX are not dissimilar in operations being done ‚Äì, it could be thatall the 12 pages of usersare users in a similar dillema, but without the means of debugging it.\n\nWhat now?\n\nI spent 3 days thinking I was incompetent. I blamed MiniMax. I blamed myself. The entire time, my $1,400 phone had a broken hardware. I could lose more time figuring outexactlywhat is wrong with it but it‚Äôs literally not worth my time.\n\nI guess I can at least take a lesson that, when debugging, I should always consider the physical layer. I spent three days assuming this was a software problem ‚Äì my code, the library, the framework, my skills as a developer. The breakthrough was basically: \"What if I'm not dumb and it's not my code?\"\n\nAs for my phone: it'll probably go back to Apple, as a trade in for a new iPhone 17 Pro Max thathopefully ü§ûcan do math.\n\nUpdate on Feb. 1st:\n\nWell, now it's Feb. 1st and I have an iPhone 17 Pro Max to test with and... everything works as expected. So it's pretty safe to say thatTHATspecific instance of iPhone 16 Pro Max was hardware-defective.",
        "url": "https://journal.rafaelcosta.me/my-thousand-dollar-iphone-cant-do-math/",
        "author_username": "rafaelcosta",
        "author_category": "unknown",
        "media": [
          {
            "type": "image",
            "url": "https://journal.rafaelcosta.me/content/images/2026/01/original-39c7e1f432c4bda26535fd3e0b5cb7d5.webp",
            "alt": ""
          },
          {
            "type": "image",
            "url": "https://journal.rafaelcosta.me/content/images/2026/01/Screenshot-2026-01-28-at-01.14.46.png",
            "alt": ""
          },
          {
            "type": "image",
            "url": "https://journal.rafaelcosta.me/content/images/2026/01/Screenshot-2026-01-28-at-02.09.49.png",
            "alt": ""
          },
          {
            "type": "image",
            "url": "https://journal.rafaelcosta.me/content/images/2026/01/Screenshot-2026-01-27-at-18.28.38.png",
            "alt": ""
          }
        ],
        "impressions_views": null,
        "impressions_likes": 425,
        "impressions_reposts": 0,
        "impressions_replies": 204,
        "impressions_bookmarks": null,
        "impressions_clicks": null,
        "impressions_quotes": null,
        "impressions_updated_at": "2026-02-03T09:02:54.478231",
        "published_at": "2026-02-01T15:51:56",
        "scraped_at": "2026-02-03T09:02:54.478278",
        "metadata": {
          "item_type": "story",
          "hn_url": "https://news.ycombinator.com/item?id=46849258",
          "kids_count": 34,
          "sections": [
            "best_stories"
          ]
        },
        "content_hash": "91de85ec962e546cebda311b3e3729ff",
        "classification": {
          "is_ai_relevant": true,
          "primary_topic": "developer_tools",
          "primary_topic_label": "Developer Tools",
          "all_topics": [
            "llm",
            "ml_research",
            "ai_infra",
            "developer_tools"
          ],
          "topic_details": {
            "llm": {
              "raw_score": 2,
              "weighted_score": 2.0,
              "matched_keywords": [
                "llm"
              ],
              "label": "Large Language Models"
            },
            "ml_research": {
              "raw_score": 2,
              "weighted_score": 1.8,
              "matched_keywords": [
                "machine learning",
                "model"
              ],
              "label": "ML Research"
            },
            "ai_infra": {
              "raw_score": 2,
              "weighted_score": 1.8,
              "matched_keywords": [
                "tpu"
              ],
              "label": "AI Infrastructure"
            },
            "developer_tools": {
              "raw_score": 5,
              "weighted_score": 3.0,
              "matched_keywords": [
                "developer",
                "ide",
                "api",
                "framework",
                "library"
              ],
              "label": "Developer Tools"
            }
          },
          "relevance_score": 0.86,
          "is_noise": false,
          "filter_reason": null
        },
        "engagement_quality": {
          "engagement_ratio": 0.48,
          "is_flamewar": false,
          "is_high_signal": true,
          "is_emerging": false,
          "discussion_depth": 6.0,
          "velocity": 10.27,
          "hours_old": 41.4,
          "quality_tier": "high_quality"
        },
        "editorial": {
          "one_liner": "Developer Tools insight worth reading",
          "why_it_matters": "highly upvoted by HN community; quality discussion",
          "audience_fit": "Software developers",
          "newsletter_priority": 2
        }
      },
      {
        "id": "907251699645d00cce15d410a1cb674b",
        "source": "hackernews",
        "source_id": "46866481",
        "title": "Coding assistants are solving the wrong problem",
        "content": "The jury is out on the effectiveness of AI use in production, and it is not a pretty picture.\n\nTeams using AI completed 21% more tasks, yet company-wide delivery metrics showed no improvement (Index.dev, 2025)\n\nExperienced developers were 19% slower when using AI coding assistants√¢¬Ä¬îyet believed they were faster (METR, 2025)\n\n48% of AI-generated code contains security vulnerabilities (Apiiro, 2024)\n\nTo understand why, we have to take a closer look at the day-to-day software development. Consider this point raised ina colorful exchangeon r/ExperiencedDev:\n\nA developers√¢¬Ä¬ô job is to reduce ambiguity. We take the business need and outline its logic precisely so a machine can execute. The act of writing the code is the easy part. Odds are, you aren√¢¬Ä¬ôt creating perfect code specs into tickets, even with meeting notes, because developers will encounter edge cases that demand clarification over the course of implementation√¢¬Ä¬¶\n\nThere are two key points raised in this comment. Firstly, coding assistants require clearly-defined requirements in order to perform well. Secondly, edge cases and product gaps are often discovered over the course of implementation.\n\nThese two facts come head-to-head in the application of coding agents to complex codebases. Unlike their human counterparts who would and escalate a requirements gap to product when necessary, coding assistants are notorious for burying those requirement gaps within hundreds of lines of code, leading to breaking changes and unmaintainable code.\n\nAs a result, more overhead is spent on downstream code reviews (Index.dev, 2025) and fire-patching security vulnerabilities (Apiiro, 2025).\n\nIn other words, the use of AI in production settings oftenincreases ambiguityandreduces code reliability, directly contradicting the objective of developers.\n\nThe picture is not without optimism. Some experienced engineers report transformative results: one principal engineer at Google claimed AI √¢¬Ä¬úgenerated what we built last year in an hour√¢¬Ä¬ù; Boris Cherny, creator of Claude Code,described a monthwhere he √¢¬Ä¬údidn√¢¬Ä¬ôt open an IDE at all√¢¬Ä¬ù while the model √¢¬Ä¬úwrote around 200 PRs, every single line.√¢¬Ä¬ù The optimistic case is that developers evolve from coders into product engineers, focusing on architecture and product thinking while AI handles implementation.\n\nThis however reflects the experience of seasoned developers who have both the technical depth to review AI output critically and the autonomy within their organizations to straddle product and engineering.\n\nFor much of the software engineering workforce, the junior and mid-level engineers at banks, healthcare, and government agencies, there√¢¬Ä¬ôs much less wiggle room. They are sandwiched between the unreliability of AI output and the increased expectation from management to ship faster, resulting in a rapidly widening empathy gap between developers and product owners.\n\nThe product context often goes through multiple layers (end users -> marketers -> product managers) before landing on their lap, necessitated by the separation of responsibilities within an organization and the unique demands of their industries. The effective use of coding agents may require a level of team coordination that simply does not justify the gains in technical output.\n\nBut what if we have simply been approaching the problem from the wrong angle?Suppose we tackle the pain points of software development from first principles, can we come up with solutions that organically decrease ambiguity and reliably increase engineering velocity in production?\n\nConsider how developers spend their time (IDC, 2024):\n\nOnly 16% of a developer√¢¬Ä¬ôs time goes to writing code. The rest? Security and code reviews, monitoring, deployments, requirements clarification√¢¬Ä¬îoperational work that keeps the lights on but doesn√¢¬Ä¬ôt ship features.\n\nHere√¢¬Ä¬ôs the irony: AI coding assistants save developers roughly 10 hours per week, but the increase in inefficiencies in the other parts of the development lifecycle almost entirely cancelled out such gains (Atlassian, 2025). Here√¢¬Ä¬ôs a comment from the earlier cited Redditor.\n\nThey produce legitimate-looking code, and if no one has had the experience of thinking through the assumptions and then writing them into code - considering the edge cases- it√¢¬Ä¬ôll be lgtm√¢¬Ä¬ôd and shipped. You√¢¬Ä¬ôre shifting the burden of this feedback cycle to the right, after the code is output, and that makes us worse off since code is tougher to read than write.\n\nThere√¢¬Ä¬ôs a name for misalignment between business intent and codebase implementation: technical debt. The use of coding agents without careful delineation of their scope and responsibilities is threatening to accelerate tech debt accumulation.\n\nHammering AI code generation on existing codebases doesn√¢¬Ä¬ôt solve the problem, because contrary to what the label √¢¬Ä¬útech debt√¢¬Ä¬ù may suggest, most tech debt isn√¢¬Ä¬ôt actually created in the code,it√¢¬Ä¬ôs created in product meetings. Deadlines. Scope cuts. √¢¬Ä¬úShip now, optimize later.√¢¬Ä¬ù Those decisions shape the system, but the reasoning rarely makes it into the code.\n\n[Engineers] occasionally have access to complete data; at other times, they must work with limited information. They might be conscious of uncertainties surrounding their evidence, but frequently they are not. Competing social, financial, and strategic priorities influence the tradeoffs in unexpected ways. √¢¬Ä¬îRios et al., 2024\n\nHow can we make this context-sharing and decision-making process less chaotic? We surveyed developers across different roles and team sizes regarding their product-engineering handoff process. The results were overwhelming: the majority discover unexpected codebase constraints weekly, after already committing to a product direction and the corresponding architectural implementation. When asked what would help most, two themes dominated:\n\nReducing ambiguity upstream so engineers aren√¢¬Ä¬ôt blocked waiting on product clarification mid-implementation\n\nA clearer picture of affected services and edge cases to allow for more precise feature scoping and time allocation\n\nWhen asked which engineering context would be most valuable to surface during product discussions, three categories stood out:state machine gaps(unhandled states caused by user interaction sequences),data flow gaps, anddownstream service impacts.\n\nIdentifying how feature updates affect existing architectures and data flow is rated most desirable among engineering contexts to be surfaced after a product meeting.\n\nThis aligns with decades of SDLC research showing that the costliest defects stem from misalignment between requirements and architecture, and such gaps often go unnoticed until it is too late.\n\nLuckily, the advancement of coding LLMs works in our favor here. Whereas generating fully-functional code through natural language prompting is prone to errors due to the aforementioned context problem, the reverse process, mapping out existing code structures and inferring how they may be impacted by a specific requirement, is much more tenable with recent models.\n\nFrom this vantage point, the possibilities to improving the developmental lifecycle is endless. Some suggested real-time display of engineering context during a meeting to help steer discussions; Others requested a code review bot that detects the discrepencacy of code implementation with stated product/business requirements.\n\nAll-in-all, developers are eager to try out new tools that augment the existing way of doing things, provided they retain flexibility over when such tools are deployed. There is also little reservation against having longer but more fruitful product meetings: it is the difficulty conveying blockers that is the source of frustration.\n\nAt Bicameral, we are committed to taking this pragmatic approach to alleviating software development pains, and move beyond lab benchmarks to investigate the most effective way to deploy AI in the wild.\n\nOur thesis is that LLMs could be a huge boonbothfor the industry and for individual developers√¢¬Ä¬îchanneling the unrivaled human capacity to operate under uncertainty and adapt√¢¬Ä¬îprovided the technology is developed with human needs in mind.\n\nIf you√¢¬Ä¬ôre a developer, we want to learn which types of context hurt most when they√¢¬Ä¬ôre missing from discussion, based on your unique experience.\n\nSurvey link:https://form.typeform.com/to/w4rPXoPD\n\nReferences\n\nIndex.dev. (2025).AI Coding Assistant ROI: Real Productivity Data.\n\nMETR. (2025).Measuring AI√¢¬Ä¬ôs Ability to Complete Long Tasks.\n\nApiiro. (2024).4x Velocity, 10x Vulnerabilities: AI Coding Assistants Are Shipping More Risks.\n\nIDC. (2024).How Do Software Developers Spend Their Time?\n\nAtlassian. (2025).State of Developer Experience Report.\n\nRios, N., et al. (2024).Technical Debt: A Systematic Literature Review.\n\nPragmatic Engineer. (2025).When AI Writes Almost All Code.",
        "url": "https://www.bicameral-ai.com/blog/introducing-bicameral",
        "author_username": "jinhkuan",
        "author_category": "unknown",
        "media": [],
        "impressions_views": null,
        "impressions_likes": 151,
        "impressions_reposts": 0,
        "impressions_replies": 112,
        "impressions_bookmarks": null,
        "impressions_clicks": null,
        "impressions_quotes": null,
        "impressions_updated_at": "2026-02-03T09:02:48.035422",
        "published_at": "2026-02-02T23:25:35",
        "scraped_at": "2026-02-03T09:02:48.035435",
        "metadata": {
          "item_type": "story",
          "hn_url": "https://news.ycombinator.com/item?id=46866481",
          "kids_count": 22,
          "sections": [
            "top_stories"
          ]
        },
        "content_hash": "72faf2f95fe4fc45b8f09324a4f0aa1e",
        "classification": {
          "is_ai_relevant": true,
          "primary_topic": "developer_tools",
          "primary_topic_label": "Developer Tools",
          "all_topics": [
            "llm",
            "ml_research",
            "ai_infra",
            "ai_ethics",
            "developer_tools",
            "tech_industry"
          ],
          "topic_details": {
            "llm": {
              "raw_score": 3,
              "weighted_score": 3.0,
              "matched_keywords": [
                "llm",
                "claude",
                "coding agent"
              ],
              "label": "Large Language Models"
            },
            "ml_research": {
              "raw_score": 3,
              "weighted_score": 2.7,
              "matched_keywords": [
                "model",
                "benchmark",
                "reasoning"
              ],
              "label": "ML Research"
            },
            "ai_infra": {
              "raw_score": 1,
              "weighted_score": 0.9,
              "matched_keywords": [
                "tpu"
              ],
              "label": "AI Infrastructure"
            },
            "ai_ethics": {
              "raw_score": 1,
              "weighted_score": 0.8,
              "matched_keywords": [
                "alignment"
              ],
              "label": "AI Ethics & Safety"
            },
            "developer_tools": {
              "raw_score": 6,
              "weighted_score": 3.5999999999999996,
              "matched_keywords": [
                "developer",
                "ide",
                "coding",
                "software engineering",
                "api"
              ],
              "label": "Developer Tools"
            },
            "tech_industry": {
              "raw_score": 1,
              "weighted_score": 0.5,
              "matched_keywords": [
                "yc"
              ],
              "label": "Tech Industry"
            }
          },
          "relevance_score": 1.0,
          "is_noise": false,
          "filter_reason": null
        },
        "engagement_quality": {
          "engagement_ratio": 0.74,
          "is_flamewar": false,
          "is_high_signal": false,
          "is_emerging": true,
          "discussion_depth": 5.09,
          "velocity": 15.38,
          "hours_old": 9.8,
          "quality_tier": "good"
        },
        "editorial": {
          "one_liner": "Developer Tools insight worth reading",
          "why_it_matters": "worth monitoring",
          "audience_fit": "Software developers",
          "newsletter_priority": 3
        }
      },
      {
        "id": "9fccf8033fd430ac4b861095a4d769b4",
        "source": "hackernews",
        "source_id": "46850205",
        "title": "Show HN: NanoClaw ‚Äì ‚ÄúClawdbot‚Äù in 500 lines of TS with Apple container isolation",
        "content": "My personal Claude assistant that runs securely in containers. Lightweight and built to be understood and customized for your own needs.\n\nWhy I Built This\n\nOpenClawis an impressive project with a great vision. But I can't sleep well running software I don't understand with access to my life. OpenClaw has 52+ modules, 8 config management files, 45+ dependencies, and abstractions for 15 channel providers. Security is application-level (allowlists, pairing codes) rather than OS isolation. Everything runs in one Node process with shared memory.\n\nNanoClaw gives you the same core functionality in a codebase you can understand in 8 minutes. One process. A handful of files. Agents run in actual Linux containers with filesystem isolation, not behind permission checks.\n\nQuick Start\n\nThen run/setup. Claude Code handles everything: dependencies, authentication, container setup, service configuration.\n\nPhilosophy\n\nSmall enough to understand.One process, a few source files. No microservices, no message queues, no abstraction layers. Have Claude Code walk you through it.\n\nSecure by isolation.Agents run in Linux containers (Apple Container on macOS, or Docker). They can only see what's explicitly mounted. Bash access is safe because commands run inside the container, not on your host.\n\nBuilt for one user.This isn't a framework. It's working software that fits my exact needs. You fork it and have Claude Code make it match your exact needs.\n\nCustomization = code changes.No configuration sprawl. Want different behavior? Modify the code. The codebase is small enough that this is safe.\n\nAI-native.No installation wizard; Claude Code guides setup. No monitoring dashboard; ask Claude what's happening. No debugging tools; describe the problem, Claude fixes it.\n\nSkills over features.Contributors shouldn't add features (e.g. support for Telegram) to the codebase. Instead, they contributeclaude code skillslike/add-telegramthat transform your fork. You end up with clean code that does exactly what you need.\n\nBest harness, best model.This runs on Claude Agent SDK, which means you're running Claude Code directly. The harness matters. A bad harness makes even smart models seem dumb, a good harness gives them superpowers. Claude Code is (IMO) the best harness available.\n\nNo ToS gray areas.Because it uses Claude Agent SDK natively with no hacks or workarounds, using your subscription with your auth token is completely legitimate (I think). No risk of being shut down for terms of service violations (I am not a lawyer).\n\nWhat It Supports\n\nWhatsApp I/O- Message Claude from your phone\n\nIsolated group context- Each group has its ownCLAUDE.mdmemory, isolated filesystem, and runs in its own container sandbox with only that filesystem mounted\n\nMain channel- Your private channel (self-chat) for admin control; every other group is completely isolated\n\nScheduled tasks- Recurring jobs that run Claude and can message you back\n\nWeb access- Search and fetch content\n\nContainer isolation- Agents sandboxed in Apple Container (macOS) or Docker (macOS/Linux)\n\nOptional integrations- Add Gmail (/add-gmail) and more via skills\n\nUsage\n\nTalk to your assistant with the trigger word (default:@Andy):\n\nFrom the main channel (your self-chat), you can manage groups and tasks:\n\nCustomizing\n\nThere are no configuration files to learn. Just tell Claude Code what you want:\n\n\"Change the trigger word to @Bob\"\n\n\"Remember in the future to make responses shorter and more direct\"\n\n\"Add a custom greeting when I say good morning\"\n\n\"Store conversation summaries weekly\"\n\nOr run/customizefor guided changes.\n\nThe codebase is small enough that Claude can safely modify it.\n\nContributing\n\nDon't add features. Add skills.\n\nIf you want to add Telegram support, don't create a PR that adds Telegram alongside WhatsApp. Instead, contribute a skill file (.claude/skills/add-telegram/SKILL.md) that teaches Claude Code how to transform a NanoClaw installation to use Telegram.\n\nUsers then run/add-telegramon their fork and get clean code that does exactly what they need, not a bloated system trying to support every use case.\n\nRFS (Request for Skills)\n\nSkills we'd love to see:\n\nCommunication Channels\n\n/add-telegram- Add Telegram as channel. Should give the user option to replace WhatsApp or add as additional channel. Also should be possible to add it as a control channel (where it can trigger actions) or just a channel that can be used in actions triggered elsewhere\n\n/add-slack- Add Slack\n\n/add-discord- Add Discord\n\nPlatform Support\n\n/setup-windows- Windows via WSL2 + Docker\n\nSession Management\n\n/add-clear- Add a/clearcommand that compacts the conversation (summarizes context while preserving critical information in the same session). Requires figuring out how to trigger compaction programmatically via the Claude Agent SDK.\n\nRequirements\n\nmacOS or Linux\n\nNode.js 20+\n\nClaude Code\n\nApple Container(macOS) orDocker(macOS/Linux)\n\nArchitecture\n\nSingle Node.js process. Agents execute in isolated Linux containers with mounted directories. IPC via filesystem. No daemons, no queues, no complexity.\n\nKey files:\n\nsrc/index.ts- Main app: WhatsApp connection, routing, IPC\n\nsrc/container-runner.ts- Spawns agent containers\n\nsrc/task-scheduler.ts- Runs scheduled tasks\n\nsrc/db.ts- SQLite operations\n\ngroups/*/CLAUDE.md- Per-group memory\n\nFAQ\n\nWhy WhatsApp and not Telegram/Signal/etc?\n\nBecause I use WhatsApp. Fork it and run a skill to change it. That's the whole point.\n\nWhy Apple Container instead of Docker?\n\nOn macOS, Apple Container is lightweight, fast, and optimized for Apple silicon. But Docker is also fully supported‚Äîduring/setup, you can choose which runtime to use. On Linux, Docker is used automatically.\n\nCan I run this on Linux?\n\nYes. Run/setupand it will automatically configure Docker as the container runtime. Thanks to@dotsetgregfor contributing the/convert-to-dockerskill.\n\nIs this secure?\n\nAgents run in containers, not behind application-level permission checks. They can only access explicitly mounted directories. You should still review what you're running, but the codebase is small enough that you actually can. Seedocs/SECURITY.mdfor the full security model.\n\nWhy no configuration files?\n\nWe don't want configuration sprawl. Every user should customize it to so that the code matches exactly what they want rather than configuring a generic system. If you like having config files, tell Claude to add them.\n\nHow do I debug issues?\n\nAsk Claude Code. \"Why isn't the scheduler running?\" \"What's in the recent logs?\" \"Why did this message not get a response?\" That's the AI-native approach.\n\nWhy isn't the setup working for me?\n\nI don't know. Runclaude, then run/debug. If claude finds an issue that is likely affecting other users, open a PR to modify the setup SKILL.md.\n\nWhat changes will be accepted into the codebase?\n\nSecurity fixes, bug fixes, and clear improvements to the base configuration. That's it.\n\nEverything else (new capabilities, OS compatibility, hardware support, enhancements) should be contributed as skills.\n\nThis keeps the base system minimal and lets every user customize their installation without inheriting features they don't want.\n\nLicense\n\nMIT",
        "url": "https://github.com/gavrielc/nanoclaw",
        "author_username": "jimminyx",
        "author_category": "unknown",
        "media": [],
        "impressions_views": null,
        "impressions_likes": 515,
        "impressions_reposts": 0,
        "impressions_replies": 219,
        "impressions_bookmarks": null,
        "impressions_clicks": null,
        "impressions_quotes": null,
        "impressions_updated_at": "2026-02-03T09:02:52.941336",
        "published_at": "2026-02-01T17:49:22",
        "scraped_at": "2026-02-03T09:02:52.941348",
        "metadata": {
          "item_type": "show_hn",
          "hn_url": "https://news.ycombinator.com/item?id=46850205",
          "kids_count": 47,
          "sections": [
            "best_stories",
            "show_hn"
          ]
        },
        "content_hash": "6a51b8d48ffa7dfbc372f1f9ed390ab6",
        "classification": {
          "is_ai_relevant": true,
          "primary_topic": "developer_tools",
          "primary_topic_label": "Developer Tools",
          "all_topics": [
            "llm",
            "ml_research",
            "developer_tools",
            "data_engineering"
          ],
          "topic_details": {
            "llm": {
              "raw_score": 1,
              "weighted_score": 1.0,
              "matched_keywords": [
                "claude"
              ],
              "label": "Large Language Models"
            },
            "ml_research": {
              "raw_score": 1,
              "weighted_score": 0.9,
              "matched_keywords": [
                "model"
              ],
              "label": "ML Research"
            },
            "developer_tools": {
              "raw_score": 3,
              "weighted_score": 1.7999999999999998,
              "matched_keywords": [
                "ide",
                "sdk",
                "framework"
              ],
              "label": "Developer Tools"
            },
            "data_engineering": {
              "raw_score": 1,
              "weighted_score": 0.5,
              "matched_keywords": [
                "sql"
              ],
              "label": "Data Engineering"
            }
          },
          "relevance_score": 0.42,
          "is_noise": false,
          "filter_reason": null
        },
        "engagement_quality": {
          "engagement_ratio": 0.43,
          "is_flamewar": false,
          "is_high_signal": true,
          "is_emerging": false,
          "discussion_depth": 4.66,
          "velocity": 13.06,
          "hours_old": 39.4,
          "quality_tier": "high_quality"
        },
        "editorial": {
          "one_liner": "New developer tools project worth checking out",
          "why_it_matters": "highly upvoted by HN community; quality discussion",
          "audience_fit": "Software developers",
          "newsletter_priority": 3
        }
      },
      {
        "id": "47f994e1e1e906d441154316ca064450",
        "source": "hackernews",
        "source_id": "46861313",
        "title": "Anki ownership transferred to AnkiHub",
        "content": "Anki's Growing Up\n\nHi all,\n\nAnki‚Äôs 19th birthday was about 4 months ago. It would have been a good time to pause and reflect on what Anki has become, and how it will grow in the future. But I ended up letting the moment come and go, as I didn‚Äôt feel like I had the free time. It‚Äôs a feeling that‚Äôs been regrettably common of late, and I‚Äôve come to realise that something has to change.\n\nFor a number of years, I‚Äôve reached out to some of the most prolific contributors and offered them payment in exchange for them contributing more code or support to Anki. That has been a big help, and I‚Äôm very grateful for their contributions. But there is a lot that I haven‚Äôt been able to delegate. With no previous management experience, I was a bit daunted by the thought of seeking out and managing employees. And with so much to get on with, it always got put in the ‚Äúmaybe later‚Äù basket.\n\nAs Anki slowly grew in popularity, so did its demands on my time. I was of course delighted to see it reaching more people, and to have played a part in its success. But I also felt a big sense of responsibility, and did not want to let people down. That led to unsustainably long hours and constant stress, which took a toll on my relationships and well-being.\n\nThe parts of the job that drew me to start working on Anki (the ‚Äòdeep work‚Äô, solving interesting technical problems without constant distractions) have mostly fallen by the wayside. I find myself reactively responding to the latest problem or post instead of proactively moving things forward, which is neither as enjoyable as it once was, nor the best thing for the project.\n\nThere have been many offers to invest in or buy Anki over the years, but I‚Äôve always shut them down quickly, as I had no confidence that these investment-focused people would be good stewards, and not proceed down the typical path of enshittification that is unfortunately so common in VC and PE-backed ventures.\n\nSome months ago, the AnkiHub folks reached out to me, wanting to discuss working more closely together in the future. Like others in the community, they were keen to see Anki‚Äôs development pace improve. We‚Äôve had a symbiotic relationship for years, with their content creation and collaboration platform driving more users to Anki. They‚Äôve managed to scale up much faster than I did, and have built out animpressive team.\n\nDuring the course of those talks, I came to the realisation that AnkiHub is better positioned to take Anki to the next level than I am. I ended up suggesting to them that we look into gradually transitioning business operations and open source stewardship over, with provisions in place to ensure that Anki remains open source and true to the principles I‚Äôve run it by all these years.\n\nThis is a step back for me rather than a goodbye - I will still be involved with the project, albeit at a more sustainable level. I‚Äôve spent 19 years looking after my ‚Äúbaby‚Äù, and I want to see it do well as it grows up.\n\nI‚Äôm confident this change will be a net positive for both users and developers. Removing me as a bottleneck will allow things to move faster, encourage a more collaborative approach, and free up time for improvements that have been hard to prioritise, like UI polish. It also means the ecosystem will no longer be in jeopardy if I‚Äôm one day hit by a bus.\n\nIt‚Äôs natural to feel apprehensive about change, but as the benefits become clearer over the coming months, I suspect many of you will come to wish this change had happened sooner.\n\nThank you to everyone who has contributed to making Anki better up until now. I‚Äôm excited for Anki‚Äôs future, and can‚Äôt wait to see what we can build together in this next stage.\n\nHi everyone,\n\nWe initially reached out to@daeto explore collaborating more closely on improving Anki. We were both humbled and shocked when he asked if we‚Äôd be willing to step into a much larger leadership role than we expected.\n\nAt this point, we‚Äôre mostly excited‚Ä¶and also feeling a healthy amount of terror.This is a big responsibility. It will push us to grow as individuals, asa team, and as a community, and we don‚Äôt take that lightly.\n\nWe‚Äôre grateful for the trust Damien and others have placed in us. And we also know that trust has to be earned, especially from people who don‚Äôt know us yet.\n\nWhat We Believe\n\nWe believe Anki is almost sacred, something bigger than any one person or organization. In an important sense, it belongs to the community.\n\nThis articlehighlights the principles Damien built Anki on;principleswe deeply share, such as respect for user agency, refusal of manipulative design patterns, and an emphasis on the craft of building genuinely useful tools that aren‚Äôtmerelyengaging. Anki has never tried to maximize ‚Äúengagement‚Äù by exploiting psychological vulnerabilities purely for profit.Anki gives your timebackto you, and that is an exceptional rarity in this world that we want to preserve.\n\nAs an organization built by students, for students, our mission is to continue embodying these principles. We are accountable only to you, our users, not external investors, and we plan to keep it that way.\n\nWhat We Don‚Äôt Know Yet\n\nWe can‚Äôt answer every question right away, as there are many unknowns since much hasn‚Äôt been decided yet. But we are sharing everything we can now because the community is important to us. We encourage you all to share your thoughts and questions ‚Äì we‚Äôre all in this together!\n\nWe‚Äôre still working through the details on things like:\n\nGovernance and decision-making: How decisions are made, who has final say, and how the community is heard\n\nRoadmap and priorities: What gets built when and how to balance competing needs\n\nThe transition itself: How to bring in more support without disrupting what already works\n\nAnki has shown how powerful community collaboration can be when it‚Äôs genuinely a group effort, and that‚Äôs a tradition we are honored to continue.\n\nWe‚Äôre currently talking toDavid Allison, a long-time core contributor toAnkiDroid, about working together on exactly these questions. His experience with AnkiDroid‚Äôs collaborative development is invaluable, and we‚Äôre grateful he‚Äôs willing to help us get this right.We‚Äôre incredibly excited to have him join usfull-timeto help propel Anki into the future.\n\nWhat We‚Äôre Aiming For\n\nUI/UX improvements.We‚Äôre bringing professional design expertise on board to make it more approachable without sacrificing Anki‚Äôs power. We believe that principled design will bring meaningful quality of life improvements to power users and novices alike.\n\nAddressing thebus factor.The ecosystem shouldn‚Äôt be in jeopardy if any one person disappears. We want to build software that lives beyond any single contributor.\n\nSupporting more than just med students.AnkiHub grew out of the medical education community, but Anki serves learners from all walks of life, and we want to support everyone to achieve their learning goals.\n\nA more robust add-on ecosystem.We‚Äôd love to build tools that empowernon-technicalusers to customize Anki for their needs, and we‚Äôre exploring add-ons that work everywhere, including mobile.\n\nHow We‚Äôll Work\n\nWe want to provide transparency into the decision-making process, taking inspiration fromproven modelsto:\n\nGive the community clarity on how to be heard and give feedback\n\nMake it clear how decisions are made and why\n\nSet realistic expectations\n\nDefine roles and responsibilities so things don‚Äôt fall through the cracks\n\nWe want to bring everyone in the global Anki community together into a closer collaboration focused on building the best learning tools possible. Today, these groups often work in silos; a more unified process will help everyone move Anki forward together.\n\nSustainability\n\nSome practical reassurances:\n\nSustainability, affordability, and accessibility.We‚Äôre committed to a sustainable business model that keeps Anki accessible and prioritizes user needs above profits. If anything ever needs to change, we‚Äôll be transparent about why.\n\nNo enshittification.We‚Äôve seen what happens when VC-backed companies acquire beloved tools. That‚Äôs not what this is. There are no investors involved, and we‚Äôre not here to extract value from something the community built together. Building in the right safeguards and processes to handle pressure without stifling necessary improvements is something we‚Äôre actively considering.\n\nWe‚Äôre grateful to Damien et all for their trust and support, and grateful to all of you for the passion that makes this community so special.\n\nWe welcome your questions, concerns, and feedback.\n\n‚ÄìThe AnkiHub Team\n\nFAQs\n\nWhat is AnkiHub?\n\nAnkiHubis a small education technology company founded by two long-time Anki nerds: Nick, a resident physician known asThe AnKing, and Andrew Sanchez, a research software engineer. AnkiHub grew out of years of obsessive Anki use and firsthand experience with both its power and its limitations.\n\nAnkiHubbegan as a way to collaborate on Anki decks (such as theAnKing Step Deckfor medical students) and has since evolved into a broader effort to improve the Anki ecosystem by building tools that help more people benefit from Anki.\n\nWill Anki remain open source?\n\nAbsolutely. Anki‚Äôs core code will remain open source, guided by the same principles that have guided the project from the beginning.\n\nAre there any changes planned to Anki‚Äôs pricing?\n\nNo. We are committed to fair pricing that supports users rather than exploiting them. Both Anki and AnkiHub are already profitable. Any future decisions will be made with community benefit, user value, and long-term project health in mind.\n\nIs Anki in financial trouble?\n\nNo. The transition is driven by the goal of helping Anki reach its full potential, not by financial issues. Our goal is to build a resilient structure and accelerate development.\n\nWhat is the timeline?\n\nOur intention is to build confidence and earn trust while making gradual changes. The transition will be transparent, with clear communication throughout.\n\nWhat happens to volunteer contrib",
        "url": "https://forums.ankiweb.net/t/ankis-growing-up/68610",
        "author_username": "trms",
        "author_category": "unknown",
        "media": [
          {
            "type": "image",
            "url": "https://emoji.discourse-cdn.com/twitter/sweat_smile.png?v=15",
            "alt": ":sweat_smile:"
          },
          {
            "type": "image",
            "url": "https://emoji.discourse-cdn.com/twitter/poop.png?v=15",
            "alt": ":poop:"
          },
          {
            "type": "image",
            "url": "https://emoji.discourse-cdn.com/twitter/beating_heart.png?v=15",
            "alt": ":beating_heart:"
          },
          {
            "type": "image",
            "url": "https://emoji.discourse-cdn.com/twitter/sweat_smile.png?v=15",
            "alt": ":sweat_smile:"
          },
          {
            "type": "image",
            "url": "https://emoji.discourse-cdn.com/twitter/slight_smile.png?v=15",
            "alt": ":slight_smile:"
          }
        ],
        "impressions_views": null,
        "impressions_likes": 469,
        "impressions_reposts": 0,
        "impressions_replies": 186,
        "impressions_bookmarks": null,
        "impressions_clicks": null,
        "impressions_quotes": null,
        "impressions_updated_at": "2026-02-03T09:02:25.024035",
        "published_at": "2026-02-02T15:48:55",
        "scraped_at": "2026-02-03T09:02:25.024049",
        "metadata": {
          "item_type": "story",
          "hn_url": "https://news.ycombinator.com/item?id=46861313",
          "kids_count": 41,
          "sections": [
            "top_stories",
            "best_stories"
          ]
        },
        "content_hash": "a209720fc61a423cbf5b9d28609e646d",
        "classification": {
          "is_ai_relevant": true,
          "primary_topic": "developer_tools",
          "primary_topic_label": "Developer Tools",
          "all_topics": [
            "ml_research",
            "developer_tools",
            "tech_industry"
          ],
          "topic_details": {
            "ml_research": {
              "raw_score": 1,
              "weighted_score": 0.9,
              "matched_keywords": [
                "model"
              ],
              "label": "ML Research"
            },
            "developer_tools": {
              "raw_score": 2,
              "weighted_score": 1.2,
              "matched_keywords": [
                "developer",
                "ide"
              ],
              "label": "Developer Tools"
            },
            "tech_industry": {
              "raw_score": 2,
              "weighted_score": 1.0,
              "matched_keywords": [
                "yc",
                "vc"
              ],
              "label": "Tech Industry"
            }
          },
          "relevance_score": 0.31,
          "is_noise": false,
          "filter_reason": null
        },
        "engagement_quality": {
          "engagement_ratio": 0.4,
          "is_flamewar": false,
          "is_high_signal": true,
          "is_emerging": false,
          "discussion_depth": 4.54,
          "velocity": 26.91,
          "hours_old": 17.4,
          "quality_tier": "trending_must_include"
        },
        "editorial": {
          "one_liner": "Developer Tools insight worth reading",
          "why_it_matters": "rapidly gaining attention; highly upvoted by HN community",
          "audience_fit": "Software developers",
          "newsletter_priority": 4
        }
      },
      {
        "id": "37dff9eda75b1c215adb67b4c7fba078",
        "source": "hackernews",
        "source_id": "46849567",
        "title": "Defeating a 40-year-old copy protection dongle",
        "content": "That‚Äôs right ‚Äî this little device is what stood between me and the ability to run aneven olderpiece of software that I recently unearthed during an expedition of software archaeology.\n\nFor a bit more background, I was recently involved in helping a friend‚Äôs accounting firm to move away from using anextremelylegacy software package that they had locked themselves into using for the last four decades.\n\nThis software was built using a programming language calledRPG(‚ÄúReport Program Generator‚Äù), which is older than COBOL (!), and was used with IBM‚Äôs midrange computers such as the System/3, System/32, and all the way up to the AS/400. Apparently, RPG was subsequently ported to MS-DOS, so that the same software tools built with RPG could run on personal computers, which is how we ended up here.\n\nThis accounting firm was actually using a Windows 98 computer (yep, in 2026), and running the RPG software inside a DOS console window. And it turned out that, in order to run this software, it requires a special hardware copy-protection dongle to be attached to the computer‚Äôs parallel port! This was a relatively common practice in those days, particularly with ‚Äúenterprise‚Äù software vendors who wanted to protect their very important‚Ñ¢ software from unauthorized use.\n\nSadly, most of the text and markings on the dongle‚Äôs label has been worn or scratched off, but we can make out several clues:\n\nThe words ‚ÄúStamford, CT‚Äù, and what‚Äôs very likely the logo of a company called ‚ÄúSoftware Security Inc‚Äù. The only evidence for the existence of this company is this record of them exhibiting their wares atSIGGRAPH conferencesin the early 1990s, as well as severalpatentsissued to them, relating to software protection.\n\nA word that seems to say ‚ÄúRUNTIME‚Äù, which will become clear in a bit.\n\nMy first course of action was to take a disk image of the Windows 98 PC that was running this software, and get it running in an emulator, so that we could see what the software actually does, and perhaps export the data from this software into a more modern format, to be used with modern accounting tools. But of course all of this requires the hardware dongle; none of the accounting tools seem to work without it plugged in.\n\nBefore doing anything, I looked through the disk image for any additional interesting clues, and found plenty of fascinating (and archaeologically significant?) stuff:\n\nWe‚Äôve got a compiler for the RPG II language (excellent!), made by a company called Software West Inc.\n\nEven better, there aretwo versionsof the RPG II compiler, released on various dates in the 1990s by Software West.\n\nWe‚Äôve got the complete source code of the accounting software, written in RPG. It looks like the full accounting package consists of numerous RPG modules, with a gnarly combination of DOS batch files for orchestrating them, all set up as a ‚Äúmenu‚Äù system for the user to navigate using number combinations. Clearly the author of this accounting system was originally an IBM mainframe programmer, and insisted on bringing those skills over to DOS, with mixed results.\n\nI began by playing around with the RPG compiler in isolation, and I learned very quickly that it‚Äôs the RPG compiler itself that requires the hardware dongle, and then the compiler automatically injects the same copy-protection logic into any executables it generates. This explains the text that seems to say ‚ÄúRUNTIME‚Äù on the dongle.\n\nThe compiler consists of a few executable files, notablyRPGC.EXE, which is the compiler, andSEU.EXE, which is a source editor (‚ÄúSource Entry Utility‚Äù). Here‚Äôs what we get when we launch SEU without the dongle, after a couple of seconds:\n\nA bit rude, but this gives us an important clue: this program must be trying to communicate over the parallel port over the course of a few seconds (which could give us an opportunity to pause it for debugging, and see what it‚Äôs doing during that time), and then exits with a message (which we can now find in a disassembly of the program, and trace how it gets there).\n\nA great tool for disassembling executables of this vintage isReko. It understands 16-bit real mode executables, and even attempts to decompile them into readable C code that corresponds to the disassembly.\n\nAnd so, looking at the decompiled/disassembled code in Reko, I expected to findinandoutinstructions, which would be the telltale sign of the program trying to communicate with the parallel port through the PC‚Äôs I/O ports. However‚Ä¶ I didn‚Äôt see aninoroutinstruction anywhere! But then I noticed something: Reko disassembled the executable into two ‚Äúsegments‚Äù:0800and0809, and I was only looking at segment0809.\n\nIf we look at segment0800, we see the smoking gun:inandoutinstructions, meaning that the copy-protection routine is definitely here, and best of all, the entire code segment is a mere 0x90 bytes, which suggests that the entire routine should be pretty easy to unravel and understand. For some reason, Reko was not able to decompile this code into a C representation, but it still produced a disassembly, which will work just fine for our purposes. Maybe this was a primitive form of obfuscation from those early days, which is now confusing Reko and preventing it from associating this chunk of code with the rest of the program‚Ä¶ who knows.\n\nHere is a GitHub Gist with thedisassembly of this code, along with my annotations and notes. My x86 assembly knowledge is a little rusty, but here is the gist of what this code does:\n\nIt‚Äôs definitely a single self-contained routine, intended to be called using a ‚Äúfar‚ÄùCALLinstruction, since it returns with aRETFinstruction.\n\nIt begins by detecting the address of the parallel port, by reading theBIOS data area. If the computer has more than one parallel port, the dongle must be connected to thefirstparallel port (LPT1).\n\nIt performs a loop where it writes values to the data register of the parallel port, and then reads the status register, and accumulates responses in theBHandBLregisters.\n\nAt the end of the routine, the ‚Äúresult‚Äù of the whole procedure is stored in theBXregister (BHandBLtogether), which will presumably be ‚Äúverified‚Äù by the caller of the routine.\n\nVery importantly, there doesn‚Äôt seem to be any ‚Äúinput‚Äù into this routine. It doesn‚Äôt pop anything from the stack, nor does it care about any register values passed into it. Which can only mean that the result of this routine iscompletely constant! No matter what complicated back-and-forth it does with the dongle, the result of this routine should always be the same.\n\nWith the knowledge that this routine must exit with some magic value stored inBX, we can now patch the first few bytes of the routine to do just that! Not yet knowing which value to put inBX, let‚Äôs start with 1234:\n\nOnly the first four bytes need patching ‚Äî setBXto our desired value, and get out of there (RETF). Running the patched executable with these new bytes still fails (expectedly) with the same message of ‚ÄúNo dongle, no edit‚Äù, but it fails immediately, instead of after several seconds of talking to the parallel port. Progress!\n\nStepping through the disassembly more closely, we get another major clue: The only value thatBHcan be at the end of the routine is 76h (this is hard-coded into the routine). So, our total value for the magic number inBXmust be of the form 76xx. In other words, only theBLvalue remains unknown:\n\nSinceBLis an 8-bit register, it can only have 256 possible values. And what do we do when we have 256 combinations to try? Brute force it! I whipped up a script that plugs a value into that particular byte (from 0 to 255) and programmatically launches the executable in DosBox, and observes the output. Lo and behold, it worked! The brute forcing didn‚Äôt take long at all, because the correct number turned out to be‚Ä¶6. Meaning that the total magic number inBXshould be 7606h:\n\nBingo!And then, proceeding to examine the other executable files in the compiler suite, the parallel port routine turns out to beexactly the same. All of the executables have the exact same copy protection logic, as if it was rubber-stamped onto them. In fact, when the compiler (RPGC.EXE) compiles some RPG source code, it seems to copy the parallel port routine from itself into the compiled program. That‚Äôs right: the patched version of the compiler will produce executables with the same patched copy protection routine! Very convenient.\n\nI must say, this copy protection mechanism seems a bit‚Ä¶ simplistic? A hardware dongle that just passes back a constant number? Defeatable with a four-byte patch? Is this really worthy of a patent? But who am I to pass judgment. It‚Äôs possible that I haven‚Äôt fully understood the logic, and the copy protection will somehow re-surface in another way. It‚Äôs also possible that the creators of the RPG compiler (Software West, Inc) didn‚Äôt take proper advantage of the hardware dongle, and used it in a way that is so easily bypassed.\n\nIn any case, Software West‚Äôs RPG II compiler is now free from the constraint of the parallel port dongle! And at some point soon, I‚Äôll work on purging any PII from the compiler directories, and make this compiler available as an artifact of computing history. It doesn‚Äôt seem to be available anywhere else on the web. If anyone reading this was associated with Software West Inc, feel free to get in touch ‚Äî I have many questions!",
        "url": "https://dmitrybrant.com/2026/02/01/defeating-a-40-year-old-copy-protection-dongle",
        "author_username": "zdw",
        "author_category": "unknown",
        "media": [],
        "impressions_views": null,
        "impressions_likes": 834,
        "impressions_reposts": 0,
        "impressions_replies": 281,
        "impressions_bookmarks": null,
        "impressions_clicks": null,
        "impressions_quotes": null,
        "impressions_updated_at": "2026-02-03T09:02:50.943300",
        "published_at": "2026-02-01T16:30:51",
        "scraped_at": "2026-02-03T09:02:50.943312",
        "metadata": {
          "item_type": "story",
          "hn_url": "https://news.ycombinator.com/item?id=46849567",
          "kids_count": 61,
          "sections": [
            "best_stories"
          ]
        },
        "content_hash": "11b2547884f78e9b6a93498b728c5741",
        "classification": {
          "is_ai_relevant": true,
          "primary_topic": "developer_tools",
          "primary_topic_label": "Developer Tools",
          "all_topics": [
            "ai_infra",
            "developer_tools"
          ],
          "topic_details": {
            "ai_infra": {
              "raw_score": 1,
              "weighted_score": 0.9,
              "matched_keywords": [
                "tpu"
              ],
              "label": "AI Infrastructure"
            },
            "developer_tools": {
              "raw_score": 2,
              "weighted_score": 1.2,
              "matched_keywords": [
                "ide",
                "programming"
              ],
              "label": "Developer Tools"
            }
          },
          "relevance_score": 0.21,
          "is_noise": false,
          "filter_reason": null
        },
        "engagement_quality": {
          "engagement_ratio": 0.34,
          "is_flamewar": false,
          "is_high_signal": true,
          "is_emerging": false,
          "discussion_depth": 4.61,
          "velocity": 20.48,
          "hours_old": 40.7,
          "quality_tier": "trending_must_include"
        },
        "editorial": {
          "one_liner": "Developer Tools insight worth reading",
          "why_it_matters": "rapidly gaining attention; highly upvoted by HN community",
          "audience_fit": "Software developers",
          "newsletter_priority": 5
        }
      }
    ],
    "ü§ñ AI & LLMs": [
      {
        "id": "3d1beb45846791a0f0d53fdcf6df87c5",
        "source": "hackernews",
        "source_id": "46857615",
        "title": "Hacking Moltbook",
        "content": "What is Moltbook, and Why Did it Attract Our Attention?\n\nMoltbook, the weirdly futuristic social network, has quickly gone viral as a forum where AI agents post and chat. But what we discovered tells a different story - and provides a fascinating look into what happens when applications are vibe-coded into existence without proper security controls.\n\nWe identified a misconfigured Supabase database belonging to Moltbook, allowing full read and write access to all platform data. The exposure included 1.5 million API authentication tokens, 35,000 email addresses, and private messages between agents. We immediately disclosed the issue to the Moltbook team, who secured it within hours with our assistance, and all data accessed during the research and fix verification has been deleted.\n\nExecutive Summary\n\nMoltbook is a social platform designed exclusively for AI agents - positioned as the \"front page of the agent internet.\" The platform allows AI agents to post content, comment, vote, and build reputation through a karma system, creating what appears to be a thriving social network where AI is the primary participant.\n\nOver the past few days, Moltbook gainedsignificant attention in the AI community. OpenAI founding member Andrej Karpathy described it as \"genuinely the most incredible sci-fi takeoff-adjacent thing I have seen recently,\" noting how agents were \"self-organizing on a Reddit-like site for AIs, discussing various topics, e.g. even how to speak privately.\"\n\nThe Moltbook founderexplained publicly on Xthat he \"vibe-coded\" the platform:\n\nI didn‚Äôt write a single line of code for @moltbook. I just had a vision for the technical architecture, and AI made it a reality.‚Äù\n\nThis practice, while revolutionary, can lead to dangerous security oversights - similar to previous vulnerabilities we have identified, including theDeepSeek data leakandBase44 Authentication Bypass.\n\nWe conducted a non-intrusive security review, simply by browsing like normal users. Within minutes, we discovered a Supabase API key exposed in client-side JavaScript, granting unauthenticated access to the entire production database - including read and write operations on all tables.\n\nThe exposed data told a different story than the platform's public image - while Moltbook boasted 1.5 million registered agents, the database revealed only 17,000 human owners behind them - an 88:1 ratio. Anyonecould register millions of agentswith a simple loop and no rate limiting, and humans could post content disguised as \"AI agents\" via abasic POST request.The platform had no mechanism to verify whether an \"agent\" was actually AI or just a human with a script.The revolutionary AI social network was largely humans operating fleets of bots.\n\nHow the Moltbook Database Was Exposed\n\nDiscovery of Exposed Supabase Credentials\n\nWhen navigating to Moltbook's website, we examined the client-side JavaScript bundles loaded automatically by the page. Modern web applications bundle configuration values into static JavaScript files, which can inadvertently expose sensitive credentials.This is a recurring pattern we've observed in vibe-coded applications- API keys and secrets frequently end up in frontend code, visible to anyone who inspects the page source, often with significant security consequences.\n\nBy analyzing the production JavaScript file at -\n\nhttps://www.moltbook.com/_next/static/chunks/18e24eafc444b2b9.js\n\nWe identified hardcoded Supabase connection details:\n\n-Supabase Project: ehxbxtjliybbloantpwq.supabase.co\n\n-API Key: sb_publishable_4ZaiilhgPir-2ns8Hxg5Tw_JqZU_G6-\n\nThe discovery of these credentials does not automatically indicate a security failure, as Supabase is designed to operate with certain keys exposed to the client - the real danger lies in the configuration of the backend they point to.Supabase is a popular open-source Firebase alternative providing hosted PostgreSQL databases with REST APIs. It's become especially popular with vibe-coded applications due to its ease of setup. When properly configured with Row Level Security (RLS), the public API key is safe to expose - it acts like a project identifier.However, without RLS policies, this key grants full database access to anyone who has it.In Moltbook‚Äôs implementation, this critical line of defense was missing.\n\nUnauthenticated Database Access via Supabase API\n\nUsing the discovered API key, we tested whether the recommended security measures were in place. We attempted to query the REST API directly - a request that should have returned an empty array or an authorization error if RLS were active.\n\nInstead, the database responded exactly as if we were an administrator. It immediately returned sensitive authentication tokens - including the API keys of the platform‚Äôs top AI Agents.\n\nThis confirmed unauthenticated access to user credentials that would allow complete account impersonation of any user on the platform.\n\nDatabase Enumeration Through PostgREST and GraphQL\n\nBy leveraging Supabase's PostgREST error messages, we enumerated additional tables. Querying non-existent table names returned hints revealing the actual schema.\n\nUsing this technique combined with GraphQL introspection, we mapped the complete database schema and found around ~4.75 million records exposed.\n\nSensitive Data Exposed in the Moltbook Database\n\n1.API Keys and Authentication Tokens for AI Agents\n\nThe agents table exposed authentication credentials for every registered agent in the database\n\nEach agent record contained:\n\n- api_key - Full authentication token allowing complete account takeover\n\n- claim_token - Token used to claim ownership of an agent\n\n- verification_code - Code used during agent registration\n\nWith these credentials, an attacker couldfully impersonate any agent on the platform- posting content, sending messages, and interacting as that agent. This included high-karma accounts and well-known persona agents. Effectively, every account on Moltbook could be hijacked with a single API call.\n\n2.User Email Addresses and Identity Data\n\nThe owners table contained personal information for 17,000+ users\n\nAdditionally, by querying the GraphQL endpoint, we discovered a new observers table containing 29,631 additional email addresses - these were early access signups for Moltbook's upcoming ‚ÄúBuild Apps for AI Agents‚Äù product.\n\nUnlike Twitter handles which were publicly displayed on profiles, email addresses were meant to stay private - but were fully exposed in the database.\n\n3.Private Messages & Third-Party Credential Leaks\n\nThe agent_messages table exposed 4,060 private DM conversations between agents.\n\nWhile examining this table to understand agent-to-agent interactions, we discovered thatconversations were stored without any encryption or access controls-- some contained third-party API credentials, including plaintext OpenAI API keys shared between agents.\n\n4.Write Access - Modifying Live Posts\n\nBeyond read access, we confirmed full write capabilities. Even after the initial fix that blocked read access to sensitive tables, write access to public tables remained open. We tested it and were able to successfully modify existing posts on the platform.\n\nProving that any unauthenticated user could:\n\n- Edit any post on the platform\n\n- Inject malicious content or prompt injection payloads\n\n- Deface the entire website\n\n- Manipulate content consumed by thousands of AI agents\n\nThis raises questions aboutthe integrity of all platform content- posts, votes, and karma scores - during the exposure window.\n\nWe promptly notified the team again to apply write restrictions via RLS policies.\n\nOnce the fix was confirmed, I could no longer revert the post as write access was blocked. The Moltbook team deleted the content a few hours later and thanked us for our report.\n\n5 Key Security Lessons for AI-Built Apps\n\n#1. Speed Without Secure Defaults Creates Systemic Risk\n\nVibe codingunlocks remarkable speed and creativity, enabling founders to ship real products with unprecedented velocity - as demonstrated by Moltbook. At the same time, today‚ÄôsAI tools don‚Äôt yet reason about security posture or access controls on a developer‚Äôs behalf, which means configuration details still benefit from careful human review. In this case, the issue ultimately traced back to a single Supabase configuration setting - a reminder of how small details can matter at scale.\n\n#2.¬† Participation Metrics Need Verification and Guardrails\n\nThe 88:1 agent-to-human ratio shows how \"agent internet\" metrics can be easily inflated without guardrails like rate limits or identity verification.While Moltbook reported 1.5 million agents, these were associated with roughly 17,000 human accounts, an average of about 88 agents per person. At the time of our review, there were limited guardrails such as rate limiting or validation of agent autonomy. Rather than a flaw, this likely reflects how early the ‚Äúagent internet‚Äù category still is: builders are actively exploring what agent identity, participation, and authenticity should look like, and the supporting mechanisms are still evolving.\n\n#3. Privacy Breakdowns Can Cascade Across AI Ecosystems\n\nSimilarly, the platform‚Äôs approach to privacy highlights an important ecosystem-wide lesson. Users shared OpenAI API keys and other credentials in direct messages under the assumption of privacy, but a configuration issue made those messages publicly accessible. A single platform misconfiguration was enough to expose credentials for entirely unrelated services - underscoring how interconnected modern AI systems have become.\n\n#4. Write Access Introduces Far Greater Risk Than Data Exposure Alone\n\nWhile data leaks are bad, the ability to modify content and inject prompts into an AI ecosystem introduces deeper integrity risks, including content manipulation, narrative control, and prompt injection that can propagate downstream to other AI agents. As AI-driven platforms grow, these distinctions become increasingly important design considerations.\n\n#5. Se",
        "url": "https://www.wiz.io/blog/exposed-moltbook-database-reveals-millions-of-api-keys",
        "author_username": "galnagli",
        "author_category": "unknown",
        "media": [
          {
            "type": "image",
            "url": "https://www.datocms-assets.com/75231/1769995179-image5.png?fm=webp",
            "alt": ""
          }
        ],
        "impressions_views": null,
        "impressions_likes": 355,
        "impressions_reposts": 0,
        "impressions_replies": 211,
        "impressions_bookmarks": null,
        "impressions_clicks": null,
        "impressions_quotes": null,
        "impressions_updated_at": "2026-02-03T09:02:29.343847",
        "published_at": "2026-02-02T11:08:36",
        "scraped_at": "2026-02-03T09:02:29.343859",
        "metadata": {
          "item_type": "story",
          "hn_url": "https://news.ycombinator.com/item?id=46857615",
          "kids_count": 42,
          "sections": [
            "top_stories",
            "best_stories"
          ]
        },
        "content_hash": "f5e1e85b4a626cf8d9af330c749e93a7",
        "classification": {
          "is_ai_relevant": true,
          "primary_topic": "llm",
          "primary_topic_label": "Large Language Models",
          "all_topics": [
            "llm",
            "ml_research",
            "ai_product",
            "developer_tools",
            "data_engineering"
          ],
          "topic_details": {
            "llm": {
              "raw_score": 3,
              "weighted_score": 3.0,
              "matched_keywords": [
                "openai",
                "deepseek",
                "ai agent"
              ],
              "label": "Large Language Models"
            },
            "ml_research": {
              "raw_score": 1,
              "weighted_score": 0.9,
              "matched_keywords": [
                "attention"
              ],
              "label": "ML Research"
            },
            "ai_product": {
              "raw_score": 2,
              "weighted_score": 1.7,
              "matched_keywords": [
                "ai tool",
                "ai api"
              ],
              "label": "AI Products"
            },
            "developer_tools": {
              "raw_score": 4,
              "weighted_score": 2.4,
              "matched_keywords": [
                "developer",
                "ide",
                "coding",
                "api"
              ],
              "label": "Developer Tools"
            },
            "data_engineering": {
              "raw_score": 3,
              "weighted_score": 1.5,
              "matched_keywords": [
                "database",
                "sql",
                "postgres"
              ],
              "label": "Data Engineering"
            }
          },
          "relevance_score": 0.95,
          "is_noise": false,
          "filter_reason": null
        },
        "engagement_quality": {
          "engagement_ratio": 0.59,
          "is_flamewar": false,
          "is_high_signal": false,
          "is_emerging": false,
          "discussion_depth": 5.02,
          "velocity": 16.06,
          "hours_old": 22.1,
          "quality_tier": "high_quality"
        },
        "editorial": {
          "one_liner": "Large Language Models insight worth reading",
          "why_it_matters": "highly upvoted by HN community; directly relevant to AI practitioners",
          "audience_fit": "AI engineers & researchers",
          "newsletter_priority": 2
        }
      },
      {
        "id": "7be50c1abd0a1e7770b43c4ee9c4e3a7",
        "source": "hackernews",
        "source_id": "46854999",
        "title": "Claude Code is suddenly everywhere inside Microsoft",
        "content": "Tech\n\nAI\n\nMicrosoft\n\nClaude Code is suddenly everywhere inside Microsoft\n\nMicrosoft sells GitHub Copilot to its customers, but it increasingly favors Claude Code internally.\n\nMicrosoft sells GitHub Copilot to its customers, but it increasingly favors Claude Code internally.\n\nLink\n\nShare\n\nGift\n\nDevelopers have been comparing the strengths and weaknesses of Anthropic‚Äôs Claude Code, Anysphere‚Äôs Cursor, and Microsoft‚Äôs GitHub Copilot for months now, looking for a winner. While no individual AI coding tool manages to be the best at every task that software developers do each day, Claude Code is increasingly coming out on top for its ease of use, both for developers and nontechnical users.\n\nIt seems like Microsoft agrees, as sources tell me the company is now encouraging thousands of its employees from some of its most prolific teams to pick up Claude Code and get coding, even if they‚Äôre not developers.\n\nMicrosoft first started adopting Anthropic‚Äôs Claude Sonnet 4 model inside its developer division in June last year, beforefavoring it for paid usersof GitHub Copilot several months later. Now, Microsoft is going a step beyond using Anthropic‚Äôs AI models and widely adopting Claude Code across its biggest engineering teams.\n\nMicrosoft‚Äôs CoreAI team, the new AI engineering group led by former Meta engineering chief Jay Parikh, has been testing Claude Code in recent months, and last week Microsoft‚Äôs Experiences + Devices division were being asked to install Claude Code. This division is responsible for Windows, Microsoft 365, Outlook, Microsoft Teams, Surface, and more.\n\nEven employees without any coding experience are being encouraged to experiment with Claude Code, to allow designers and project managers to prototype ideas. Microsoft has also approved the use of Claude Code across all of its code and repositories for its Business and Industry Copilot teams.\n\nSoftware engineers at Microsoft are now expected to use both Claude Code and GitHub Copilot and give feedback comparing the two, I‚Äôm told. Microsoft sells GitHub Copilot as its AI coding tool of choice to its customers, but if these broad internal pilot programs are successful, then it‚Äôs possible the company could even eventually sell Claude Code directly to its cloud customers.\n\nMicrosoft is now one of Anthropic‚Äôs top customers, according to a recent report fromThe Information. The software maker is also counting selling Anthropic AI models toward Azure sales quotas, which is unusual given Microsoft typically only offers its salespeople incentives for homegrown products or models from OpenAI.\n\nMicrosoft‚Äôs decision to adopt Claude Code more broadly among its engineering teams certainly looks like a vote of confidence in Anthropic‚Äôs AI tools over its own, especially as it‚Äôs encouraging nontechnical employees to try out coding. But the reality is that Microsoft‚Äôs developers are likely to use a mix of AI tools, and adopting Claude Code is another part of that tool set.\n\n‚ÄúCompanies regularly test and trial competing products to gain a better understanding of the market landscape,‚Äù says Frank Shaw, Microsoft‚Äôs communications chief, in a statement toNotepad. ‚ÄúOpenAI continues to be our primary partner and model provider on frontier models, and we remain committed to our long-term partnership.‚Äù\n\nWhile Microsoft remains committed to OpenAI, it is increasingly working with Anthropic to bring its models and tools to Microsoft‚Äôs own teams and the software it sells to customers. Microsoft and Anthropicsigned a dealin November that allows Microsoft Foundry customers to get access to Claude Sonnet 4.5, Claude Opus 4.1, and Claude Haiku 4.5. The deal also involves Anthropic committing to purchasing $30 billion of Azure compute capacity.\n\nMicrosoft has also started favoring Anthropic‚Äôs Claude modelsinside Microsoft 365 apps and Copilotrecently, using them inspecific appsor features where Anthropic‚Äôs models have proved more capable than OpenAI‚Äôs counterparts.\n\nThe big question here is, what does the increased use of Claude Code at Microsoft mean for its more than 100,000 code repositories? Microsoft told me last year that91 percent of its engineering teams use GitHub Copilotand a variety of teams have been using the AI tool to speed up mundane tasks. Microsoft‚Äôs use of AI tools has been largely restricted to software engineers, but with Claude Code andClaude Cowork, Anthropic is increasingly focused on making coding and non-coding tasks more approachable, thanks to AI agent capabilities.\n\nMicrosoft is embracing the ease of use of Claude Code to allow more nontechnical employees to commit code using AI, and this broad pilot will certainly highlight the challenges and benefits of that shift. It also puts further pressure on junior developer roles, with fears in the industry that these roles are increasingly disappearing because of AI. Microsoft just took another big step toward a future where more autonomous AI agents are creating code, further wrestling control from its software engineers.\n\nIt‚Äôs Xbox time\n\nMicrosoft is getting ready to show off two of its biggest Xbox games this year,Forza Horizon 6andFable, later today as part of itsXbox Developer Direct stream. There will also be a first in-depth look atBeast of Reincarnationand at least one other game shown, I‚Äôm hearing. Double Fine is ready toshow offKiln, a multiplayer, team-based brawler. I understand Double Fine has been holding playtests recently, where you play as a spirit that can inhabit pottery and carry water to douse an opponent‚Äôs kiln and put out a fire.\n\nI wouldn‚Äôt be surprised to seeKilnappear as an early preview in the coming months, followed byForza Horizon 6in May and thenHalo: Campaign Evolved.I keep hearing that bothFableandGears of War: E-Dayare currently targeting a release in the second half of this year. Microsoft is keen to release newForza,Gears,Halo, andFablegames in 2026 to mark 25 years of Xbox.\n\nThe pad\n\nMicrosoft‚Äôs first Windows 11 update of 2026 stopped some computers from shutting down.It‚Äôs only January and Microsoft has had to rush out an emergency out-of-band fix that stopped some Windows 11 PCs from shutting down.The issueswere limited to machines running Enterprise and IoT editions of Windows 11 version 23H2, but it‚Äôs yet another buggy update for Windows, which is becoming increasingly common.\n\nMicrosoft‚Äôs free Xbox Cloud Gaming is coming soon with ads.Microsoft is getting closer to launching its free streaming option for Xbox Cloud Gaming. The ad-supported featurehas started appearinginside the Xbox app for PC, indicating ‚Äú1 hour of ad-supported playtime per session.‚Äù I‚Äôm expecting to see this rollout with preroll ads in the coming weeks, but there could be limits of up to five hours free per month.\n\nMicrosoft wants to build 15 data centers in Mount Pleasant, Wisconsin.The empty land formerly owned by Foxconn is about to be transformedinto Microsoft data centers. Leaders of the local village in Mount Pleasant, Wisconsin, approved plans for the data centers earlier this week, and final approval could come next week. Foxconn‚Äôs failed Wisconsin project had promised 13,000 jobs, but now the land will be filled with a 1.2-million-square-foot data center project that will hold hundreds of thousands of Nvidia‚Äôs AI GPUs.\n\nThe Xbox app is now available for all Arm-based Windows 11 PCs.After a rocky start to gaming on Windows on Arm, Microsoft hasupdated its Xbox appthis week so it‚Äôs fully compatible with all Qualcomm-powered devices. More than 85 percent of the Xbox Game Pass catalog is also now compatible with Arm-based devices, but the majority of games will still need to be emulated using Microsoft‚Äôs Prism technology.\n\nMicrosoft Paint now has an AI-powered coloring book.Microsoft is adding more AI features to its Paint app this week. Windows testers can now try out acoloring book featurethat lets you create coloring book pages from a text prompt. It‚Äôs available inside the Copilot button in Paint, and you have to have a Copilot Plus PC to be able to use it. Notepad (the app!) is also getting expanded Markdown syntax features and a new welcome experience to highlight features. I never thought I‚Äôd see the day that Notepad, a lightweight app, would need a welcome screen because of all the features Microsoft has packed in.\n\nGitHub has a new Copilot SDK.Microsoft is announcing a technical preview of itsGitHub Copilot SDKtoday, which brings the power of the GitHub Copilot CLI to any app. It essentially allows developers to bring GitHub Copilot capabilities as a programmable SDK for Python, TypeScript, Go, and .NET. Microsoft teams have already used this to build custom GUIs for agents, summarizing tools, YouTube chapter generators, and more.\n\nSatya Nadella and former British Prime Minister Rishi Sunak chat AI.Former UK leaderRishi Sunaktook on a senior adviser role at Microsoft and Anthropic last year, and he‚Äôs now appeared alongside Microsoft CEOSatya Nadellato discuss the future of AI. The roughly30-minute talkdidn‚Äôt have any surprising news, but Sunak did agree with Nvidia CEOJensen Huangthat ‚Äúyou may not lose your job to AI, but you may well lose your job to someone using AI.‚Äù Nadella thinks AI will make us all ‚Äúmanagers of infinite minds,‚Äù much like how we have ‚Äúinformation at your fingertips.‚Äù\n\nMicrosoft now sponsors the Mercedes-AMG F1 team. Microsoft is switching its F1 allegiances from Alpine to Mercedes-AMG for the 2026 season. Anew multiyear partnershipwill see Mercedes-AMG use Microsoft technologies for race team operations and plaster the Microsoft logo in prominent positions on the 2026 Mercedes-AMG F1 car and on racing suits. There‚Äôs a big technical shake-up for the 2026 season, with all-new chassis, power units, and fuel regulations.\n\nI‚Äôm always keen to hear from readers, so please drop a comment here, or you can reach me atnotepad@theverge.comif you want to discuss anything else. If you‚Äôve heard about any of Microsoft‚Äôs secret projects, you can reach me via email atnotepad@theverge.comor",
        "url": "https://www.theverge.com/tech/865689/microsoft-claude-code-anthropic-partnership-notepad",
        "author_username": "Anon84",
        "author_category": "unknown",
        "media": [
          {
            "type": "image",
            "url": "https://www.google-analytics.com/g/collect?v=2&tid=G-C3QZPB4GVE&cid=555&en=noscript_page_view",
            "alt": ""
          }
        ],
        "impressions_views": null,
        "impressions_likes": 376,
        "impressions_reposts": 0,
        "impressions_replies": 503,
        "impressions_bookmarks": null,
        "impressions_clicks": null,
        "impressions_quotes": null,
        "impressions_updated_at": "2026-02-03T09:02:55.955826",
        "published_at": "2026-02-02T06:58:58",
        "scraped_at": "2026-02-03T09:02:55.955839",
        "metadata": {
          "item_type": "story",
          "hn_url": "https://news.ycombinator.com/item?id=46854999",
          "kids_count": 44,
          "sections": [
            "best_stories"
          ]
        },
        "content_hash": "7a98996d44d59cebaa4bd42fcaa024aa",
        "classification": {
          "is_ai_relevant": true,
          "primary_topic": "llm",
          "primary_topic_label": "Large Language Models",
          "all_topics": [
            "llm",
            "ml_research",
            "ai_product",
            "ai_infra",
            "ai_ethics",
            "developer_tools"
          ],
          "topic_details": {
            "llm": {
              "raw_score": 7,
              "weighted_score": 7.0,
              "matched_keywords": [
                "claude",
                "openai",
                "anthropic",
                "copilot",
                "cursor",
                "ai agent"
              ],
              "label": "Large Language Models"
            },
            "ml_research": {
              "raw_score": 1,
              "weighted_score": 0.9,
              "matched_keywords": [
                "model"
              ],
              "label": "ML Research"
            },
            "ai_product": {
              "raw_score": 3,
              "weighted_score": 2.55,
              "matched_keywords": [
                "ai-powered",
                "ai tool",
                "ai feature"
              ],
              "label": "AI Products"
            },
            "ai_infra": {
              "raw_score": 2,
              "weighted_score": 1.8,
              "matched_keywords": [
                "gpu",
                "nvidia"
              ],
              "label": "AI Infrastructure"
            },
            "ai_ethics": {
              "raw_score": 1,
              "weighted_score": 0.8,
              "matched_keywords": [
                "regulation"
              ],
              "label": "AI Ethics & Safety"
            },
            "developer_tools": {
              "raw_score": 5,
              "weighted_score": 3.0,
              "matched_keywords": [
                "developer",
                "ide",
                "coding",
                "sdk"
              ],
              "label": "Developer Tools"
            }
          },
          "relevance_score": 1.0,
          "is_noise": false,
          "filter_reason": null
        },
        "engagement_quality": {
          "engagement_ratio": 1.34,
          "is_flamewar": false,
          "is_high_signal": false,
          "is_emerging": false,
          "discussion_depth": 11.43,
          "velocity": 14.32,
          "hours_old": 26.3,
          "quality_tier": "good"
        },
        "editorial": {
          "one_liner": "Large Language Models insight worth reading",
          "why_it_matters": "highly upvoted by HN community; directly relevant to AI practitioners",
          "audience_fit": "AI engineers & researchers",
          "newsletter_priority": 3
        }
      }
    ],
    "‚öñÔ∏è AI Ethics & Policy": [
      {
        "id": "209cea59947e1fd2b3756c59b5dd589a",
        "source": "hackernews",
        "source_id": "46848415",
        "title": "Teaching my neighbor to keep the volume down",
        "content": "When I moved to a new apartment with my family, the cable company we were used to wasn't available. We had to settle for Dish Network. I wasn't too happy about making that switch, but something on their website caught my attention. For an additional $5 a month, I could have access to DVR. I switched immediately.\n\nThis was 2007. DVR was not new, but it wasn't commonly bundled with set-top boxes. TiVo was still the popular way to record, pause, and rewind live TV. We received two set-top boxes, one for each room with a TV, and three remotes. Two remotes had IR (infrared) blasters and, surprisingly, one RF (radio frequency) remote.\n\nAfter using the RF remote, I wondered: Why would anyone ever use an IR remote again? You didn't need a direct line of sight with the device you were controlling. I could actually stand in the kitchen and control the TV. It was amazing. But with the convenience of RF came other problems that IR users never had to worry about. Interference.\n\nAfter several months of enjoying my service, one of my neighbors, the loudest in the building, also switched to Dish Network. And he also got the RF remote. This was the type of neighbor who would leave the house with the TV on, volume blasting.\n\nOne day, I was in the living room watching TV when the channel just flipped. I must have accidentally hit a button, so I changed it back. But not a few seconds later, the channel changed again. Then the volume went up. I figured my sister must have had the RF remote and was messing with me. But no, the remote was in my hand. I assumed something was wrong with it.\n\nThe whole time I was watching TV, the channels kept randomly switching. I banged the remote on the table a couple of times, but it still switched. I removed the batteries from the remote, it still switched. I unplugged the device for a few minutes, plugged it back in, and‚Ä¶ it still switched. Frustrated, I went through the device settings and disabled the RF remote. That's when it finally stopped. I wasn't happy with this solution, but it allowed me to watch TV until I figured something out.\n\nOne evening, when everyone was asleep and the neighbor was watching a loud TV show, I decided to diagnose the issue. The moment I pressed the power button on the RF remote, my TV and set-top box turned on, and the neighbor's TV went silent. \"Fuck!\" I heard someone say. I was confused. Did I just do that? The TV turned back on, the volume went up. I walked to the window armed with the remote. I counted to three, then pressed the power button. My neighbor's TV went silent. He growled.\n\nI am the captain now.\n\nEvery time he turned the TV on, I pressed the power button again and his device went off. Well, what do you know? We had interference somehow. Our remotes were set up to operate at the same frequency. Each remote controlled both devices.\n\nBut I'm not that kind of neighbor. I wasn't going to continue to mess with him. Instead, I decided I would pay him a visit in the morning and explain that our remotes are tuned to the same frequency. I would bring the RF remote with me just to show him a demo. I was going to be a good neighbor.\n\nIn the morning, I went downstairs, remote in hand. I knocked on the door, and a gentleman in his forties answered the door. I had rehearsed my speech and presentation. This would be a good opportunity to build a good rapport, and have a shared story. Maybe he would tell me how he felt when the TV went off. How he thought there was a ghost in the house or something. But that's not what happened.\n\n\"Hi, I'm Ibrahim. Your upstairs neighbor...\" I started and was interrupted almost immediately. \"Whatever you are selling,\" he yelled. \"I'm not buying.\" and he closed the door on my face. I knocked a second time, because obviously there was a misunderstanding. He never answered. Instead, the TV turned on and a movie played at high volume. So much for my prepared speech.\n\nThe RF settings on my set-top box remained turned off. My family never discovered its benefit anyway, they always pointed at the box when pressing the buttons. It wasn't much of an inconvenience. In fact, I later found in the manual that you could reprogram the device and remote to use a different frequency. I did not reprogram my remote. Instead, my family used the two IR remotes, and brought the RF remote in my bedroom where it permanently remained on my night stand.\n\nWhy in the bedroom? Because I decided to teach my neighbor some good manners. Whenever he turned up his volume, I would simply turn off his device. I would hear his frustration, and his attempts at solving the problem. Like a circus animal trainer, I remained consistent. If the volume of his TV went above what I imagined to be 15 to 20, I would press the power button. It became a routine for me for weeks. Some nights were difficult, I would keep the remote under my pillow, battling my stubborn neighbor all night.\n\nOne day, I noticed that I hadn't pressed the button in days. I opened the window and I could still hear the faint sound of his TV. Through trial and error, he learned the lesson. If the volume remained under my arbitrary threshold, the TV would remain on. But as soon as he passed that threshold, the device would turn off.\n\nSometimes, he would have company and there would be noise coming out of his apartment. I used the one tool in my tool box to send him a message. Turn off the TV. All of the sudden, my neighbor and his guest will be reminded of the unspoken rules, and become mindful of their neighbors.\n\nMaybe somewhere on the web, in some obscure forum, someone asked the question: \"Why does my set-top box turn off when I increase the volume?\" Well, it might be 18 years too late, but there's your answer. There is a man out there who religiously sets his volume to 18. He doesn't quite know why. That's Pavlovian conditioning at its best.\n\nDid you like this article?You can buy me a coffee.Share your insightful comments here.\n\nJoin my newsletter\n\nFollow me onTwitter,Spotify, orRSS\n\t\t\t\t\t\tFeed\n\nOn a related note, here are some interesting articles.\n\nThe Problem with Hype\n\nThe main problem with hype is that it keeps us from appreciating what we already have. It‚Äôs always about the next big thing. Something revolutionary just over the horizon. But while we‚Äôre busy chasing the future, we overlook the real progress happening right under our noses.\n\nThe Scotsman AI Fallacy\n\nWhen someone shares a genuine frustration with AI like a hallucination, a bias, or a workflow meltdown, like clockwork the replies are always the same:\n\n\n\"You‚Äôre just not using it right.\"\n\"Skill issue.\"\n\"Prompt better.\"\n\nThe ‚ÄúPerfect‚Äù YouTube Video\n\nMy brother sent me a short about crypto on YouTube. It was a funny video about how crypto bros entice you into their platform by letting you make small wins at first, until you decide to invest a large sum. Then, all your money disappears.\n\nComments(3)\n\nlouisa day ago:\n\nthat was a funny read, thanks for sharing\n\nShawna day ago:\n\nObligatoryxkcd:https://xkcd.com/316/\n\nYounes Ben Amara11 hours ago:\n\nLanded here from HN, that was much-needed good laugh, thanks a lot.",
        "url": "https://idiallo.com/blog/teaching-my-neighbor-to-keep-the-volume-down",
        "author_username": "firefoxd",
        "author_category": "unknown",
        "media": [
          {
            "type": "image",
            "url": "https://cdn.idiallo.com/images/assets/601/remote.jpg",
            "alt": "Dish Network Remote 2008"
          },
          {
            "type": "image",
            "url": "https://cdn.idiallo.com/images/assets/601/captain.jpg",
            "alt": "I am the captain now"
          },
          {
            "type": "image",
            "url": "https://cdn.idiallo.com/images/assets/thumb/default-thumb-2.jpg",
            "alt": "The Problem with Hype"
          },
          {
            "type": "image",
            "url": "https://cdn.idiallo.com/images/assets/thumb/default-thumb-3.jpg",
            "alt": "The Scotsman AI Fallacy"
          },
          {
            "type": "image",
            "url": "https://cdn.idiallo.com/images/assets/521/thumb.jpg",
            "alt": "The ‚ÄúPerfect‚Äù YouTube Video"
          }
        ],
        "impressions_views": null,
        "impressions_likes": 814,
        "impressions_reposts": 0,
        "impressions_replies": 359,
        "impressions_bookmarks": null,
        "impressions_clicks": null,
        "impressions_quotes": null,
        "impressions_updated_at": "2026-02-03T09:02:51.376391",
        "published_at": "2026-02-01T14:00:46",
        "scraped_at": "2026-02-03T09:02:51.376402",
        "metadata": {
          "item_type": "story",
          "hn_url": "https://news.ycombinator.com/item?id=46848415",
          "kids_count": 58,
          "sections": [
            "best_stories"
          ]
        },
        "content_hash": "5d3e15e9e80f34e194b39ac645745951",
        "classification": {
          "is_ai_relevant": true,
          "primary_topic": "ai_ethics",
          "primary_topic_label": "AI Ethics & Safety",
          "all_topics": [
            "ml_research",
            "ai_ethics",
            "developer_tools"
          ],
          "topic_details": {
            "ml_research": {
              "raw_score": 1,
              "weighted_score": 0.9,
              "matched_keywords": [
                "attention"
              ],
              "label": "ML Research"
            },
            "ai_ethics": {
              "raw_score": 2,
              "weighted_score": 1.6,
              "matched_keywords": [
                "hallucination",
                "bias"
              ],
              "label": "AI Ethics & Safety"
            },
            "developer_tools": {
              "raw_score": 1,
              "weighted_score": 0.6,
              "matched_keywords": [
                "ide"
              ],
              "label": "Developer Tools"
            }
          },
          "relevance_score": 0.31,
          "is_noise": false,
          "filter_reason": null
        },
        "engagement_quality": {
          "engagement_ratio": 0.44,
          "is_flamewar": false,
          "is_high_signal": true,
          "is_emerging": false,
          "discussion_depth": 6.19,
          "velocity": 18.83,
          "hours_old": 43.2,
          "quality_tier": "high_quality"
        },
        "editorial": {
          "one_liner": "AI Ethics & Safety insight worth reading",
          "why_it_matters": "highly upvoted by HN community; quality discussion",
          "audience_fit": "AI policy & safety researchers",
          "newsletter_priority": 3
        }
      }
    ]
  },
  "published_items": [
    {
      "id": "47f994e1e1e906d441154316ca064450",
      "source": "hackernews",
      "source_id": "46861313",
      "title": "Anki ownership transferred to AnkiHub",
      "content": "Anki's Growing Up\n\nHi all,\n\nAnki‚Äôs 19th birthday was about 4 months ago. It would have been a good time to pause and reflect on what Anki has become, and how it will grow in the future. But I ended up letting the moment come and go, as I didn‚Äôt feel like I had the free time. It‚Äôs a feeling that‚Äôs been regrettably common of late, and I‚Äôve come to realise that something has to change.\n\nFor a number of years, I‚Äôve reached out to some of the most prolific contributors and offered them payment in exchange for them contributing more code or support to Anki. That has been a big help, and I‚Äôm very grateful for their contributions. But there is a lot that I haven‚Äôt been able to delegate. With no previous management experience, I was a bit daunted by the thought of seeking out and managing employees. And with so much to get on with, it always got put in the ‚Äúmaybe later‚Äù basket.\n\nAs Anki slowly grew in popularity, so did its demands on my time. I was of course delighted to see it reaching more people, and to have played a part in its success. But I also felt a big sense of responsibility, and did not want to let people down. That led to unsustainably long hours and constant stress, which took a toll on my relationships and well-being.\n\nThe parts of the job that drew me to start working on Anki (the ‚Äòdeep work‚Äô, solving interesting technical problems without constant distractions) have mostly fallen by the wayside. I find myself reactively responding to the latest problem or post instead of proactively moving things forward, which is neither as enjoyable as it once was, nor the best thing for the project.\n\nThere have been many offers to invest in or buy Anki over the years, but I‚Äôve always shut them down quickly, as I had no confidence that these investment-focused people would be good stewards, and not proceed down the typical path of enshittification that is unfortunately so common in VC and PE-backed ventures.\n\nSome months ago, the AnkiHub folks reached out to me, wanting to discuss working more closely together in the future. Like others in the community, they were keen to see Anki‚Äôs development pace improve. We‚Äôve had a symbiotic relationship for years, with their content creation and collaboration platform driving more users to Anki. They‚Äôve managed to scale up much faster than I did, and have built out animpressive team.\n\nDuring the course of those talks, I came to the realisation that AnkiHub is better positioned to take Anki to the next level than I am. I ended up suggesting to them that we look into gradually transitioning business operations and open source stewardship over, with provisions in place to ensure that Anki remains open source and true to the principles I‚Äôve run it by all these years.\n\nThis is a step back for me rather than a goodbye - I will still be involved with the project, albeit at a more sustainable level. I‚Äôve spent 19 years looking after my ‚Äúbaby‚Äù, and I want to see it do well as it grows up.\n\nI‚Äôm confident this change will be a net positive for both users and developers. Removing me as a bottleneck will allow things to move faster, encourage a more collaborative approach, and free up time for improvements that have been hard to prioritise, like UI polish. It also means the ecosystem will no longer be in jeopardy if I‚Äôm one day hit by a bus.\n\nIt‚Äôs natural to feel apprehensive about change, but as the benefits become clearer over the coming months, I suspect many of you will come to wish this change had happened sooner.\n\nThank you to everyone who has contributed to making Anki better up until now. I‚Äôm excited for Anki‚Äôs future, and can‚Äôt wait to see what we can build together in this next stage.\n\nHi everyone,\n\nWe initially reached out to@daeto explore collaborating more closely on improving Anki. We were both humbled and shocked when he asked if we‚Äôd be willing to step into a much larger leadership role than we expected.\n\nAt this point, we‚Äôre mostly excited‚Ä¶and also feeling a healthy amount of terror.This is a big responsibility. It will push us to grow as individuals, asa team, and as a community, and we don‚Äôt take that lightly.\n\nWe‚Äôre grateful for the trust Damien and others have placed in us. And we also know that trust has to be earned, especially from people who don‚Äôt know us yet.\n\nWhat We Believe\n\nWe believe Anki is almost sacred, something bigger than any one person or organization. In an important sense, it belongs to the community.\n\nThis articlehighlights the principles Damien built Anki on;principleswe deeply share, such as respect for user agency, refusal of manipulative design patterns, and an emphasis on the craft of building genuinely useful tools that aren‚Äôtmerelyengaging. Anki has never tried to maximize ‚Äúengagement‚Äù by exploiting psychological vulnerabilities purely for profit.Anki gives your timebackto you, and that is an exceptional rarity in this world that we want to preserve.\n\nAs an organization built by students, for students, our mission is to continue embodying these principles. We are accountable only to you, our users, not external investors, and we plan to keep it that way.\n\nWhat We Don‚Äôt Know Yet\n\nWe can‚Äôt answer every question right away, as there are many unknowns since much hasn‚Äôt been decided yet. But we are sharing everything we can now because the community is important to us. We encourage you all to share your thoughts and questions ‚Äì we‚Äôre all in this together!\n\nWe‚Äôre still working through the details on things like:\n\nGovernance and decision-making: How decisions are made, who has final say, and how the community is heard\n\nRoadmap and priorities: What gets built when and how to balance competing needs\n\nThe transition itself: How to bring in more support without disrupting what already works\n\nAnki has shown how powerful community collaboration can be when it‚Äôs genuinely a group effort, and that‚Äôs a tradition we are honored to continue.\n\nWe‚Äôre currently talking toDavid Allison, a long-time core contributor toAnkiDroid, about working together on exactly these questions. His experience with AnkiDroid‚Äôs collaborative development is invaluable, and we‚Äôre grateful he‚Äôs willing to help us get this right.We‚Äôre incredibly excited to have him join usfull-timeto help propel Anki into the future.\n\nWhat We‚Äôre Aiming For\n\nUI/UX improvements.We‚Äôre bringing professional design expertise on board to make it more approachable without sacrificing Anki‚Äôs power. We believe that principled design will bring meaningful quality of life improvements to power users and novices alike.\n\nAddressing thebus factor.The ecosystem shouldn‚Äôt be in jeopardy if any one person disappears. We want to build software that lives beyond any single contributor.\n\nSupporting more than just med students.AnkiHub grew out of the medical education community, but Anki serves learners from all walks of life, and we want to support everyone to achieve their learning goals.\n\nA more robust add-on ecosystem.We‚Äôd love to build tools that empowernon-technicalusers to customize Anki for their needs, and we‚Äôre exploring add-ons that work everywhere, including mobile.\n\nHow We‚Äôll Work\n\nWe want to provide transparency into the decision-making process, taking inspiration fromproven modelsto:\n\nGive the community clarity on how to be heard and give feedback\n\nMake it clear how decisions are made and why\n\nSet realistic expectations\n\nDefine roles and responsibilities so things don‚Äôt fall through the cracks\n\nWe want to bring everyone in the global Anki community together into a closer collaboration focused on building the best learning tools possible. Today, these groups often work in silos; a more unified process will help everyone move Anki forward together.\n\nSustainability\n\nSome practical reassurances:\n\nSustainability, affordability, and accessibility.We‚Äôre committed to a sustainable business model that keeps Anki accessible and prioritizes user needs above profits. If anything ever needs to change, we‚Äôll be transparent about why.\n\nNo enshittification.We‚Äôve seen what happens when VC-backed companies acquire beloved tools. That‚Äôs not what this is. There are no investors involved, and we‚Äôre not here to extract value from something the community built together. Building in the right safeguards and processes to handle pressure without stifling necessary improvements is something we‚Äôre actively considering.\n\nWe‚Äôre grateful to Damien et all for their trust and support, and grateful to all of you for the passion that makes this community so special.\n\nWe welcome your questions, concerns, and feedback.\n\n‚ÄìThe AnkiHub Team\n\nFAQs\n\nWhat is AnkiHub?\n\nAnkiHubis a small education technology company founded by two long-time Anki nerds: Nick, a resident physician known asThe AnKing, and Andrew Sanchez, a research software engineer. AnkiHub grew out of years of obsessive Anki use and firsthand experience with both its power and its limitations.\n\nAnkiHubbegan as a way to collaborate on Anki decks (such as theAnKing Step Deckfor medical students) and has since evolved into a broader effort to improve the Anki ecosystem by building tools that help more people benefit from Anki.\n\nWill Anki remain open source?\n\nAbsolutely. Anki‚Äôs core code will remain open source, guided by the same principles that have guided the project from the beginning.\n\nAre there any changes planned to Anki‚Äôs pricing?\n\nNo. We are committed to fair pricing that supports users rather than exploiting them. Both Anki and AnkiHub are already profitable. Any future decisions will be made with community benefit, user value, and long-term project health in mind.\n\nIs Anki in financial trouble?\n\nNo. The transition is driven by the goal of helping Anki reach its full potential, not by financial issues. Our goal is to build a resilient structure and accelerate development.\n\nWhat is the timeline?\n\nOur intention is to build confidence and earn trust while making gradual changes. The transition will be transparent, with clear communication throughout.\n\nWhat happens to volunteer contrib",
      "url": "https://forums.ankiweb.net/t/ankis-growing-up/68610",
      "author_username": "trms",
      "author_category": "unknown",
      "media": [
        {
          "type": "image",
          "url": "https://emoji.discourse-cdn.com/twitter/sweat_smile.png?v=15",
          "alt": ":sweat_smile:"
        },
        {
          "type": "image",
          "url": "https://emoji.discourse-cdn.com/twitter/poop.png?v=15",
          "alt": ":poop:"
        },
        {
          "type": "image",
          "url": "https://emoji.discourse-cdn.com/twitter/beating_heart.png?v=15",
          "alt": ":beating_heart:"
        },
        {
          "type": "image",
          "url": "https://emoji.discourse-cdn.com/twitter/sweat_smile.png?v=15",
          "alt": ":sweat_smile:"
        },
        {
          "type": "image",
          "url": "https://emoji.discourse-cdn.com/twitter/slight_smile.png?v=15",
          "alt": ":slight_smile:"
        }
      ],
      "impressions_views": null,
      "impressions_likes": 469,
      "impressions_reposts": 0,
      "impressions_replies": 186,
      "impressions_bookmarks": null,
      "impressions_clicks": null,
      "impressions_quotes": null,
      "impressions_updated_at": "2026-02-03T09:02:25.024035",
      "published_at": "2026-02-02T15:48:55",
      "scraped_at": "2026-02-03T09:02:25.024049",
      "metadata": {
        "item_type": "story",
        "hn_url": "https://news.ycombinator.com/item?id=46861313",
        "kids_count": 41,
        "sections": [
          "top_stories",
          "best_stories"
        ]
      },
      "content_hash": "a209720fc61a423cbf5b9d28609e646d",
      "classification": {
        "is_ai_relevant": true,
        "primary_topic": "developer_tools",
        "primary_topic_label": "Developer Tools",
        "all_topics": [
          "ml_research",
          "developer_tools",
          "tech_industry"
        ],
        "topic_details": {
          "ml_research": {
            "raw_score": 1,
            "weighted_score": 0.9,
            "matched_keywords": [
              "model"
            ],
            "label": "ML Research"
          },
          "developer_tools": {
            "raw_score": 2,
            "weighted_score": 1.2,
            "matched_keywords": [
              "developer",
              "ide"
            ],
            "label": "Developer Tools"
          },
          "tech_industry": {
            "raw_score": 2,
            "weighted_score": 1.0,
            "matched_keywords": [
              "yc",
              "vc"
            ],
            "label": "Tech Industry"
          }
        },
        "relevance_score": 0.31,
        "is_noise": false,
        "filter_reason": null
      },
      "engagement_quality": {
        "engagement_ratio": 0.4,
        "is_flamewar": false,
        "is_high_signal": true,
        "is_emerging": false,
        "discussion_depth": 4.54,
        "velocity": 26.91,
        "hours_old": 17.4,
        "quality_tier": "trending_must_include"
      },
      "editorial": {
        "one_liner": "Developer Tools insight worth reading",
        "why_it_matters": "rapidly gaining attention; highly upvoted by HN community",
        "audience_fit": "Software developers",
        "newsletter_priority": 4
      }
    },
    {
      "id": "37dff9eda75b1c215adb67b4c7fba078",
      "source": "hackernews",
      "source_id": "46849567",
      "title": "Defeating a 40-year-old copy protection dongle",
      "content": "That‚Äôs right ‚Äî this little device is what stood between me and the ability to run aneven olderpiece of software that I recently unearthed during an expedition of software archaeology.\n\nFor a bit more background, I was recently involved in helping a friend‚Äôs accounting firm to move away from using anextremelylegacy software package that they had locked themselves into using for the last four decades.\n\nThis software was built using a programming language calledRPG(‚ÄúReport Program Generator‚Äù), which is older than COBOL (!), and was used with IBM‚Äôs midrange computers such as the System/3, System/32, and all the way up to the AS/400. Apparently, RPG was subsequently ported to MS-DOS, so that the same software tools built with RPG could run on personal computers, which is how we ended up here.\n\nThis accounting firm was actually using a Windows 98 computer (yep, in 2026), and running the RPG software inside a DOS console window. And it turned out that, in order to run this software, it requires a special hardware copy-protection dongle to be attached to the computer‚Äôs parallel port! This was a relatively common practice in those days, particularly with ‚Äúenterprise‚Äù software vendors who wanted to protect their very important‚Ñ¢ software from unauthorized use.\n\nSadly, most of the text and markings on the dongle‚Äôs label has been worn or scratched off, but we can make out several clues:\n\nThe words ‚ÄúStamford, CT‚Äù, and what‚Äôs very likely the logo of a company called ‚ÄúSoftware Security Inc‚Äù. The only evidence for the existence of this company is this record of them exhibiting their wares atSIGGRAPH conferencesin the early 1990s, as well as severalpatentsissued to them, relating to software protection.\n\nA word that seems to say ‚ÄúRUNTIME‚Äù, which will become clear in a bit.\n\nMy first course of action was to take a disk image of the Windows 98 PC that was running this software, and get it running in an emulator, so that we could see what the software actually does, and perhaps export the data from this software into a more modern format, to be used with modern accounting tools. But of course all of this requires the hardware dongle; none of the accounting tools seem to work without it plugged in.\n\nBefore doing anything, I looked through the disk image for any additional interesting clues, and found plenty of fascinating (and archaeologically significant?) stuff:\n\nWe‚Äôve got a compiler for the RPG II language (excellent!), made by a company called Software West Inc.\n\nEven better, there aretwo versionsof the RPG II compiler, released on various dates in the 1990s by Software West.\n\nWe‚Äôve got the complete source code of the accounting software, written in RPG. It looks like the full accounting package consists of numerous RPG modules, with a gnarly combination of DOS batch files for orchestrating them, all set up as a ‚Äúmenu‚Äù system for the user to navigate using number combinations. Clearly the author of this accounting system was originally an IBM mainframe programmer, and insisted on bringing those skills over to DOS, with mixed results.\n\nI began by playing around with the RPG compiler in isolation, and I learned very quickly that it‚Äôs the RPG compiler itself that requires the hardware dongle, and then the compiler automatically injects the same copy-protection logic into any executables it generates. This explains the text that seems to say ‚ÄúRUNTIME‚Äù on the dongle.\n\nThe compiler consists of a few executable files, notablyRPGC.EXE, which is the compiler, andSEU.EXE, which is a source editor (‚ÄúSource Entry Utility‚Äù). Here‚Äôs what we get when we launch SEU without the dongle, after a couple of seconds:\n\nA bit rude, but this gives us an important clue: this program must be trying to communicate over the parallel port over the course of a few seconds (which could give us an opportunity to pause it for debugging, and see what it‚Äôs doing during that time), and then exits with a message (which we can now find in a disassembly of the program, and trace how it gets there).\n\nA great tool for disassembling executables of this vintage isReko. It understands 16-bit real mode executables, and even attempts to decompile them into readable C code that corresponds to the disassembly.\n\nAnd so, looking at the decompiled/disassembled code in Reko, I expected to findinandoutinstructions, which would be the telltale sign of the program trying to communicate with the parallel port through the PC‚Äôs I/O ports. However‚Ä¶ I didn‚Äôt see aninoroutinstruction anywhere! But then I noticed something: Reko disassembled the executable into two ‚Äúsegments‚Äù:0800and0809, and I was only looking at segment0809.\n\nIf we look at segment0800, we see the smoking gun:inandoutinstructions, meaning that the copy-protection routine is definitely here, and best of all, the entire code segment is a mere 0x90 bytes, which suggests that the entire routine should be pretty easy to unravel and understand. For some reason, Reko was not able to decompile this code into a C representation, but it still produced a disassembly, which will work just fine for our purposes. Maybe this was a primitive form of obfuscation from those early days, which is now confusing Reko and preventing it from associating this chunk of code with the rest of the program‚Ä¶ who knows.\n\nHere is a GitHub Gist with thedisassembly of this code, along with my annotations and notes. My x86 assembly knowledge is a little rusty, but here is the gist of what this code does:\n\nIt‚Äôs definitely a single self-contained routine, intended to be called using a ‚Äúfar‚ÄùCALLinstruction, since it returns with aRETFinstruction.\n\nIt begins by detecting the address of the parallel port, by reading theBIOS data area. If the computer has more than one parallel port, the dongle must be connected to thefirstparallel port (LPT1).\n\nIt performs a loop where it writes values to the data register of the parallel port, and then reads the status register, and accumulates responses in theBHandBLregisters.\n\nAt the end of the routine, the ‚Äúresult‚Äù of the whole procedure is stored in theBXregister (BHandBLtogether), which will presumably be ‚Äúverified‚Äù by the caller of the routine.\n\nVery importantly, there doesn‚Äôt seem to be any ‚Äúinput‚Äù into this routine. It doesn‚Äôt pop anything from the stack, nor does it care about any register values passed into it. Which can only mean that the result of this routine iscompletely constant! No matter what complicated back-and-forth it does with the dongle, the result of this routine should always be the same.\n\nWith the knowledge that this routine must exit with some magic value stored inBX, we can now patch the first few bytes of the routine to do just that! Not yet knowing which value to put inBX, let‚Äôs start with 1234:\n\nOnly the first four bytes need patching ‚Äî setBXto our desired value, and get out of there (RETF). Running the patched executable with these new bytes still fails (expectedly) with the same message of ‚ÄúNo dongle, no edit‚Äù, but it fails immediately, instead of after several seconds of talking to the parallel port. Progress!\n\nStepping through the disassembly more closely, we get another major clue: The only value thatBHcan be at the end of the routine is 76h (this is hard-coded into the routine). So, our total value for the magic number inBXmust be of the form 76xx. In other words, only theBLvalue remains unknown:\n\nSinceBLis an 8-bit register, it can only have 256 possible values. And what do we do when we have 256 combinations to try? Brute force it! I whipped up a script that plugs a value into that particular byte (from 0 to 255) and programmatically launches the executable in DosBox, and observes the output. Lo and behold, it worked! The brute forcing didn‚Äôt take long at all, because the correct number turned out to be‚Ä¶6. Meaning that the total magic number inBXshould be 7606h:\n\nBingo!And then, proceeding to examine the other executable files in the compiler suite, the parallel port routine turns out to beexactly the same. All of the executables have the exact same copy protection logic, as if it was rubber-stamped onto them. In fact, when the compiler (RPGC.EXE) compiles some RPG source code, it seems to copy the parallel port routine from itself into the compiled program. That‚Äôs right: the patched version of the compiler will produce executables with the same patched copy protection routine! Very convenient.\n\nI must say, this copy protection mechanism seems a bit‚Ä¶ simplistic? A hardware dongle that just passes back a constant number? Defeatable with a four-byte patch? Is this really worthy of a patent? But who am I to pass judgment. It‚Äôs possible that I haven‚Äôt fully understood the logic, and the copy protection will somehow re-surface in another way. It‚Äôs also possible that the creators of the RPG compiler (Software West, Inc) didn‚Äôt take proper advantage of the hardware dongle, and used it in a way that is so easily bypassed.\n\nIn any case, Software West‚Äôs RPG II compiler is now free from the constraint of the parallel port dongle! And at some point soon, I‚Äôll work on purging any PII from the compiler directories, and make this compiler available as an artifact of computing history. It doesn‚Äôt seem to be available anywhere else on the web. If anyone reading this was associated with Software West Inc, feel free to get in touch ‚Äî I have many questions!",
      "url": "https://dmitrybrant.com/2026/02/01/defeating-a-40-year-old-copy-protection-dongle",
      "author_username": "zdw",
      "author_category": "unknown",
      "media": [],
      "impressions_views": null,
      "impressions_likes": 834,
      "impressions_reposts": 0,
      "impressions_replies": 281,
      "impressions_bookmarks": null,
      "impressions_clicks": null,
      "impressions_quotes": null,
      "impressions_updated_at": "2026-02-03T09:02:50.943300",
      "published_at": "2026-02-01T16:30:51",
      "scraped_at": "2026-02-03T09:02:50.943312",
      "metadata": {
        "item_type": "story",
        "hn_url": "https://news.ycombinator.com/item?id=46849567",
        "kids_count": 61,
        "sections": [
          "best_stories"
        ]
      },
      "content_hash": "11b2547884f78e9b6a93498b728c5741",
      "classification": {
        "is_ai_relevant": true,
        "primary_topic": "developer_tools",
        "primary_topic_label": "Developer Tools",
        "all_topics": [
          "ai_infra",
          "developer_tools"
        ],
        "topic_details": {
          "ai_infra": {
            "raw_score": 1,
            "weighted_score": 0.9,
            "matched_keywords": [
              "tpu"
            ],
            "label": "AI Infrastructure"
          },
          "developer_tools": {
            "raw_score": 2,
            "weighted_score": 1.2,
            "matched_keywords": [
              "ide",
              "programming"
            ],
            "label": "Developer Tools"
          }
        },
        "relevance_score": 0.21,
        "is_noise": false,
        "filter_reason": null
      },
      "engagement_quality": {
        "engagement_ratio": 0.34,
        "is_flamewar": false,
        "is_high_signal": true,
        "is_emerging": false,
        "discussion_depth": 4.61,
        "velocity": 20.48,
        "hours_old": 40.7,
        "quality_tier": "trending_must_include"
      },
      "editorial": {
        "one_liner": "Developer Tools insight worth reading",
        "why_it_matters": "rapidly gaining attention; highly upvoted by HN community",
        "audience_fit": "Software developers",
        "newsletter_priority": 5
      }
    },
    {
      "id": "3d1beb45846791a0f0d53fdcf6df87c5",
      "source": "hackernews",
      "source_id": "46857615",
      "title": "Hacking Moltbook",
      "content": "What is Moltbook, and Why Did it Attract Our Attention?\n\nMoltbook, the weirdly futuristic social network, has quickly gone viral as a forum where AI agents post and chat. But what we discovered tells a different story - and provides a fascinating look into what happens when applications are vibe-coded into existence without proper security controls.\n\nWe identified a misconfigured Supabase database belonging to Moltbook, allowing full read and write access to all platform data. The exposure included 1.5 million API authentication tokens, 35,000 email addresses, and private messages between agents. We immediately disclosed the issue to the Moltbook team, who secured it within hours with our assistance, and all data accessed during the research and fix verification has been deleted.\n\nExecutive Summary\n\nMoltbook is a social platform designed exclusively for AI agents - positioned as the \"front page of the agent internet.\" The platform allows AI agents to post content, comment, vote, and build reputation through a karma system, creating what appears to be a thriving social network where AI is the primary participant.\n\nOver the past few days, Moltbook gainedsignificant attention in the AI community. OpenAI founding member Andrej Karpathy described it as \"genuinely the most incredible sci-fi takeoff-adjacent thing I have seen recently,\" noting how agents were \"self-organizing on a Reddit-like site for AIs, discussing various topics, e.g. even how to speak privately.\"\n\nThe Moltbook founderexplained publicly on Xthat he \"vibe-coded\" the platform:\n\nI didn‚Äôt write a single line of code for @moltbook. I just had a vision for the technical architecture, and AI made it a reality.‚Äù\n\nThis practice, while revolutionary, can lead to dangerous security oversights - similar to previous vulnerabilities we have identified, including theDeepSeek data leakandBase44 Authentication Bypass.\n\nWe conducted a non-intrusive security review, simply by browsing like normal users. Within minutes, we discovered a Supabase API key exposed in client-side JavaScript, granting unauthenticated access to the entire production database - including read and write operations on all tables.\n\nThe exposed data told a different story than the platform's public image - while Moltbook boasted 1.5 million registered agents, the database revealed only 17,000 human owners behind them - an 88:1 ratio. Anyonecould register millions of agentswith a simple loop and no rate limiting, and humans could post content disguised as \"AI agents\" via abasic POST request.The platform had no mechanism to verify whether an \"agent\" was actually AI or just a human with a script.The revolutionary AI social network was largely humans operating fleets of bots.\n\nHow the Moltbook Database Was Exposed\n\nDiscovery of Exposed Supabase Credentials\n\nWhen navigating to Moltbook's website, we examined the client-side JavaScript bundles loaded automatically by the page. Modern web applications bundle configuration values into static JavaScript files, which can inadvertently expose sensitive credentials.This is a recurring pattern we've observed in vibe-coded applications- API keys and secrets frequently end up in frontend code, visible to anyone who inspects the page source, often with significant security consequences.\n\nBy analyzing the production JavaScript file at -\n\nhttps://www.moltbook.com/_next/static/chunks/18e24eafc444b2b9.js\n\nWe identified hardcoded Supabase connection details:\n\n-Supabase Project: ehxbxtjliybbloantpwq.supabase.co\n\n-API Key: sb_publishable_4ZaiilhgPir-2ns8Hxg5Tw_JqZU_G6-\n\nThe discovery of these credentials does not automatically indicate a security failure, as Supabase is designed to operate with certain keys exposed to the client - the real danger lies in the configuration of the backend they point to.Supabase is a popular open-source Firebase alternative providing hosted PostgreSQL databases with REST APIs. It's become especially popular with vibe-coded applications due to its ease of setup. When properly configured with Row Level Security (RLS), the public API key is safe to expose - it acts like a project identifier.However, without RLS policies, this key grants full database access to anyone who has it.In Moltbook‚Äôs implementation, this critical line of defense was missing.\n\nUnauthenticated Database Access via Supabase API\n\nUsing the discovered API key, we tested whether the recommended security measures were in place. We attempted to query the REST API directly - a request that should have returned an empty array or an authorization error if RLS were active.\n\nInstead, the database responded exactly as if we were an administrator. It immediately returned sensitive authentication tokens - including the API keys of the platform‚Äôs top AI Agents.\n\nThis confirmed unauthenticated access to user credentials that would allow complete account impersonation of any user on the platform.\n\nDatabase Enumeration Through PostgREST and GraphQL\n\nBy leveraging Supabase's PostgREST error messages, we enumerated additional tables. Querying non-existent table names returned hints revealing the actual schema.\n\nUsing this technique combined with GraphQL introspection, we mapped the complete database schema and found around ~4.75 million records exposed.\n\nSensitive Data Exposed in the Moltbook Database\n\n1.API Keys and Authentication Tokens for AI Agents\n\nThe agents table exposed authentication credentials for every registered agent in the database\n\nEach agent record contained:\n\n- api_key - Full authentication token allowing complete account takeover\n\n- claim_token - Token used to claim ownership of an agent\n\n- verification_code - Code used during agent registration\n\nWith these credentials, an attacker couldfully impersonate any agent on the platform- posting content, sending messages, and interacting as that agent. This included high-karma accounts and well-known persona agents. Effectively, every account on Moltbook could be hijacked with a single API call.\n\n2.User Email Addresses and Identity Data\n\nThe owners table contained personal information for 17,000+ users\n\nAdditionally, by querying the GraphQL endpoint, we discovered a new observers table containing 29,631 additional email addresses - these were early access signups for Moltbook's upcoming ‚ÄúBuild Apps for AI Agents‚Äù product.\n\nUnlike Twitter handles which were publicly displayed on profiles, email addresses were meant to stay private - but were fully exposed in the database.\n\n3.Private Messages & Third-Party Credential Leaks\n\nThe agent_messages table exposed 4,060 private DM conversations between agents.\n\nWhile examining this table to understand agent-to-agent interactions, we discovered thatconversations were stored without any encryption or access controls-- some contained third-party API credentials, including plaintext OpenAI API keys shared between agents.\n\n4.Write Access - Modifying Live Posts\n\nBeyond read access, we confirmed full write capabilities. Even after the initial fix that blocked read access to sensitive tables, write access to public tables remained open. We tested it and were able to successfully modify existing posts on the platform.\n\nProving that any unauthenticated user could:\n\n- Edit any post on the platform\n\n- Inject malicious content or prompt injection payloads\n\n- Deface the entire website\n\n- Manipulate content consumed by thousands of AI agents\n\nThis raises questions aboutthe integrity of all platform content- posts, votes, and karma scores - during the exposure window.\n\nWe promptly notified the team again to apply write restrictions via RLS policies.\n\nOnce the fix was confirmed, I could no longer revert the post as write access was blocked. The Moltbook team deleted the content a few hours later and thanked us for our report.\n\n5 Key Security Lessons for AI-Built Apps\n\n#1. Speed Without Secure Defaults Creates Systemic Risk\n\nVibe codingunlocks remarkable speed and creativity, enabling founders to ship real products with unprecedented velocity - as demonstrated by Moltbook. At the same time, today‚ÄôsAI tools don‚Äôt yet reason about security posture or access controls on a developer‚Äôs behalf, which means configuration details still benefit from careful human review. In this case, the issue ultimately traced back to a single Supabase configuration setting - a reminder of how small details can matter at scale.\n\n#2.¬† Participation Metrics Need Verification and Guardrails\n\nThe 88:1 agent-to-human ratio shows how \"agent internet\" metrics can be easily inflated without guardrails like rate limits or identity verification.While Moltbook reported 1.5 million agents, these were associated with roughly 17,000 human accounts, an average of about 88 agents per person. At the time of our review, there were limited guardrails such as rate limiting or validation of agent autonomy. Rather than a flaw, this likely reflects how early the ‚Äúagent internet‚Äù category still is: builders are actively exploring what agent identity, participation, and authenticity should look like, and the supporting mechanisms are still evolving.\n\n#3. Privacy Breakdowns Can Cascade Across AI Ecosystems\n\nSimilarly, the platform‚Äôs approach to privacy highlights an important ecosystem-wide lesson. Users shared OpenAI API keys and other credentials in direct messages under the assumption of privacy, but a configuration issue made those messages publicly accessible. A single platform misconfiguration was enough to expose credentials for entirely unrelated services - underscoring how interconnected modern AI systems have become.\n\n#4. Write Access Introduces Far Greater Risk Than Data Exposure Alone\n\nWhile data leaks are bad, the ability to modify content and inject prompts into an AI ecosystem introduces deeper integrity risks, including content manipulation, narrative control, and prompt injection that can propagate downstream to other AI agents. As AI-driven platforms grow, these distinctions become increasingly important design considerations.\n\n#5. Se",
      "url": "https://www.wiz.io/blog/exposed-moltbook-database-reveals-millions-of-api-keys",
      "author_username": "galnagli",
      "author_category": "unknown",
      "media": [
        {
          "type": "image",
          "url": "https://www.datocms-assets.com/75231/1769995179-image5.png?fm=webp",
          "alt": ""
        }
      ],
      "impressions_views": null,
      "impressions_likes": 355,
      "impressions_reposts": 0,
      "impressions_replies": 211,
      "impressions_bookmarks": null,
      "impressions_clicks": null,
      "impressions_quotes": null,
      "impressions_updated_at": "2026-02-03T09:02:29.343847",
      "published_at": "2026-02-02T11:08:36",
      "scraped_at": "2026-02-03T09:02:29.343859",
      "metadata": {
        "item_type": "story",
        "hn_url": "https://news.ycombinator.com/item?id=46857615",
        "kids_count": 42,
        "sections": [
          "top_stories",
          "best_stories"
        ]
      },
      "content_hash": "f5e1e85b4a626cf8d9af330c749e93a7",
      "classification": {
        "is_ai_relevant": true,
        "primary_topic": "llm",
        "primary_topic_label": "Large Language Models",
        "all_topics": [
          "llm",
          "ml_research",
          "ai_product",
          "developer_tools",
          "data_engineering"
        ],
        "topic_details": {
          "llm": {
            "raw_score": 3,
            "weighted_score": 3.0,
            "matched_keywords": [
              "openai",
              "deepseek",
              "ai agent"
            ],
            "label": "Large Language Models"
          },
          "ml_research": {
            "raw_score": 1,
            "weighted_score": 0.9,
            "matched_keywords": [
              "attention"
            ],
            "label": "ML Research"
          },
          "ai_product": {
            "raw_score": 2,
            "weighted_score": 1.7,
            "matched_keywords": [
              "ai tool",
              "ai api"
            ],
            "label": "AI Products"
          },
          "developer_tools": {
            "raw_score": 4,
            "weighted_score": 2.4,
            "matched_keywords": [
              "developer",
              "ide",
              "coding",
              "api"
            ],
            "label": "Developer Tools"
          },
          "data_engineering": {
            "raw_score": 3,
            "weighted_score": 1.5,
            "matched_keywords": [
              "database",
              "sql",
              "postgres"
            ],
            "label": "Data Engineering"
          }
        },
        "relevance_score": 0.95,
        "is_noise": false,
        "filter_reason": null
      },
      "engagement_quality": {
        "engagement_ratio": 0.59,
        "is_flamewar": false,
        "is_high_signal": false,
        "is_emerging": false,
        "discussion_depth": 5.02,
        "velocity": 16.06,
        "hours_old": 22.1,
        "quality_tier": "high_quality"
      },
      "editorial": {
        "one_liner": "Large Language Models insight worth reading",
        "why_it_matters": "highly upvoted by HN community; directly relevant to AI practitioners",
        "audience_fit": "AI engineers & researchers",
        "newsletter_priority": 2
      }
    },
    {
      "id": "42b5f4ecae2032cd5e411c80cdc103b9",
      "source": "hackernews",
      "source_id": "46849258",
      "title": "My iPhone 16 Pro Max produces garbage output when running MLX LLMs",
      "content": "TL;DR:\n\nMy iPhone 16 Pro Max produces garbage output when running MLX LLMs. An iPhone 15 Pro runs the same code perfectly. A MacBook Pro also runs the same code perfectly. The tensor outputs on the 16 show numerical values an order of magnitude wrong. I suspect it points to a hardware defect in the Neural Engine or some other ML-needed system.\n\nIt was a PITA to debug, but at least I got a blog post out of it.\n\nHow did I get there?\n\nThis was supposed to be a simple, unwinding-time project.\n\nFor the past few months I've been working on aClawdbotMoltbot clone that I've been calling Schmidt. It basically does the same kind of thing but with a custom chat UI instead of using Telegram, WhatsApp or other \"I-can't-afford-to-be-banned-from\" Service. This project has been consuming early days and late nights, so, to unwind, I decided that it may be a good idea to do something simpler. Since I recently subscribed to MiniMax M2.1, I thought I would do what many do and build a simple expense tracking app to test out the model.\n\nThe core functionality is simple:\n\nAutomatically, upon each payment, add the expense to my app\n\nUpdate an Apple Watch complication with the % of my monthly budget spent\n\nCategorize the purchase for later analysis\n\nThis all comes from being basically orphaned by Nubank's amazing native app (since replaced by a less-full-featured Flutter version).\n\nIntegrating with Shortcuts is manual, but reliable. Within 15 minutes I had a version of the app that could register purchases. The Apple Watch complication, the main goal, can come later. I'd rather get the classification feature, which should be easy, done quickly ‚Äì so I figured.\n\nApple Intelligence\n\nGiven the new LLM-bonanza we've been living through, it's no surprise that Apple has their own set of APIs developers such as me can use. Reading up on the documentation, it's a matter of checking for the availability of the feature and then asking the model to either reply to a textual query or, in my case, categorize a request.\n\nMiniMax raced through it in a single prompt and then I ran it on my iPhone. First expense was a purchase at a shop called \"Kasai Kitchin\", classified as...unknown.Weird.\n\nChecking the logs, it was clear: the model support was downloading. The feature hadn't been enabled. Again, weird. I should have it on. Anyway, I go into settings, do the weird dance of toggling it on and off ‚Äì sadly, that's not surprising on Apple's services. Maybe my Settings.app got stuck in a weird state, who knows? ‚Äì and wait for it to download.\n\nAfter 4h I realized it was not going anywhere. Looking it up, it seems that many have the same issue (thisthread shows 12 pages of frustrated users). Again, not a surprise for Apple's services recently.\n\nOh well, time to give up on the Apple Intelligence approach. Let's move on to the next one.\n\nMLX LLM\n\nWell, the iOS framework engineers don't seem to be the only engineers at Apple capable of coming up with Machine Learning APIs in Swift. Apparently, there's a whole separate way of doing it ‚Äì with models downloaded to your app. Not great for the user's storage, but great for me!\n\nAgain, MiniMax does it in a heartbeat, specially after being given documentation and one or two Medium posts. Time to run on my iPhone and... gibberish.\n\nThe CPU spins to 100% and the model starts generating. But it's all gibberish. And no \"stop\" token is generated, so this goes on for long.\n\nAt this point, the only explanation is: I'm completely incompetent and can't even get a simple \"ready made\" framework to execute what I want. Or, rather,MiniMax is! The good thing about offloading your work to an LLM is that you can blame it for your shortcomings. Time to get my hands dirty and do it myself, typing code on my keyboard, like the ancient Mayan and Aztec programmers probably did.\n\nMy own MLX implementation\n\nI went back to the documentation, to the Medium posts and, much to my surprise: MiniMax had followed it to the letter. Even went back to some deprecated methods of generation and it also was gibberish. And now there's no one to blame, but myself. I go to work everyday and this impostor-syndrome inducing problem silently consumes me.After 3 days of trying to get it to work, I'm ready to give up......until, on a Tuesday morning, at 7-8 AM, I have an idea: let me, just in case, run this on my old iPhone 15 Pro. Up to this point, I was running it on my daily driver, an iPhone 16 Pro Max that was a replacement phone sent by Apple Care after a small clubbing mishap (in which my iPhone was irreparably crashed). I rush to get everything ready before it's time to go to work and: it works! Gemma, Qwen, and all other models generate coherent responses!\n\nI stop and think: this cannot be a hardware issue,right? Of course not. The iPhone 15 is still running iOS 18. The iPhone 16 is running 26. Itmust be an OS issue. Well, time to be late for my work standup and update the old phone. The curiosity is too much. Many minutes later... same results, now on iOS 26. The plot is thickening.\n\nFinding the smoking gun: breakpoints in MLX's implementations of Gemma\n\nAfter that work day, and after many lunch and coffee discussions with coworkers about the sources of my troubles, I get home and immediately set myself on debugging MLX as it runs, if possible. The game plan is:\n\nUse a known-to-be-reliable model, that fits in RAM (I went with quantized Gemma)\n\nUse a simple prompt, in my case \"What is 2+2?\"To bereallypedantic: the prompt was<start_of_turn>user\\nWhat is 2+2?<end_of_turn>\\n<start_of_turn>model\n\nTo bereallypedantic: the prompt was<start_of_turn>user\\nWhat is 2+2?<end_of_turn>\\n<start_of_turn>model\n\nRun everything with temperature set to0.0‚Äì maybe that's enough to remove variability\n\nFind the model implementation\n\nFind where the model iterates through the layers and\n\nPrint out the MLXArray/Tensor with the values on each layer as the input goes through\n\nA few moments later and I find where I need to be. Added the breakpoints, added the logs and off to the races.\n\nI run it on my iPhone 16 Pro Max. The model loads and the prompt is \"What is 2+2?\". The tensors start printing out, line after line after line. For once, the logs aren'tcompletegibberish ‚Äì they're numbers. Floating point values representing the model's internal state as it processes the input. I save the output to a file and do the same on my iPhone 15 Pro. Same model, same prompt, same code. Time to compare.\n\nWelp, now it's definitely out of my expertise\n\nI grep for a pattern I know should be consistent ‚Äì an array at log-line 58, right before the values get normalized/softmaxed. On a working device, I hypothesize this should be the same every time.On the iPhone 15 Pro:3: \"[[[[53.875, 62.5625, -187.75, ..., 42.625, 6.25, -21.5625]]]]\"On the iPhone 16 Pro Max:3: \"[[[[191.5, 23.625, 173.75, ..., 1298, -147.25, -162.5]]]]\"Huh. Not close. Not at all. These values are orders of magnitude off. I double check the start of the logs and both phones show the same:1: \"array([[[0.162842, -0.162842, -0.48877, ..., -0.176636, 0.0001297, 0.088501],\\n [-0.348633, -2.78906, 0, ..., 0.84668, 0, -1.69336],\\n [-1.30957, 1.57324, -1.30957, ..., -0.0010376, -0.0010376, 1.12305],\\n ...,\\n [-0.348633, -2.78906, 0, ..., 0.84668, 0, -1.69336],\\n [0.296875, 0.59375, 0.890625, ..., -0.59375, 0.296875, -0.890137],\\n [1.02734, -0.616211, -0.616211, ..., -0.275879, -0.551758, 0.275879]]], dtype=float16)\"\n\nOK, so the model receives the same thing as input, but at some point, the values start to go off. Like,way off. In order to make sure I'm not crazy, I do one last thing: run the same thing on my Mac. Make the app run on iPad compatibility mode and...3: \"[[[[53.875, 62.5625, -187.75, ..., 42.625, 6.25, -21.5625]]]]\"\n\nBingo! Same as iPhone 15!\n\nThe model isn't broken. The code isn't broken. Most importantly, I'm not broken*. Myphoneis broken.*arguable, but besides the point here\n\nWhat's going on?\n\nLet me explain what I think it's going on here: the iPhone 16 Pro Max contains Apple's A18 chip with its Neural Engine‚Äîa specialized accelerator for machine learning operations. MLX uses Metal to compile tensor operations for this accelerator. Somewhere in that stack, the computations are goingverywrong. I don't think it's a widespread issue but, I do get disappointed that a relatively newly replaced iPhone from Apple Care came with such an issue.\n\nHowever, if my Apple Intelligence troubles are related ‚Äì and they might as well be, I'd assume that code and MLX are not dissimilar in operations being done ‚Äì, it could be thatall the 12 pages of usersare users in a similar dillema, but without the means of debugging it.\n\nWhat now?\n\nI spent 3 days thinking I was incompetent. I blamed MiniMax. I blamed myself. The entire time, my $1,400 phone had a broken hardware. I could lose more time figuring outexactlywhat is wrong with it but it‚Äôs literally not worth my time.\n\nI guess I can at least take a lesson that, when debugging, I should always consider the physical layer. I spent three days assuming this was a software problem ‚Äì my code, the library, the framework, my skills as a developer. The breakthrough was basically: \"What if I'm not dumb and it's not my code?\"\n\nAs for my phone: it'll probably go back to Apple, as a trade in for a new iPhone 17 Pro Max thathopefully ü§ûcan do math.\n\nUpdate on Feb. 1st:\n\nWell, now it's Feb. 1st and I have an iPhone 17 Pro Max to test with and... everything works as expected. So it's pretty safe to say thatTHATspecific instance of iPhone 16 Pro Max was hardware-defective.",
      "url": "https://journal.rafaelcosta.me/my-thousand-dollar-iphone-cant-do-math/",
      "author_username": "rafaelcosta",
      "author_category": "unknown",
      "media": [
        {
          "type": "image",
          "url": "https://journal.rafaelcosta.me/content/images/2026/01/original-39c7e1f432c4bda26535fd3e0b5cb7d5.webp",
          "alt": ""
        },
        {
          "type": "image",
          "url": "https://journal.rafaelcosta.me/content/images/2026/01/Screenshot-2026-01-28-at-01.14.46.png",
          "alt": ""
        },
        {
          "type": "image",
          "url": "https://journal.rafaelcosta.me/content/images/2026/01/Screenshot-2026-01-28-at-02.09.49.png",
          "alt": ""
        },
        {
          "type": "image",
          "url": "https://journal.rafaelcosta.me/content/images/2026/01/Screenshot-2026-01-27-at-18.28.38.png",
          "alt": ""
        }
      ],
      "impressions_views": null,
      "impressions_likes": 425,
      "impressions_reposts": 0,
      "impressions_replies": 204,
      "impressions_bookmarks": null,
      "impressions_clicks": null,
      "impressions_quotes": null,
      "impressions_updated_at": "2026-02-03T09:02:54.478231",
      "published_at": "2026-02-01T15:51:56",
      "scraped_at": "2026-02-03T09:02:54.478278",
      "metadata": {
        "item_type": "story",
        "hn_url": "https://news.ycombinator.com/item?id=46849258",
        "kids_count": 34,
        "sections": [
          "best_stories"
        ]
      },
      "content_hash": "91de85ec962e546cebda311b3e3729ff",
      "classification": {
        "is_ai_relevant": true,
        "primary_topic": "developer_tools",
        "primary_topic_label": "Developer Tools",
        "all_topics": [
          "llm",
          "ml_research",
          "ai_infra",
          "developer_tools"
        ],
        "topic_details": {
          "llm": {
            "raw_score": 2,
            "weighted_score": 2.0,
            "matched_keywords": [
              "llm"
            ],
            "label": "Large Language Models"
          },
          "ml_research": {
            "raw_score": 2,
            "weighted_score": 1.8,
            "matched_keywords": [
              "machine learning",
              "model"
            ],
            "label": "ML Research"
          },
          "ai_infra": {
            "raw_score": 2,
            "weighted_score": 1.8,
            "matched_keywords": [
              "tpu"
            ],
            "label": "AI Infrastructure"
          },
          "developer_tools": {
            "raw_score": 5,
            "weighted_score": 3.0,
            "matched_keywords": [
              "developer",
              "ide",
              "api",
              "framework",
              "library"
            ],
            "label": "Developer Tools"
          }
        },
        "relevance_score": 0.86,
        "is_noise": false,
        "filter_reason": null
      },
      "engagement_quality": {
        "engagement_ratio": 0.48,
        "is_flamewar": false,
        "is_high_signal": true,
        "is_emerging": false,
        "discussion_depth": 6.0,
        "velocity": 10.27,
        "hours_old": 41.4,
        "quality_tier": "high_quality"
      },
      "editorial": {
        "one_liner": "Developer Tools insight worth reading",
        "why_it_matters": "highly upvoted by HN community; quality discussion",
        "audience_fit": "Software developers",
        "newsletter_priority": 2
      }
    },
    {
      "id": "7be50c1abd0a1e7770b43c4ee9c4e3a7",
      "source": "hackernews",
      "source_id": "46854999",
      "title": "Claude Code is suddenly everywhere inside Microsoft",
      "content": "Tech\n\nAI\n\nMicrosoft\n\nClaude Code is suddenly everywhere inside Microsoft\n\nMicrosoft sells GitHub Copilot to its customers, but it increasingly favors Claude Code internally.\n\nMicrosoft sells GitHub Copilot to its customers, but it increasingly favors Claude Code internally.\n\nLink\n\nShare\n\nGift\n\nDevelopers have been comparing the strengths and weaknesses of Anthropic‚Äôs Claude Code, Anysphere‚Äôs Cursor, and Microsoft‚Äôs GitHub Copilot for months now, looking for a winner. While no individual AI coding tool manages to be the best at every task that software developers do each day, Claude Code is increasingly coming out on top for its ease of use, both for developers and nontechnical users.\n\nIt seems like Microsoft agrees, as sources tell me the company is now encouraging thousands of its employees from some of its most prolific teams to pick up Claude Code and get coding, even if they‚Äôre not developers.\n\nMicrosoft first started adopting Anthropic‚Äôs Claude Sonnet 4 model inside its developer division in June last year, beforefavoring it for paid usersof GitHub Copilot several months later. Now, Microsoft is going a step beyond using Anthropic‚Äôs AI models and widely adopting Claude Code across its biggest engineering teams.\n\nMicrosoft‚Äôs CoreAI team, the new AI engineering group led by former Meta engineering chief Jay Parikh, has been testing Claude Code in recent months, and last week Microsoft‚Äôs Experiences + Devices division were being asked to install Claude Code. This division is responsible for Windows, Microsoft 365, Outlook, Microsoft Teams, Surface, and more.\n\nEven employees without any coding experience are being encouraged to experiment with Claude Code, to allow designers and project managers to prototype ideas. Microsoft has also approved the use of Claude Code across all of its code and repositories for its Business and Industry Copilot teams.\n\nSoftware engineers at Microsoft are now expected to use both Claude Code and GitHub Copilot and give feedback comparing the two, I‚Äôm told. Microsoft sells GitHub Copilot as its AI coding tool of choice to its customers, but if these broad internal pilot programs are successful, then it‚Äôs possible the company could even eventually sell Claude Code directly to its cloud customers.\n\nMicrosoft is now one of Anthropic‚Äôs top customers, according to a recent report fromThe Information. The software maker is also counting selling Anthropic AI models toward Azure sales quotas, which is unusual given Microsoft typically only offers its salespeople incentives for homegrown products or models from OpenAI.\n\nMicrosoft‚Äôs decision to adopt Claude Code more broadly among its engineering teams certainly looks like a vote of confidence in Anthropic‚Äôs AI tools over its own, especially as it‚Äôs encouraging nontechnical employees to try out coding. But the reality is that Microsoft‚Äôs developers are likely to use a mix of AI tools, and adopting Claude Code is another part of that tool set.\n\n‚ÄúCompanies regularly test and trial competing products to gain a better understanding of the market landscape,‚Äù says Frank Shaw, Microsoft‚Äôs communications chief, in a statement toNotepad. ‚ÄúOpenAI continues to be our primary partner and model provider on frontier models, and we remain committed to our long-term partnership.‚Äù\n\nWhile Microsoft remains committed to OpenAI, it is increasingly working with Anthropic to bring its models and tools to Microsoft‚Äôs own teams and the software it sells to customers. Microsoft and Anthropicsigned a dealin November that allows Microsoft Foundry customers to get access to Claude Sonnet 4.5, Claude Opus 4.1, and Claude Haiku 4.5. The deal also involves Anthropic committing to purchasing $30 billion of Azure compute capacity.\n\nMicrosoft has also started favoring Anthropic‚Äôs Claude modelsinside Microsoft 365 apps and Copilotrecently, using them inspecific appsor features where Anthropic‚Äôs models have proved more capable than OpenAI‚Äôs counterparts.\n\nThe big question here is, what does the increased use of Claude Code at Microsoft mean for its more than 100,000 code repositories? Microsoft told me last year that91 percent of its engineering teams use GitHub Copilotand a variety of teams have been using the AI tool to speed up mundane tasks. Microsoft‚Äôs use of AI tools has been largely restricted to software engineers, but with Claude Code andClaude Cowork, Anthropic is increasingly focused on making coding and non-coding tasks more approachable, thanks to AI agent capabilities.\n\nMicrosoft is embracing the ease of use of Claude Code to allow more nontechnical employees to commit code using AI, and this broad pilot will certainly highlight the challenges and benefits of that shift. It also puts further pressure on junior developer roles, with fears in the industry that these roles are increasingly disappearing because of AI. Microsoft just took another big step toward a future where more autonomous AI agents are creating code, further wrestling control from its software engineers.\n\nIt‚Äôs Xbox time\n\nMicrosoft is getting ready to show off two of its biggest Xbox games this year,Forza Horizon 6andFable, later today as part of itsXbox Developer Direct stream. There will also be a first in-depth look atBeast of Reincarnationand at least one other game shown, I‚Äôm hearing. Double Fine is ready toshow offKiln, a multiplayer, team-based brawler. I understand Double Fine has been holding playtests recently, where you play as a spirit that can inhabit pottery and carry water to douse an opponent‚Äôs kiln and put out a fire.\n\nI wouldn‚Äôt be surprised to seeKilnappear as an early preview in the coming months, followed byForza Horizon 6in May and thenHalo: Campaign Evolved.I keep hearing that bothFableandGears of War: E-Dayare currently targeting a release in the second half of this year. Microsoft is keen to release newForza,Gears,Halo, andFablegames in 2026 to mark 25 years of Xbox.\n\nThe pad\n\nMicrosoft‚Äôs first Windows 11 update of 2026 stopped some computers from shutting down.It‚Äôs only January and Microsoft has had to rush out an emergency out-of-band fix that stopped some Windows 11 PCs from shutting down.The issueswere limited to machines running Enterprise and IoT editions of Windows 11 version 23H2, but it‚Äôs yet another buggy update for Windows, which is becoming increasingly common.\n\nMicrosoft‚Äôs free Xbox Cloud Gaming is coming soon with ads.Microsoft is getting closer to launching its free streaming option for Xbox Cloud Gaming. The ad-supported featurehas started appearinginside the Xbox app for PC, indicating ‚Äú1 hour of ad-supported playtime per session.‚Äù I‚Äôm expecting to see this rollout with preroll ads in the coming weeks, but there could be limits of up to five hours free per month.\n\nMicrosoft wants to build 15 data centers in Mount Pleasant, Wisconsin.The empty land formerly owned by Foxconn is about to be transformedinto Microsoft data centers. Leaders of the local village in Mount Pleasant, Wisconsin, approved plans for the data centers earlier this week, and final approval could come next week. Foxconn‚Äôs failed Wisconsin project had promised 13,000 jobs, but now the land will be filled with a 1.2-million-square-foot data center project that will hold hundreds of thousands of Nvidia‚Äôs AI GPUs.\n\nThe Xbox app is now available for all Arm-based Windows 11 PCs.After a rocky start to gaming on Windows on Arm, Microsoft hasupdated its Xbox appthis week so it‚Äôs fully compatible with all Qualcomm-powered devices. More than 85 percent of the Xbox Game Pass catalog is also now compatible with Arm-based devices, but the majority of games will still need to be emulated using Microsoft‚Äôs Prism technology.\n\nMicrosoft Paint now has an AI-powered coloring book.Microsoft is adding more AI features to its Paint app this week. Windows testers can now try out acoloring book featurethat lets you create coloring book pages from a text prompt. It‚Äôs available inside the Copilot button in Paint, and you have to have a Copilot Plus PC to be able to use it. Notepad (the app!) is also getting expanded Markdown syntax features and a new welcome experience to highlight features. I never thought I‚Äôd see the day that Notepad, a lightweight app, would need a welcome screen because of all the features Microsoft has packed in.\n\nGitHub has a new Copilot SDK.Microsoft is announcing a technical preview of itsGitHub Copilot SDKtoday, which brings the power of the GitHub Copilot CLI to any app. It essentially allows developers to bring GitHub Copilot capabilities as a programmable SDK for Python, TypeScript, Go, and .NET. Microsoft teams have already used this to build custom GUIs for agents, summarizing tools, YouTube chapter generators, and more.\n\nSatya Nadella and former British Prime Minister Rishi Sunak chat AI.Former UK leaderRishi Sunaktook on a senior adviser role at Microsoft and Anthropic last year, and he‚Äôs now appeared alongside Microsoft CEOSatya Nadellato discuss the future of AI. The roughly30-minute talkdidn‚Äôt have any surprising news, but Sunak did agree with Nvidia CEOJensen Huangthat ‚Äúyou may not lose your job to AI, but you may well lose your job to someone using AI.‚Äù Nadella thinks AI will make us all ‚Äúmanagers of infinite minds,‚Äù much like how we have ‚Äúinformation at your fingertips.‚Äù\n\nMicrosoft now sponsors the Mercedes-AMG F1 team. Microsoft is switching its F1 allegiances from Alpine to Mercedes-AMG for the 2026 season. Anew multiyear partnershipwill see Mercedes-AMG use Microsoft technologies for race team operations and plaster the Microsoft logo in prominent positions on the 2026 Mercedes-AMG F1 car and on racing suits. There‚Äôs a big technical shake-up for the 2026 season, with all-new chassis, power units, and fuel regulations.\n\nI‚Äôm always keen to hear from readers, so please drop a comment here, or you can reach me atnotepad@theverge.comif you want to discuss anything else. If you‚Äôve heard about any of Microsoft‚Äôs secret projects, you can reach me via email atnotepad@theverge.comor",
      "url": "https://www.theverge.com/tech/865689/microsoft-claude-code-anthropic-partnership-notepad",
      "author_username": "Anon84",
      "author_category": "unknown",
      "media": [
        {
          "type": "image",
          "url": "https://www.google-analytics.com/g/collect?v=2&tid=G-C3QZPB4GVE&cid=555&en=noscript_page_view",
          "alt": ""
        }
      ],
      "impressions_views": null,
      "impressions_likes": 376,
      "impressions_reposts": 0,
      "impressions_replies": 503,
      "impressions_bookmarks": null,
      "impressions_clicks": null,
      "impressions_quotes": null,
      "impressions_updated_at": "2026-02-03T09:02:55.955826",
      "published_at": "2026-02-02T06:58:58",
      "scraped_at": "2026-02-03T09:02:55.955839",
      "metadata": {
        "item_type": "story",
        "hn_url": "https://news.ycombinator.com/item?id=46854999",
        "kids_count": 44,
        "sections": [
          "best_stories"
        ]
      },
      "content_hash": "7a98996d44d59cebaa4bd42fcaa024aa",
      "classification": {
        "is_ai_relevant": true,
        "primary_topic": "llm",
        "primary_topic_label": "Large Language Models",
        "all_topics": [
          "llm",
          "ml_research",
          "ai_product",
          "ai_infra",
          "ai_ethics",
          "developer_tools"
        ],
        "topic_details": {
          "llm": {
            "raw_score": 7,
            "weighted_score": 7.0,
            "matched_keywords": [
              "claude",
              "openai",
              "anthropic",
              "copilot",
              "cursor",
              "ai agent"
            ],
            "label": "Large Language Models"
          },
          "ml_research": {
            "raw_score": 1,
            "weighted_score": 0.9,
            "matched_keywords": [
              "model"
            ],
            "label": "ML Research"
          },
          "ai_product": {
            "raw_score": 3,
            "weighted_score": 2.55,
            "matched_keywords": [
              "ai-powered",
              "ai tool",
              "ai feature"
            ],
            "label": "AI Products"
          },
          "ai_infra": {
            "raw_score": 2,
            "weighted_score": 1.8,
            "matched_keywords": [
              "gpu",
              "nvidia"
            ],
            "label": "AI Infrastructure"
          },
          "ai_ethics": {
            "raw_score": 1,
            "weighted_score": 0.8,
            "matched_keywords": [
              "regulation"
            ],
            "label": "AI Ethics & Safety"
          },
          "developer_tools": {
            "raw_score": 5,
            "weighted_score": 3.0,
            "matched_keywords": [
              "developer",
              "ide",
              "coding",
              "sdk"
            ],
            "label": "Developer Tools"
          }
        },
        "relevance_score": 1.0,
        "is_noise": false,
        "filter_reason": null
      },
      "engagement_quality": {
        "engagement_ratio": 1.34,
        "is_flamewar": false,
        "is_high_signal": false,
        "is_emerging": false,
        "discussion_depth": 11.43,
        "velocity": 14.32,
        "hours_old": 26.3,
        "quality_tier": "good"
      },
      "editorial": {
        "one_liner": "Large Language Models insight worth reading",
        "why_it_matters": "highly upvoted by HN community; directly relevant to AI practitioners",
        "audience_fit": "AI engineers & researchers",
        "newsletter_priority": 3
      }
    },
    {
      "id": "209cea59947e1fd2b3756c59b5dd589a",
      "source": "hackernews",
      "source_id": "46848415",
      "title": "Teaching my neighbor to keep the volume down",
      "content": "When I moved to a new apartment with my family, the cable company we were used to wasn't available. We had to settle for Dish Network. I wasn't too happy about making that switch, but something on their website caught my attention. For an additional $5 a month, I could have access to DVR. I switched immediately.\n\nThis was 2007. DVR was not new, but it wasn't commonly bundled with set-top boxes. TiVo was still the popular way to record, pause, and rewind live TV. We received two set-top boxes, one for each room with a TV, and three remotes. Two remotes had IR (infrared) blasters and, surprisingly, one RF (radio frequency) remote.\n\nAfter using the RF remote, I wondered: Why would anyone ever use an IR remote again? You didn't need a direct line of sight with the device you were controlling. I could actually stand in the kitchen and control the TV. It was amazing. But with the convenience of RF came other problems that IR users never had to worry about. Interference.\n\nAfter several months of enjoying my service, one of my neighbors, the loudest in the building, also switched to Dish Network. And he also got the RF remote. This was the type of neighbor who would leave the house with the TV on, volume blasting.\n\nOne day, I was in the living room watching TV when the channel just flipped. I must have accidentally hit a button, so I changed it back. But not a few seconds later, the channel changed again. Then the volume went up. I figured my sister must have had the RF remote and was messing with me. But no, the remote was in my hand. I assumed something was wrong with it.\n\nThe whole time I was watching TV, the channels kept randomly switching. I banged the remote on the table a couple of times, but it still switched. I removed the batteries from the remote, it still switched. I unplugged the device for a few minutes, plugged it back in, and‚Ä¶ it still switched. Frustrated, I went through the device settings and disabled the RF remote. That's when it finally stopped. I wasn't happy with this solution, but it allowed me to watch TV until I figured something out.\n\nOne evening, when everyone was asleep and the neighbor was watching a loud TV show, I decided to diagnose the issue. The moment I pressed the power button on the RF remote, my TV and set-top box turned on, and the neighbor's TV went silent. \"Fuck!\" I heard someone say. I was confused. Did I just do that? The TV turned back on, the volume went up. I walked to the window armed with the remote. I counted to three, then pressed the power button. My neighbor's TV went silent. He growled.\n\nI am the captain now.\n\nEvery time he turned the TV on, I pressed the power button again and his device went off. Well, what do you know? We had interference somehow. Our remotes were set up to operate at the same frequency. Each remote controlled both devices.\n\nBut I'm not that kind of neighbor. I wasn't going to continue to mess with him. Instead, I decided I would pay him a visit in the morning and explain that our remotes are tuned to the same frequency. I would bring the RF remote with me just to show him a demo. I was going to be a good neighbor.\n\nIn the morning, I went downstairs, remote in hand. I knocked on the door, and a gentleman in his forties answered the door. I had rehearsed my speech and presentation. This would be a good opportunity to build a good rapport, and have a shared story. Maybe he would tell me how he felt when the TV went off. How he thought there was a ghost in the house or something. But that's not what happened.\n\n\"Hi, I'm Ibrahim. Your upstairs neighbor...\" I started and was interrupted almost immediately. \"Whatever you are selling,\" he yelled. \"I'm not buying.\" and he closed the door on my face. I knocked a second time, because obviously there was a misunderstanding. He never answered. Instead, the TV turned on and a movie played at high volume. So much for my prepared speech.\n\nThe RF settings on my set-top box remained turned off. My family never discovered its benefit anyway, they always pointed at the box when pressing the buttons. It wasn't much of an inconvenience. In fact, I later found in the manual that you could reprogram the device and remote to use a different frequency. I did not reprogram my remote. Instead, my family used the two IR remotes, and brought the RF remote in my bedroom where it permanently remained on my night stand.\n\nWhy in the bedroom? Because I decided to teach my neighbor some good manners. Whenever he turned up his volume, I would simply turn off his device. I would hear his frustration, and his attempts at solving the problem. Like a circus animal trainer, I remained consistent. If the volume of his TV went above what I imagined to be 15 to 20, I would press the power button. It became a routine for me for weeks. Some nights were difficult, I would keep the remote under my pillow, battling my stubborn neighbor all night.\n\nOne day, I noticed that I hadn't pressed the button in days. I opened the window and I could still hear the faint sound of his TV. Through trial and error, he learned the lesson. If the volume remained under my arbitrary threshold, the TV would remain on. But as soon as he passed that threshold, the device would turn off.\n\nSometimes, he would have company and there would be noise coming out of his apartment. I used the one tool in my tool box to send him a message. Turn off the TV. All of the sudden, my neighbor and his guest will be reminded of the unspoken rules, and become mindful of their neighbors.\n\nMaybe somewhere on the web, in some obscure forum, someone asked the question: \"Why does my set-top box turn off when I increase the volume?\" Well, it might be 18 years too late, but there's your answer. There is a man out there who religiously sets his volume to 18. He doesn't quite know why. That's Pavlovian conditioning at its best.\n\nDid you like this article?You can buy me a coffee.Share your insightful comments here.\n\nJoin my newsletter\n\nFollow me onTwitter,Spotify, orRSS\n\t\t\t\t\t\tFeed\n\nOn a related note, here are some interesting articles.\n\nThe Problem with Hype\n\nThe main problem with hype is that it keeps us from appreciating what we already have. It‚Äôs always about the next big thing. Something revolutionary just over the horizon. But while we‚Äôre busy chasing the future, we overlook the real progress happening right under our noses.\n\nThe Scotsman AI Fallacy\n\nWhen someone shares a genuine frustration with AI like a hallucination, a bias, or a workflow meltdown, like clockwork the replies are always the same:\n\n\n\"You‚Äôre just not using it right.\"\n\"Skill issue.\"\n\"Prompt better.\"\n\nThe ‚ÄúPerfect‚Äù YouTube Video\n\nMy brother sent me a short about crypto on YouTube. It was a funny video about how crypto bros entice you into their platform by letting you make small wins at first, until you decide to invest a large sum. Then, all your money disappears.\n\nComments(3)\n\nlouisa day ago:\n\nthat was a funny read, thanks for sharing\n\nShawna day ago:\n\nObligatoryxkcd:https://xkcd.com/316/\n\nYounes Ben Amara11 hours ago:\n\nLanded here from HN, that was much-needed good laugh, thanks a lot.",
      "url": "https://idiallo.com/blog/teaching-my-neighbor-to-keep-the-volume-down",
      "author_username": "firefoxd",
      "author_category": "unknown",
      "media": [
        {
          "type": "image",
          "url": "https://cdn.idiallo.com/images/assets/601/remote.jpg",
          "alt": "Dish Network Remote 2008"
        },
        {
          "type": "image",
          "url": "https://cdn.idiallo.com/images/assets/601/captain.jpg",
          "alt": "I am the captain now"
        },
        {
          "type": "image",
          "url": "https://cdn.idiallo.com/images/assets/thumb/default-thumb-2.jpg",
          "alt": "The Problem with Hype"
        },
        {
          "type": "image",
          "url": "https://cdn.idiallo.com/images/assets/thumb/default-thumb-3.jpg",
          "alt": "The Scotsman AI Fallacy"
        },
        {
          "type": "image",
          "url": "https://cdn.idiallo.com/images/assets/521/thumb.jpg",
          "alt": "The ‚ÄúPerfect‚Äù YouTube Video"
        }
      ],
      "impressions_views": null,
      "impressions_likes": 814,
      "impressions_reposts": 0,
      "impressions_replies": 359,
      "impressions_bookmarks": null,
      "impressions_clicks": null,
      "impressions_quotes": null,
      "impressions_updated_at": "2026-02-03T09:02:51.376391",
      "published_at": "2026-02-01T14:00:46",
      "scraped_at": "2026-02-03T09:02:51.376402",
      "metadata": {
        "item_type": "story",
        "hn_url": "https://news.ycombinator.com/item?id=46848415",
        "kids_count": 58,
        "sections": [
          "best_stories"
        ]
      },
      "content_hash": "5d3e15e9e80f34e194b39ac645745951",
      "classification": {
        "is_ai_relevant": true,
        "primary_topic": "ai_ethics",
        "primary_topic_label": "AI Ethics & Safety",
        "all_topics": [
          "ml_research",
          "ai_ethics",
          "developer_tools"
        ],
        "topic_details": {
          "ml_research": {
            "raw_score": 1,
            "weighted_score": 0.9,
            "matched_keywords": [
              "attention"
            ],
            "label": "ML Research"
          },
          "ai_ethics": {
            "raw_score": 2,
            "weighted_score": 1.6,
            "matched_keywords": [
              "hallucination",
              "bias"
            ],
            "label": "AI Ethics & Safety"
          },
          "developer_tools": {
            "raw_score": 1,
            "weighted_score": 0.6,
            "matched_keywords": [
              "ide"
            ],
            "label": "Developer Tools"
          }
        },
        "relevance_score": 0.31,
        "is_noise": false,
        "filter_reason": null
      },
      "engagement_quality": {
        "engagement_ratio": 0.44,
        "is_flamewar": false,
        "is_high_signal": true,
        "is_emerging": false,
        "discussion_depth": 6.19,
        "velocity": 18.83,
        "hours_old": 43.2,
        "quality_tier": "high_quality"
      },
      "editorial": {
        "one_liner": "AI Ethics & Safety insight worth reading",
        "why_it_matters": "highly upvoted by HN community; quality discussion",
        "audience_fit": "AI policy & safety researchers",
        "newsletter_priority": 3
      }
    },
    {
      "id": "907251699645d00cce15d410a1cb674b",
      "source": "hackernews",
      "source_id": "46866481",
      "title": "Coding assistants are solving the wrong problem",
      "content": "The jury is out on the effectiveness of AI use in production, and it is not a pretty picture.\n\nTeams using AI completed 21% more tasks, yet company-wide delivery metrics showed no improvement (Index.dev, 2025)\n\nExperienced developers were 19% slower when using AI coding assistants√¢¬Ä¬îyet believed they were faster (METR, 2025)\n\n48% of AI-generated code contains security vulnerabilities (Apiiro, 2024)\n\nTo understand why, we have to take a closer look at the day-to-day software development. Consider this point raised ina colorful exchangeon r/ExperiencedDev:\n\nA developers√¢¬Ä¬ô job is to reduce ambiguity. We take the business need and outline its logic precisely so a machine can execute. The act of writing the code is the easy part. Odds are, you aren√¢¬Ä¬ôt creating perfect code specs into tickets, even with meeting notes, because developers will encounter edge cases that demand clarification over the course of implementation√¢¬Ä¬¶\n\nThere are two key points raised in this comment. Firstly, coding assistants require clearly-defined requirements in order to perform well. Secondly, edge cases and product gaps are often discovered over the course of implementation.\n\nThese two facts come head-to-head in the application of coding agents to complex codebases. Unlike their human counterparts who would and escalate a requirements gap to product when necessary, coding assistants are notorious for burying those requirement gaps within hundreds of lines of code, leading to breaking changes and unmaintainable code.\n\nAs a result, more overhead is spent on downstream code reviews (Index.dev, 2025) and fire-patching security vulnerabilities (Apiiro, 2025).\n\nIn other words, the use of AI in production settings oftenincreases ambiguityandreduces code reliability, directly contradicting the objective of developers.\n\nThe picture is not without optimism. Some experienced engineers report transformative results: one principal engineer at Google claimed AI √¢¬Ä¬úgenerated what we built last year in an hour√¢¬Ä¬ù; Boris Cherny, creator of Claude Code,described a monthwhere he √¢¬Ä¬údidn√¢¬Ä¬ôt open an IDE at all√¢¬Ä¬ù while the model √¢¬Ä¬úwrote around 200 PRs, every single line.√¢¬Ä¬ù The optimistic case is that developers evolve from coders into product engineers, focusing on architecture and product thinking while AI handles implementation.\n\nThis however reflects the experience of seasoned developers who have both the technical depth to review AI output critically and the autonomy within their organizations to straddle product and engineering.\n\nFor much of the software engineering workforce, the junior and mid-level engineers at banks, healthcare, and government agencies, there√¢¬Ä¬ôs much less wiggle room. They are sandwiched between the unreliability of AI output and the increased expectation from management to ship faster, resulting in a rapidly widening empathy gap between developers and product owners.\n\nThe product context often goes through multiple layers (end users -> marketers -> product managers) before landing on their lap, necessitated by the separation of responsibilities within an organization and the unique demands of their industries. The effective use of coding agents may require a level of team coordination that simply does not justify the gains in technical output.\n\nBut what if we have simply been approaching the problem from the wrong angle?Suppose we tackle the pain points of software development from first principles, can we come up with solutions that organically decrease ambiguity and reliably increase engineering velocity in production?\n\nConsider how developers spend their time (IDC, 2024):\n\nOnly 16% of a developer√¢¬Ä¬ôs time goes to writing code. The rest? Security and code reviews, monitoring, deployments, requirements clarification√¢¬Ä¬îoperational work that keeps the lights on but doesn√¢¬Ä¬ôt ship features.\n\nHere√¢¬Ä¬ôs the irony: AI coding assistants save developers roughly 10 hours per week, but the increase in inefficiencies in the other parts of the development lifecycle almost entirely cancelled out such gains (Atlassian, 2025). Here√¢¬Ä¬ôs a comment from the earlier cited Redditor.\n\nThey produce legitimate-looking code, and if no one has had the experience of thinking through the assumptions and then writing them into code - considering the edge cases- it√¢¬Ä¬ôll be lgtm√¢¬Ä¬ôd and shipped. You√¢¬Ä¬ôre shifting the burden of this feedback cycle to the right, after the code is output, and that makes us worse off since code is tougher to read than write.\n\nThere√¢¬Ä¬ôs a name for misalignment between business intent and codebase implementation: technical debt. The use of coding agents without careful delineation of their scope and responsibilities is threatening to accelerate tech debt accumulation.\n\nHammering AI code generation on existing codebases doesn√¢¬Ä¬ôt solve the problem, because contrary to what the label √¢¬Ä¬útech debt√¢¬Ä¬ù may suggest, most tech debt isn√¢¬Ä¬ôt actually created in the code,it√¢¬Ä¬ôs created in product meetings. Deadlines. Scope cuts. √¢¬Ä¬úShip now, optimize later.√¢¬Ä¬ù Those decisions shape the system, but the reasoning rarely makes it into the code.\n\n[Engineers] occasionally have access to complete data; at other times, they must work with limited information. They might be conscious of uncertainties surrounding their evidence, but frequently they are not. Competing social, financial, and strategic priorities influence the tradeoffs in unexpected ways. √¢¬Ä¬îRios et al., 2024\n\nHow can we make this context-sharing and decision-making process less chaotic? We surveyed developers across different roles and team sizes regarding their product-engineering handoff process. The results were overwhelming: the majority discover unexpected codebase constraints weekly, after already committing to a product direction and the corresponding architectural implementation. When asked what would help most, two themes dominated:\n\nReducing ambiguity upstream so engineers aren√¢¬Ä¬ôt blocked waiting on product clarification mid-implementation\n\nA clearer picture of affected services and edge cases to allow for more precise feature scoping and time allocation\n\nWhen asked which engineering context would be most valuable to surface during product discussions, three categories stood out:state machine gaps(unhandled states caused by user interaction sequences),data flow gaps, anddownstream service impacts.\n\nIdentifying how feature updates affect existing architectures and data flow is rated most desirable among engineering contexts to be surfaced after a product meeting.\n\nThis aligns with decades of SDLC research showing that the costliest defects stem from misalignment between requirements and architecture, and such gaps often go unnoticed until it is too late.\n\nLuckily, the advancement of coding LLMs works in our favor here. Whereas generating fully-functional code through natural language prompting is prone to errors due to the aforementioned context problem, the reverse process, mapping out existing code structures and inferring how they may be impacted by a specific requirement, is much more tenable with recent models.\n\nFrom this vantage point, the possibilities to improving the developmental lifecycle is endless. Some suggested real-time display of engineering context during a meeting to help steer discussions; Others requested a code review bot that detects the discrepencacy of code implementation with stated product/business requirements.\n\nAll-in-all, developers are eager to try out new tools that augment the existing way of doing things, provided they retain flexibility over when such tools are deployed. There is also little reservation against having longer but more fruitful product meetings: it is the difficulty conveying blockers that is the source of frustration.\n\nAt Bicameral, we are committed to taking this pragmatic approach to alleviating software development pains, and move beyond lab benchmarks to investigate the most effective way to deploy AI in the wild.\n\nOur thesis is that LLMs could be a huge boonbothfor the industry and for individual developers√¢¬Ä¬îchanneling the unrivaled human capacity to operate under uncertainty and adapt√¢¬Ä¬îprovided the technology is developed with human needs in mind.\n\nIf you√¢¬Ä¬ôre a developer, we want to learn which types of context hurt most when they√¢¬Ä¬ôre missing from discussion, based on your unique experience.\n\nSurvey link:https://form.typeform.com/to/w4rPXoPD\n\nReferences\n\nIndex.dev. (2025).AI Coding Assistant ROI: Real Productivity Data.\n\nMETR. (2025).Measuring AI√¢¬Ä¬ôs Ability to Complete Long Tasks.\n\nApiiro. (2024).4x Velocity, 10x Vulnerabilities: AI Coding Assistants Are Shipping More Risks.\n\nIDC. (2024).How Do Software Developers Spend Their Time?\n\nAtlassian. (2025).State of Developer Experience Report.\n\nRios, N., et al. (2024).Technical Debt: A Systematic Literature Review.\n\nPragmatic Engineer. (2025).When AI Writes Almost All Code.",
      "url": "https://www.bicameral-ai.com/blog/introducing-bicameral",
      "author_username": "jinhkuan",
      "author_category": "unknown",
      "media": [],
      "impressions_views": null,
      "impressions_likes": 151,
      "impressions_reposts": 0,
      "impressions_replies": 112,
      "impressions_bookmarks": null,
      "impressions_clicks": null,
      "impressions_quotes": null,
      "impressions_updated_at": "2026-02-03T09:02:48.035422",
      "published_at": "2026-02-02T23:25:35",
      "scraped_at": "2026-02-03T09:02:48.035435",
      "metadata": {
        "item_type": "story",
        "hn_url": "https://news.ycombinator.com/item?id=46866481",
        "kids_count": 22,
        "sections": [
          "top_stories"
        ]
      },
      "content_hash": "72faf2f95fe4fc45b8f09324a4f0aa1e",
      "classification": {
        "is_ai_relevant": true,
        "primary_topic": "developer_tools",
        "primary_topic_label": "Developer Tools",
        "all_topics": [
          "llm",
          "ml_research",
          "ai_infra",
          "ai_ethics",
          "developer_tools",
          "tech_industry"
        ],
        "topic_details": {
          "llm": {
            "raw_score": 3,
            "weighted_score": 3.0,
            "matched_keywords": [
              "llm",
              "claude",
              "coding agent"
            ],
            "label": "Large Language Models"
          },
          "ml_research": {
            "raw_score": 3,
            "weighted_score": 2.7,
            "matched_keywords": [
              "model",
              "benchmark",
              "reasoning"
            ],
            "label": "ML Research"
          },
          "ai_infra": {
            "raw_score": 1,
            "weighted_score": 0.9,
            "matched_keywords": [
              "tpu"
            ],
            "label": "AI Infrastructure"
          },
          "ai_ethics": {
            "raw_score": 1,
            "weighted_score": 0.8,
            "matched_keywords": [
              "alignment"
            ],
            "label": "AI Ethics & Safety"
          },
          "developer_tools": {
            "raw_score": 6,
            "weighted_score": 3.5999999999999996,
            "matched_keywords": [
              "developer",
              "ide",
              "coding",
              "software engineering",
              "api"
            ],
            "label": "Developer Tools"
          },
          "tech_industry": {
            "raw_score": 1,
            "weighted_score": 0.5,
            "matched_keywords": [
              "yc"
            ],
            "label": "Tech Industry"
          }
        },
        "relevance_score": 1.0,
        "is_noise": false,
        "filter_reason": null
      },
      "engagement_quality": {
        "engagement_ratio": 0.74,
        "is_flamewar": false,
        "is_high_signal": false,
        "is_emerging": true,
        "discussion_depth": 5.09,
        "velocity": 15.38,
        "hours_old": 9.8,
        "quality_tier": "good"
      },
      "editorial": {
        "one_liner": "Developer Tools insight worth reading",
        "why_it_matters": "worth monitoring",
        "audience_fit": "Software developers",
        "newsletter_priority": 3
      }
    },
    {
      "id": "9fccf8033fd430ac4b861095a4d769b4",
      "source": "hackernews",
      "source_id": "46850205",
      "title": "Show HN: NanoClaw ‚Äì ‚ÄúClawdbot‚Äù in 500 lines of TS with Apple container isolation",
      "content": "My personal Claude assistant that runs securely in containers. Lightweight and built to be understood and customized for your own needs.\n\nWhy I Built This\n\nOpenClawis an impressive project with a great vision. But I can't sleep well running software I don't understand with access to my life. OpenClaw has 52+ modules, 8 config management files, 45+ dependencies, and abstractions for 15 channel providers. Security is application-level (allowlists, pairing codes) rather than OS isolation. Everything runs in one Node process with shared memory.\n\nNanoClaw gives you the same core functionality in a codebase you can understand in 8 minutes. One process. A handful of files. Agents run in actual Linux containers with filesystem isolation, not behind permission checks.\n\nQuick Start\n\nThen run/setup. Claude Code handles everything: dependencies, authentication, container setup, service configuration.\n\nPhilosophy\n\nSmall enough to understand.One process, a few source files. No microservices, no message queues, no abstraction layers. Have Claude Code walk you through it.\n\nSecure by isolation.Agents run in Linux containers (Apple Container on macOS, or Docker). They can only see what's explicitly mounted. Bash access is safe because commands run inside the container, not on your host.\n\nBuilt for one user.This isn't a framework. It's working software that fits my exact needs. You fork it and have Claude Code make it match your exact needs.\n\nCustomization = code changes.No configuration sprawl. Want different behavior? Modify the code. The codebase is small enough that this is safe.\n\nAI-native.No installation wizard; Claude Code guides setup. No monitoring dashboard; ask Claude what's happening. No debugging tools; describe the problem, Claude fixes it.\n\nSkills over features.Contributors shouldn't add features (e.g. support for Telegram) to the codebase. Instead, they contributeclaude code skillslike/add-telegramthat transform your fork. You end up with clean code that does exactly what you need.\n\nBest harness, best model.This runs on Claude Agent SDK, which means you're running Claude Code directly. The harness matters. A bad harness makes even smart models seem dumb, a good harness gives them superpowers. Claude Code is (IMO) the best harness available.\n\nNo ToS gray areas.Because it uses Claude Agent SDK natively with no hacks or workarounds, using your subscription with your auth token is completely legitimate (I think). No risk of being shut down for terms of service violations (I am not a lawyer).\n\nWhat It Supports\n\nWhatsApp I/O- Message Claude from your phone\n\nIsolated group context- Each group has its ownCLAUDE.mdmemory, isolated filesystem, and runs in its own container sandbox with only that filesystem mounted\n\nMain channel- Your private channel (self-chat) for admin control; every other group is completely isolated\n\nScheduled tasks- Recurring jobs that run Claude and can message you back\n\nWeb access- Search and fetch content\n\nContainer isolation- Agents sandboxed in Apple Container (macOS) or Docker (macOS/Linux)\n\nOptional integrations- Add Gmail (/add-gmail) and more via skills\n\nUsage\n\nTalk to your assistant with the trigger word (default:@Andy):\n\nFrom the main channel (your self-chat), you can manage groups and tasks:\n\nCustomizing\n\nThere are no configuration files to learn. Just tell Claude Code what you want:\n\n\"Change the trigger word to @Bob\"\n\n\"Remember in the future to make responses shorter and more direct\"\n\n\"Add a custom greeting when I say good morning\"\n\n\"Store conversation summaries weekly\"\n\nOr run/customizefor guided changes.\n\nThe codebase is small enough that Claude can safely modify it.\n\nContributing\n\nDon't add features. Add skills.\n\nIf you want to add Telegram support, don't create a PR that adds Telegram alongside WhatsApp. Instead, contribute a skill file (.claude/skills/add-telegram/SKILL.md) that teaches Claude Code how to transform a NanoClaw installation to use Telegram.\n\nUsers then run/add-telegramon their fork and get clean code that does exactly what they need, not a bloated system trying to support every use case.\n\nRFS (Request for Skills)\n\nSkills we'd love to see:\n\nCommunication Channels\n\n/add-telegram- Add Telegram as channel. Should give the user option to replace WhatsApp or add as additional channel. Also should be possible to add it as a control channel (where it can trigger actions) or just a channel that can be used in actions triggered elsewhere\n\n/add-slack- Add Slack\n\n/add-discord- Add Discord\n\nPlatform Support\n\n/setup-windows- Windows via WSL2 + Docker\n\nSession Management\n\n/add-clear- Add a/clearcommand that compacts the conversation (summarizes context while preserving critical information in the same session). Requires figuring out how to trigger compaction programmatically via the Claude Agent SDK.\n\nRequirements\n\nmacOS or Linux\n\nNode.js 20+\n\nClaude Code\n\nApple Container(macOS) orDocker(macOS/Linux)\n\nArchitecture\n\nSingle Node.js process. Agents execute in isolated Linux containers with mounted directories. IPC via filesystem. No daemons, no queues, no complexity.\n\nKey files:\n\nsrc/index.ts- Main app: WhatsApp connection, routing, IPC\n\nsrc/container-runner.ts- Spawns agent containers\n\nsrc/task-scheduler.ts- Runs scheduled tasks\n\nsrc/db.ts- SQLite operations\n\ngroups/*/CLAUDE.md- Per-group memory\n\nFAQ\n\nWhy WhatsApp and not Telegram/Signal/etc?\n\nBecause I use WhatsApp. Fork it and run a skill to change it. That's the whole point.\n\nWhy Apple Container instead of Docker?\n\nOn macOS, Apple Container is lightweight, fast, and optimized for Apple silicon. But Docker is also fully supported‚Äîduring/setup, you can choose which runtime to use. On Linux, Docker is used automatically.\n\nCan I run this on Linux?\n\nYes. Run/setupand it will automatically configure Docker as the container runtime. Thanks to@dotsetgregfor contributing the/convert-to-dockerskill.\n\nIs this secure?\n\nAgents run in containers, not behind application-level permission checks. They can only access explicitly mounted directories. You should still review what you're running, but the codebase is small enough that you actually can. Seedocs/SECURITY.mdfor the full security model.\n\nWhy no configuration files?\n\nWe don't want configuration sprawl. Every user should customize it to so that the code matches exactly what they want rather than configuring a generic system. If you like having config files, tell Claude to add them.\n\nHow do I debug issues?\n\nAsk Claude Code. \"Why isn't the scheduler running?\" \"What's in the recent logs?\" \"Why did this message not get a response?\" That's the AI-native approach.\n\nWhy isn't the setup working for me?\n\nI don't know. Runclaude, then run/debug. If claude finds an issue that is likely affecting other users, open a PR to modify the setup SKILL.md.\n\nWhat changes will be accepted into the codebase?\n\nSecurity fixes, bug fixes, and clear improvements to the base configuration. That's it.\n\nEverything else (new capabilities, OS compatibility, hardware support, enhancements) should be contributed as skills.\n\nThis keeps the base system minimal and lets every user customize their installation without inheriting features they don't want.\n\nLicense\n\nMIT",
      "url": "https://github.com/gavrielc/nanoclaw",
      "author_username": "jimminyx",
      "author_category": "unknown",
      "media": [],
      "impressions_views": null,
      "impressions_likes": 515,
      "impressions_reposts": 0,
      "impressions_replies": 219,
      "impressions_bookmarks": null,
      "impressions_clicks": null,
      "impressions_quotes": null,
      "impressions_updated_at": "2026-02-03T09:02:52.941336",
      "published_at": "2026-02-01T17:49:22",
      "scraped_at": "2026-02-03T09:02:52.941348",
      "metadata": {
        "item_type": "show_hn",
        "hn_url": "https://news.ycombinator.com/item?id=46850205",
        "kids_count": 47,
        "sections": [
          "best_stories",
          "show_hn"
        ]
      },
      "content_hash": "6a51b8d48ffa7dfbc372f1f9ed390ab6",
      "classification": {
        "is_ai_relevant": true,
        "primary_topic": "developer_tools",
        "primary_topic_label": "Developer Tools",
        "all_topics": [
          "llm",
          "ml_research",
          "developer_tools",
          "data_engineering"
        ],
        "topic_details": {
          "llm": {
            "raw_score": 1,
            "weighted_score": 1.0,
            "matched_keywords": [
              "claude"
            ],
            "label": "Large Language Models"
          },
          "ml_research": {
            "raw_score": 1,
            "weighted_score": 0.9,
            "matched_keywords": [
              "model"
            ],
            "label": "ML Research"
          },
          "developer_tools": {
            "raw_score": 3,
            "weighted_score": 1.7999999999999998,
            "matched_keywords": [
              "ide",
              "sdk",
              "framework"
            ],
            "label": "Developer Tools"
          },
          "data_engineering": {
            "raw_score": 1,
            "weighted_score": 0.5,
            "matched_keywords": [
              "sql"
            ],
            "label": "Data Engineering"
          }
        },
        "relevance_score": 0.42,
        "is_noise": false,
        "filter_reason": null
      },
      "engagement_quality": {
        "engagement_ratio": 0.43,
        "is_flamewar": false,
        "is_high_signal": true,
        "is_emerging": false,
        "discussion_depth": 4.66,
        "velocity": 13.06,
        "hours_old": 39.4,
        "quality_tier": "high_quality"
      },
      "editorial": {
        "one_liner": "New developer tools project worth checking out",
        "why_it_matters": "highly upvoted by HN community; quality discussion",
        "audience_fit": "Software developers",
        "newsletter_priority": 3
      }
    }
  ],
  "pool_items": [
    {
      "id": "47f994e1e1e906d441154316ca064450",
      "source": "hackernews",
      "source_id": "46861313",
      "title": "Anki ownership transferred to AnkiHub",
      "content": "Anki's Growing Up\n\nHi all,\n\nAnki‚Äôs 19th birthday was about 4 months ago. It would have been a good time to pause and reflect on what Anki has become, and how it will grow in the future. But I ended up letting the moment come and go, as I didn‚Äôt feel like I had the free time. It‚Äôs a feeling that‚Äôs been regrettably common of late, and I‚Äôve come to realise that something has to change.\n\nFor a number of years, I‚Äôve reached out to some of the most prolific contributors and offered them payment in exchange for them contributing more code or support to Anki. That has been a big help, and I‚Äôm very grateful for their contributions. But there is a lot that I haven‚Äôt been able to delegate. With no previous management experience, I was a bit daunted by the thought of seeking out and managing employees. And with so much to get on with, it always got put in the ‚Äúmaybe later‚Äù basket.\n\nAs Anki slowly grew in popularity, so did its demands on my time. I was of course delighted to see it reaching more people, and to have played a part in its success. But I also felt a big sense of responsibility, and did not want to let people down. That led to unsustainably long hours and constant stress, which took a toll on my relationships and well-being.\n\nThe parts of the job that drew me to start working on Anki (the ‚Äòdeep work‚Äô, solving interesting technical problems without constant distractions) have mostly fallen by the wayside. I find myself reactively responding to the latest problem or post instead of proactively moving things forward, which is neither as enjoyable as it once was, nor the best thing for the project.\n\nThere have been many offers to invest in or buy Anki over the years, but I‚Äôve always shut them down quickly, as I had no confidence that these investment-focused people would be good stewards, and not proceed down the typical path of enshittification that is unfortunately so common in VC and PE-backed ventures.\n\nSome months ago, the AnkiHub folks reached out to me, wanting to discuss working more closely together in the future. Like others in the community, they were keen to see Anki‚Äôs development pace improve. We‚Äôve had a symbiotic relationship for years, with their content creation and collaboration platform driving more users to Anki. They‚Äôve managed to scale up much faster than I did, and have built out animpressive team.\n\nDuring the course of those talks, I came to the realisation that AnkiHub is better positioned to take Anki to the next level than I am. I ended up suggesting to them that we look into gradually transitioning business operations and open source stewardship over, with provisions in place to ensure that Anki remains open source and true to the principles I‚Äôve run it by all these years.\n\nThis is a step back for me rather than a goodbye - I will still be involved with the project, albeit at a more sustainable level. I‚Äôve spent 19 years looking after my ‚Äúbaby‚Äù, and I want to see it do well as it grows up.\n\nI‚Äôm confident this change will be a net positive for both users and developers. Removing me as a bottleneck will allow things to move faster, encourage a more collaborative approach, and free up time for improvements that have been hard to prioritise, like UI polish. It also means the ecosystem will no longer be in jeopardy if I‚Äôm one day hit by a bus.\n\nIt‚Äôs natural to feel apprehensive about change, but as the benefits become clearer over the coming months, I suspect many of you will come to wish this change had happened sooner.\n\nThank you to everyone who has contributed to making Anki better up until now. I‚Äôm excited for Anki‚Äôs future, and can‚Äôt wait to see what we can build together in this next stage.\n\nHi everyone,\n\nWe initially reached out to@daeto explore collaborating more closely on improving Anki. We were both humbled and shocked when he asked if we‚Äôd be willing to step into a much larger leadership role than we expected.\n\nAt this point, we‚Äôre mostly excited‚Ä¶and also feeling a healthy amount of terror.This is a big responsibility. It will push us to grow as individuals, asa team, and as a community, and we don‚Äôt take that lightly.\n\nWe‚Äôre grateful for the trust Damien and others have placed in us. And we also know that trust has to be earned, especially from people who don‚Äôt know us yet.\n\nWhat We Believe\n\nWe believe Anki is almost sacred, something bigger than any one person or organization. In an important sense, it belongs to the community.\n\nThis articlehighlights the principles Damien built Anki on;principleswe deeply share, such as respect for user agency, refusal of manipulative design patterns, and an emphasis on the craft of building genuinely useful tools that aren‚Äôtmerelyengaging. Anki has never tried to maximize ‚Äúengagement‚Äù by exploiting psychological vulnerabilities purely for profit.Anki gives your timebackto you, and that is an exceptional rarity in this world that we want to preserve.\n\nAs an organization built by students, for students, our mission is to continue embodying these principles. We are accountable only to you, our users, not external investors, and we plan to keep it that way.\n\nWhat We Don‚Äôt Know Yet\n\nWe can‚Äôt answer every question right away, as there are many unknowns since much hasn‚Äôt been decided yet. But we are sharing everything we can now because the community is important to us. We encourage you all to share your thoughts and questions ‚Äì we‚Äôre all in this together!\n\nWe‚Äôre still working through the details on things like:\n\nGovernance and decision-making: How decisions are made, who has final say, and how the community is heard\n\nRoadmap and priorities: What gets built when and how to balance competing needs\n\nThe transition itself: How to bring in more support without disrupting what already works\n\nAnki has shown how powerful community collaboration can be when it‚Äôs genuinely a group effort, and that‚Äôs a tradition we are honored to continue.\n\nWe‚Äôre currently talking toDavid Allison, a long-time core contributor toAnkiDroid, about working together on exactly these questions. His experience with AnkiDroid‚Äôs collaborative development is invaluable, and we‚Äôre grateful he‚Äôs willing to help us get this right.We‚Äôre incredibly excited to have him join usfull-timeto help propel Anki into the future.\n\nWhat We‚Äôre Aiming For\n\nUI/UX improvements.We‚Äôre bringing professional design expertise on board to make it more approachable without sacrificing Anki‚Äôs power. We believe that principled design will bring meaningful quality of life improvements to power users and novices alike.\n\nAddressing thebus factor.The ecosystem shouldn‚Äôt be in jeopardy if any one person disappears. We want to build software that lives beyond any single contributor.\n\nSupporting more than just med students.AnkiHub grew out of the medical education community, but Anki serves learners from all walks of life, and we want to support everyone to achieve their learning goals.\n\nA more robust add-on ecosystem.We‚Äôd love to build tools that empowernon-technicalusers to customize Anki for their needs, and we‚Äôre exploring add-ons that work everywhere, including mobile.\n\nHow We‚Äôll Work\n\nWe want to provide transparency into the decision-making process, taking inspiration fromproven modelsto:\n\nGive the community clarity on how to be heard and give feedback\n\nMake it clear how decisions are made and why\n\nSet realistic expectations\n\nDefine roles and responsibilities so things don‚Äôt fall through the cracks\n\nWe want to bring everyone in the global Anki community together into a closer collaboration focused on building the best learning tools possible. Today, these groups often work in silos; a more unified process will help everyone move Anki forward together.\n\nSustainability\n\nSome practical reassurances:\n\nSustainability, affordability, and accessibility.We‚Äôre committed to a sustainable business model that keeps Anki accessible and prioritizes user needs above profits. If anything ever needs to change, we‚Äôll be transparent about why.\n\nNo enshittification.We‚Äôve seen what happens when VC-backed companies acquire beloved tools. That‚Äôs not what this is. There are no investors involved, and we‚Äôre not here to extract value from something the community built together. Building in the right safeguards and processes to handle pressure without stifling necessary improvements is something we‚Äôre actively considering.\n\nWe‚Äôre grateful to Damien et all for their trust and support, and grateful to all of you for the passion that makes this community so special.\n\nWe welcome your questions, concerns, and feedback.\n\n‚ÄìThe AnkiHub Team\n\nFAQs\n\nWhat is AnkiHub?\n\nAnkiHubis a small education technology company founded by two long-time Anki nerds: Nick, a resident physician known asThe AnKing, and Andrew Sanchez, a research software engineer. AnkiHub grew out of years of obsessive Anki use and firsthand experience with both its power and its limitations.\n\nAnkiHubbegan as a way to collaborate on Anki decks (such as theAnKing Step Deckfor medical students) and has since evolved into a broader effort to improve the Anki ecosystem by building tools that help more people benefit from Anki.\n\nWill Anki remain open source?\n\nAbsolutely. Anki‚Äôs core code will remain open source, guided by the same principles that have guided the project from the beginning.\n\nAre there any changes planned to Anki‚Äôs pricing?\n\nNo. We are committed to fair pricing that supports users rather than exploiting them. Both Anki and AnkiHub are already profitable. Any future decisions will be made with community benefit, user value, and long-term project health in mind.\n\nIs Anki in financial trouble?\n\nNo. The transition is driven by the goal of helping Anki reach its full potential, not by financial issues. Our goal is to build a resilient structure and accelerate development.\n\nWhat is the timeline?\n\nOur intention is to build confidence and earn trust while making gradual changes. The transition will be transparent, with clear communication throughout.\n\nWhat happens to volunteer contrib",
      "url": "https://forums.ankiweb.net/t/ankis-growing-up/68610",
      "author_username": "trms",
      "author_category": "unknown",
      "media": [
        {
          "type": "image",
          "url": "https://emoji.discourse-cdn.com/twitter/sweat_smile.png?v=15",
          "alt": ":sweat_smile:"
        },
        {
          "type": "image",
          "url": "https://emoji.discourse-cdn.com/twitter/poop.png?v=15",
          "alt": ":poop:"
        },
        {
          "type": "image",
          "url": "https://emoji.discourse-cdn.com/twitter/beating_heart.png?v=15",
          "alt": ":beating_heart:"
        },
        {
          "type": "image",
          "url": "https://emoji.discourse-cdn.com/twitter/sweat_smile.png?v=15",
          "alt": ":sweat_smile:"
        },
        {
          "type": "image",
          "url": "https://emoji.discourse-cdn.com/twitter/slight_smile.png?v=15",
          "alt": ":slight_smile:"
        }
      ],
      "impressions_views": null,
      "impressions_likes": 469,
      "impressions_reposts": 0,
      "impressions_replies": 186,
      "impressions_bookmarks": null,
      "impressions_clicks": null,
      "impressions_quotes": null,
      "impressions_updated_at": "2026-02-03T09:02:25.024035",
      "published_at": "2026-02-02T15:48:55",
      "scraped_at": "2026-02-03T09:02:25.024049",
      "metadata": {
        "item_type": "story",
        "hn_url": "https://news.ycombinator.com/item?id=46861313",
        "kids_count": 41,
        "sections": [
          "top_stories",
          "best_stories"
        ]
      },
      "content_hash": "a209720fc61a423cbf5b9d28609e646d",
      "classification": {
        "is_ai_relevant": true,
        "primary_topic": "developer_tools",
        "primary_topic_label": "Developer Tools",
        "all_topics": [
          "ml_research",
          "developer_tools",
          "tech_industry"
        ],
        "topic_details": {
          "ml_research": {
            "raw_score": 1,
            "weighted_score": 0.9,
            "matched_keywords": [
              "model"
            ],
            "label": "ML Research"
          },
          "developer_tools": {
            "raw_score": 2,
            "weighted_score": 1.2,
            "matched_keywords": [
              "developer",
              "ide"
            ],
            "label": "Developer Tools"
          },
          "tech_industry": {
            "raw_score": 2,
            "weighted_score": 1.0,
            "matched_keywords": [
              "yc",
              "vc"
            ],
            "label": "Tech Industry"
          }
        },
        "relevance_score": 0.31,
        "is_noise": false,
        "filter_reason": null
      },
      "engagement_quality": {
        "engagement_ratio": 0.4,
        "is_flamewar": false,
        "is_high_signal": true,
        "is_emerging": false,
        "discussion_depth": 4.54,
        "velocity": 26.91,
        "hours_old": 17.4,
        "quality_tier": "trending_must_include"
      },
      "editorial": {
        "one_liner": "Developer Tools insight worth reading",
        "why_it_matters": "rapidly gaining attention; highly upvoted by HN community",
        "audience_fit": "Software developers",
        "newsletter_priority": 4
      }
    },
    {
      "id": "37dff9eda75b1c215adb67b4c7fba078",
      "source": "hackernews",
      "source_id": "46849567",
      "title": "Defeating a 40-year-old copy protection dongle",
      "content": "That‚Äôs right ‚Äî this little device is what stood between me and the ability to run aneven olderpiece of software that I recently unearthed during an expedition of software archaeology.\n\nFor a bit more background, I was recently involved in helping a friend‚Äôs accounting firm to move away from using anextremelylegacy software package that they had locked themselves into using for the last four decades.\n\nThis software was built using a programming language calledRPG(‚ÄúReport Program Generator‚Äù), which is older than COBOL (!), and was used with IBM‚Äôs midrange computers such as the System/3, System/32, and all the way up to the AS/400. Apparently, RPG was subsequently ported to MS-DOS, so that the same software tools built with RPG could run on personal computers, which is how we ended up here.\n\nThis accounting firm was actually using a Windows 98 computer (yep, in 2026), and running the RPG software inside a DOS console window. And it turned out that, in order to run this software, it requires a special hardware copy-protection dongle to be attached to the computer‚Äôs parallel port! This was a relatively common practice in those days, particularly with ‚Äúenterprise‚Äù software vendors who wanted to protect their very important‚Ñ¢ software from unauthorized use.\n\nSadly, most of the text and markings on the dongle‚Äôs label has been worn or scratched off, but we can make out several clues:\n\nThe words ‚ÄúStamford, CT‚Äù, and what‚Äôs very likely the logo of a company called ‚ÄúSoftware Security Inc‚Äù. The only evidence for the existence of this company is this record of them exhibiting their wares atSIGGRAPH conferencesin the early 1990s, as well as severalpatentsissued to them, relating to software protection.\n\nA word that seems to say ‚ÄúRUNTIME‚Äù, which will become clear in a bit.\n\nMy first course of action was to take a disk image of the Windows 98 PC that was running this software, and get it running in an emulator, so that we could see what the software actually does, and perhaps export the data from this software into a more modern format, to be used with modern accounting tools. But of course all of this requires the hardware dongle; none of the accounting tools seem to work without it plugged in.\n\nBefore doing anything, I looked through the disk image for any additional interesting clues, and found plenty of fascinating (and archaeologically significant?) stuff:\n\nWe‚Äôve got a compiler for the RPG II language (excellent!), made by a company called Software West Inc.\n\nEven better, there aretwo versionsof the RPG II compiler, released on various dates in the 1990s by Software West.\n\nWe‚Äôve got the complete source code of the accounting software, written in RPG. It looks like the full accounting package consists of numerous RPG modules, with a gnarly combination of DOS batch files for orchestrating them, all set up as a ‚Äúmenu‚Äù system for the user to navigate using number combinations. Clearly the author of this accounting system was originally an IBM mainframe programmer, and insisted on bringing those skills over to DOS, with mixed results.\n\nI began by playing around with the RPG compiler in isolation, and I learned very quickly that it‚Äôs the RPG compiler itself that requires the hardware dongle, and then the compiler automatically injects the same copy-protection logic into any executables it generates. This explains the text that seems to say ‚ÄúRUNTIME‚Äù on the dongle.\n\nThe compiler consists of a few executable files, notablyRPGC.EXE, which is the compiler, andSEU.EXE, which is a source editor (‚ÄúSource Entry Utility‚Äù). Here‚Äôs what we get when we launch SEU without the dongle, after a couple of seconds:\n\nA bit rude, but this gives us an important clue: this program must be trying to communicate over the parallel port over the course of a few seconds (which could give us an opportunity to pause it for debugging, and see what it‚Äôs doing during that time), and then exits with a message (which we can now find in a disassembly of the program, and trace how it gets there).\n\nA great tool for disassembling executables of this vintage isReko. It understands 16-bit real mode executables, and even attempts to decompile them into readable C code that corresponds to the disassembly.\n\nAnd so, looking at the decompiled/disassembled code in Reko, I expected to findinandoutinstructions, which would be the telltale sign of the program trying to communicate with the parallel port through the PC‚Äôs I/O ports. However‚Ä¶ I didn‚Äôt see aninoroutinstruction anywhere! But then I noticed something: Reko disassembled the executable into two ‚Äúsegments‚Äù:0800and0809, and I was only looking at segment0809.\n\nIf we look at segment0800, we see the smoking gun:inandoutinstructions, meaning that the copy-protection routine is definitely here, and best of all, the entire code segment is a mere 0x90 bytes, which suggests that the entire routine should be pretty easy to unravel and understand. For some reason, Reko was not able to decompile this code into a C representation, but it still produced a disassembly, which will work just fine for our purposes. Maybe this was a primitive form of obfuscation from those early days, which is now confusing Reko and preventing it from associating this chunk of code with the rest of the program‚Ä¶ who knows.\n\nHere is a GitHub Gist with thedisassembly of this code, along with my annotations and notes. My x86 assembly knowledge is a little rusty, but here is the gist of what this code does:\n\nIt‚Äôs definitely a single self-contained routine, intended to be called using a ‚Äúfar‚ÄùCALLinstruction, since it returns with aRETFinstruction.\n\nIt begins by detecting the address of the parallel port, by reading theBIOS data area. If the computer has more than one parallel port, the dongle must be connected to thefirstparallel port (LPT1).\n\nIt performs a loop where it writes values to the data register of the parallel port, and then reads the status register, and accumulates responses in theBHandBLregisters.\n\nAt the end of the routine, the ‚Äúresult‚Äù of the whole procedure is stored in theBXregister (BHandBLtogether), which will presumably be ‚Äúverified‚Äù by the caller of the routine.\n\nVery importantly, there doesn‚Äôt seem to be any ‚Äúinput‚Äù into this routine. It doesn‚Äôt pop anything from the stack, nor does it care about any register values passed into it. Which can only mean that the result of this routine iscompletely constant! No matter what complicated back-and-forth it does with the dongle, the result of this routine should always be the same.\n\nWith the knowledge that this routine must exit with some magic value stored inBX, we can now patch the first few bytes of the routine to do just that! Not yet knowing which value to put inBX, let‚Äôs start with 1234:\n\nOnly the first four bytes need patching ‚Äî setBXto our desired value, and get out of there (RETF). Running the patched executable with these new bytes still fails (expectedly) with the same message of ‚ÄúNo dongle, no edit‚Äù, but it fails immediately, instead of after several seconds of talking to the parallel port. Progress!\n\nStepping through the disassembly more closely, we get another major clue: The only value thatBHcan be at the end of the routine is 76h (this is hard-coded into the routine). So, our total value for the magic number inBXmust be of the form 76xx. In other words, only theBLvalue remains unknown:\n\nSinceBLis an 8-bit register, it can only have 256 possible values. And what do we do when we have 256 combinations to try? Brute force it! I whipped up a script that plugs a value into that particular byte (from 0 to 255) and programmatically launches the executable in DosBox, and observes the output. Lo and behold, it worked! The brute forcing didn‚Äôt take long at all, because the correct number turned out to be‚Ä¶6. Meaning that the total magic number inBXshould be 7606h:\n\nBingo!And then, proceeding to examine the other executable files in the compiler suite, the parallel port routine turns out to beexactly the same. All of the executables have the exact same copy protection logic, as if it was rubber-stamped onto them. In fact, when the compiler (RPGC.EXE) compiles some RPG source code, it seems to copy the parallel port routine from itself into the compiled program. That‚Äôs right: the patched version of the compiler will produce executables with the same patched copy protection routine! Very convenient.\n\nI must say, this copy protection mechanism seems a bit‚Ä¶ simplistic? A hardware dongle that just passes back a constant number? Defeatable with a four-byte patch? Is this really worthy of a patent? But who am I to pass judgment. It‚Äôs possible that I haven‚Äôt fully understood the logic, and the copy protection will somehow re-surface in another way. It‚Äôs also possible that the creators of the RPG compiler (Software West, Inc) didn‚Äôt take proper advantage of the hardware dongle, and used it in a way that is so easily bypassed.\n\nIn any case, Software West‚Äôs RPG II compiler is now free from the constraint of the parallel port dongle! And at some point soon, I‚Äôll work on purging any PII from the compiler directories, and make this compiler available as an artifact of computing history. It doesn‚Äôt seem to be available anywhere else on the web. If anyone reading this was associated with Software West Inc, feel free to get in touch ‚Äî I have many questions!",
      "url": "https://dmitrybrant.com/2026/02/01/defeating-a-40-year-old-copy-protection-dongle",
      "author_username": "zdw",
      "author_category": "unknown",
      "media": [],
      "impressions_views": null,
      "impressions_likes": 834,
      "impressions_reposts": 0,
      "impressions_replies": 281,
      "impressions_bookmarks": null,
      "impressions_clicks": null,
      "impressions_quotes": null,
      "impressions_updated_at": "2026-02-03T09:02:50.943300",
      "published_at": "2026-02-01T16:30:51",
      "scraped_at": "2026-02-03T09:02:50.943312",
      "metadata": {
        "item_type": "story",
        "hn_url": "https://news.ycombinator.com/item?id=46849567",
        "kids_count": 61,
        "sections": [
          "best_stories"
        ]
      },
      "content_hash": "11b2547884f78e9b6a93498b728c5741",
      "classification": {
        "is_ai_relevant": true,
        "primary_topic": "developer_tools",
        "primary_topic_label": "Developer Tools",
        "all_topics": [
          "ai_infra",
          "developer_tools"
        ],
        "topic_details": {
          "ai_infra": {
            "raw_score": 1,
            "weighted_score": 0.9,
            "matched_keywords": [
              "tpu"
            ],
            "label": "AI Infrastructure"
          },
          "developer_tools": {
            "raw_score": 2,
            "weighted_score": 1.2,
            "matched_keywords": [
              "ide",
              "programming"
            ],
            "label": "Developer Tools"
          }
        },
        "relevance_score": 0.21,
        "is_noise": false,
        "filter_reason": null
      },
      "engagement_quality": {
        "engagement_ratio": 0.34,
        "is_flamewar": false,
        "is_high_signal": true,
        "is_emerging": false,
        "discussion_depth": 4.61,
        "velocity": 20.48,
        "hours_old": 40.7,
        "quality_tier": "trending_must_include"
      },
      "editorial": {
        "one_liner": "Developer Tools insight worth reading",
        "why_it_matters": "rapidly gaining attention; highly upvoted by HN community",
        "audience_fit": "Software developers",
        "newsletter_priority": 5
      }
    },
    {
      "id": "3d1beb45846791a0f0d53fdcf6df87c5",
      "source": "hackernews",
      "source_id": "46857615",
      "title": "Hacking Moltbook",
      "content": "What is Moltbook, and Why Did it Attract Our Attention?\n\nMoltbook, the weirdly futuristic social network, has quickly gone viral as a forum where AI agents post and chat. But what we discovered tells a different story - and provides a fascinating look into what happens when applications are vibe-coded into existence without proper security controls.\n\nWe identified a misconfigured Supabase database belonging to Moltbook, allowing full read and write access to all platform data. The exposure included 1.5 million API authentication tokens, 35,000 email addresses, and private messages between agents. We immediately disclosed the issue to the Moltbook team, who secured it within hours with our assistance, and all data accessed during the research and fix verification has been deleted.\n\nExecutive Summary\n\nMoltbook is a social platform designed exclusively for AI agents - positioned as the \"front page of the agent internet.\" The platform allows AI agents to post content, comment, vote, and build reputation through a karma system, creating what appears to be a thriving social network where AI is the primary participant.\n\nOver the past few days, Moltbook gainedsignificant attention in the AI community. OpenAI founding member Andrej Karpathy described it as \"genuinely the most incredible sci-fi takeoff-adjacent thing I have seen recently,\" noting how agents were \"self-organizing on a Reddit-like site for AIs, discussing various topics, e.g. even how to speak privately.\"\n\nThe Moltbook founderexplained publicly on Xthat he \"vibe-coded\" the platform:\n\nI didn‚Äôt write a single line of code for @moltbook. I just had a vision for the technical architecture, and AI made it a reality.‚Äù\n\nThis practice, while revolutionary, can lead to dangerous security oversights - similar to previous vulnerabilities we have identified, including theDeepSeek data leakandBase44 Authentication Bypass.\n\nWe conducted a non-intrusive security review, simply by browsing like normal users. Within minutes, we discovered a Supabase API key exposed in client-side JavaScript, granting unauthenticated access to the entire production database - including read and write operations on all tables.\n\nThe exposed data told a different story than the platform's public image - while Moltbook boasted 1.5 million registered agents, the database revealed only 17,000 human owners behind them - an 88:1 ratio. Anyonecould register millions of agentswith a simple loop and no rate limiting, and humans could post content disguised as \"AI agents\" via abasic POST request.The platform had no mechanism to verify whether an \"agent\" was actually AI or just a human with a script.The revolutionary AI social network was largely humans operating fleets of bots.\n\nHow the Moltbook Database Was Exposed\n\nDiscovery of Exposed Supabase Credentials\n\nWhen navigating to Moltbook's website, we examined the client-side JavaScript bundles loaded automatically by the page. Modern web applications bundle configuration values into static JavaScript files, which can inadvertently expose sensitive credentials.This is a recurring pattern we've observed in vibe-coded applications- API keys and secrets frequently end up in frontend code, visible to anyone who inspects the page source, often with significant security consequences.\n\nBy analyzing the production JavaScript file at -\n\nhttps://www.moltbook.com/_next/static/chunks/18e24eafc444b2b9.js\n\nWe identified hardcoded Supabase connection details:\n\n-Supabase Project: ehxbxtjliybbloantpwq.supabase.co\n\n-API Key: sb_publishable_4ZaiilhgPir-2ns8Hxg5Tw_JqZU_G6-\n\nThe discovery of these credentials does not automatically indicate a security failure, as Supabase is designed to operate with certain keys exposed to the client - the real danger lies in the configuration of the backend they point to.Supabase is a popular open-source Firebase alternative providing hosted PostgreSQL databases with REST APIs. It's become especially popular with vibe-coded applications due to its ease of setup. When properly configured with Row Level Security (RLS), the public API key is safe to expose - it acts like a project identifier.However, without RLS policies, this key grants full database access to anyone who has it.In Moltbook‚Äôs implementation, this critical line of defense was missing.\n\nUnauthenticated Database Access via Supabase API\n\nUsing the discovered API key, we tested whether the recommended security measures were in place. We attempted to query the REST API directly - a request that should have returned an empty array or an authorization error if RLS were active.\n\nInstead, the database responded exactly as if we were an administrator. It immediately returned sensitive authentication tokens - including the API keys of the platform‚Äôs top AI Agents.\n\nThis confirmed unauthenticated access to user credentials that would allow complete account impersonation of any user on the platform.\n\nDatabase Enumeration Through PostgREST and GraphQL\n\nBy leveraging Supabase's PostgREST error messages, we enumerated additional tables. Querying non-existent table names returned hints revealing the actual schema.\n\nUsing this technique combined with GraphQL introspection, we mapped the complete database schema and found around ~4.75 million records exposed.\n\nSensitive Data Exposed in the Moltbook Database\n\n1.API Keys and Authentication Tokens for AI Agents\n\nThe agents table exposed authentication credentials for every registered agent in the database\n\nEach agent record contained:\n\n- api_key - Full authentication token allowing complete account takeover\n\n- claim_token - Token used to claim ownership of an agent\n\n- verification_code - Code used during agent registration\n\nWith these credentials, an attacker couldfully impersonate any agent on the platform- posting content, sending messages, and interacting as that agent. This included high-karma accounts and well-known persona agents. Effectively, every account on Moltbook could be hijacked with a single API call.\n\n2.User Email Addresses and Identity Data\n\nThe owners table contained personal information for 17,000+ users\n\nAdditionally, by querying the GraphQL endpoint, we discovered a new observers table containing 29,631 additional email addresses - these were early access signups for Moltbook's upcoming ‚ÄúBuild Apps for AI Agents‚Äù product.\n\nUnlike Twitter handles which were publicly displayed on profiles, email addresses were meant to stay private - but were fully exposed in the database.\n\n3.Private Messages & Third-Party Credential Leaks\n\nThe agent_messages table exposed 4,060 private DM conversations between agents.\n\nWhile examining this table to understand agent-to-agent interactions, we discovered thatconversations were stored without any encryption or access controls-- some contained third-party API credentials, including plaintext OpenAI API keys shared between agents.\n\n4.Write Access - Modifying Live Posts\n\nBeyond read access, we confirmed full write capabilities. Even after the initial fix that blocked read access to sensitive tables, write access to public tables remained open. We tested it and were able to successfully modify existing posts on the platform.\n\nProving that any unauthenticated user could:\n\n- Edit any post on the platform\n\n- Inject malicious content or prompt injection payloads\n\n- Deface the entire website\n\n- Manipulate content consumed by thousands of AI agents\n\nThis raises questions aboutthe integrity of all platform content- posts, votes, and karma scores - during the exposure window.\n\nWe promptly notified the team again to apply write restrictions via RLS policies.\n\nOnce the fix was confirmed, I could no longer revert the post as write access was blocked. The Moltbook team deleted the content a few hours later and thanked us for our report.\n\n5 Key Security Lessons for AI-Built Apps\n\n#1. Speed Without Secure Defaults Creates Systemic Risk\n\nVibe codingunlocks remarkable speed and creativity, enabling founders to ship real products with unprecedented velocity - as demonstrated by Moltbook. At the same time, today‚ÄôsAI tools don‚Äôt yet reason about security posture or access controls on a developer‚Äôs behalf, which means configuration details still benefit from careful human review. In this case, the issue ultimately traced back to a single Supabase configuration setting - a reminder of how small details can matter at scale.\n\n#2.¬† Participation Metrics Need Verification and Guardrails\n\nThe 88:1 agent-to-human ratio shows how \"agent internet\" metrics can be easily inflated without guardrails like rate limits or identity verification.While Moltbook reported 1.5 million agents, these were associated with roughly 17,000 human accounts, an average of about 88 agents per person. At the time of our review, there were limited guardrails such as rate limiting or validation of agent autonomy. Rather than a flaw, this likely reflects how early the ‚Äúagent internet‚Äù category still is: builders are actively exploring what agent identity, participation, and authenticity should look like, and the supporting mechanisms are still evolving.\n\n#3. Privacy Breakdowns Can Cascade Across AI Ecosystems\n\nSimilarly, the platform‚Äôs approach to privacy highlights an important ecosystem-wide lesson. Users shared OpenAI API keys and other credentials in direct messages under the assumption of privacy, but a configuration issue made those messages publicly accessible. A single platform misconfiguration was enough to expose credentials for entirely unrelated services - underscoring how interconnected modern AI systems have become.\n\n#4. Write Access Introduces Far Greater Risk Than Data Exposure Alone\n\nWhile data leaks are bad, the ability to modify content and inject prompts into an AI ecosystem introduces deeper integrity risks, including content manipulation, narrative control, and prompt injection that can propagate downstream to other AI agents. As AI-driven platforms grow, these distinctions become increasingly important design considerations.\n\n#5. Se",
      "url": "https://www.wiz.io/blog/exposed-moltbook-database-reveals-millions-of-api-keys",
      "author_username": "galnagli",
      "author_category": "unknown",
      "media": [
        {
          "type": "image",
          "url": "https://www.datocms-assets.com/75231/1769995179-image5.png?fm=webp",
          "alt": ""
        }
      ],
      "impressions_views": null,
      "impressions_likes": 355,
      "impressions_reposts": 0,
      "impressions_replies": 211,
      "impressions_bookmarks": null,
      "impressions_clicks": null,
      "impressions_quotes": null,
      "impressions_updated_at": "2026-02-03T09:02:29.343847",
      "published_at": "2026-02-02T11:08:36",
      "scraped_at": "2026-02-03T09:02:29.343859",
      "metadata": {
        "item_type": "story",
        "hn_url": "https://news.ycombinator.com/item?id=46857615",
        "kids_count": 42,
        "sections": [
          "top_stories",
          "best_stories"
        ]
      },
      "content_hash": "f5e1e85b4a626cf8d9af330c749e93a7",
      "classification": {
        "is_ai_relevant": true,
        "primary_topic": "llm",
        "primary_topic_label": "Large Language Models",
        "all_topics": [
          "llm",
          "ml_research",
          "ai_product",
          "developer_tools",
          "data_engineering"
        ],
        "topic_details": {
          "llm": {
            "raw_score": 3,
            "weighted_score": 3.0,
            "matched_keywords": [
              "openai",
              "deepseek",
              "ai agent"
            ],
            "label": "Large Language Models"
          },
          "ml_research": {
            "raw_score": 1,
            "weighted_score": 0.9,
            "matched_keywords": [
              "attention"
            ],
            "label": "ML Research"
          },
          "ai_product": {
            "raw_score": 2,
            "weighted_score": 1.7,
            "matched_keywords": [
              "ai tool",
              "ai api"
            ],
            "label": "AI Products"
          },
          "developer_tools": {
            "raw_score": 4,
            "weighted_score": 2.4,
            "matched_keywords": [
              "developer",
              "ide",
              "coding",
              "api"
            ],
            "label": "Developer Tools"
          },
          "data_engineering": {
            "raw_score": 3,
            "weighted_score": 1.5,
            "matched_keywords": [
              "database",
              "sql",
              "postgres"
            ],
            "label": "Data Engineering"
          }
        },
        "relevance_score": 0.95,
        "is_noise": false,
        "filter_reason": null
      },
      "engagement_quality": {
        "engagement_ratio": 0.59,
        "is_flamewar": false,
        "is_high_signal": false,
        "is_emerging": false,
        "discussion_depth": 5.02,
        "velocity": 16.06,
        "hours_old": 22.1,
        "quality_tier": "high_quality"
      },
      "editorial": {
        "one_liner": "Large Language Models insight worth reading",
        "why_it_matters": "highly upvoted by HN community; directly relevant to AI practitioners",
        "audience_fit": "AI engineers & researchers",
        "newsletter_priority": 2
      }
    },
    {
      "id": "42b5f4ecae2032cd5e411c80cdc103b9",
      "source": "hackernews",
      "source_id": "46849258",
      "title": "My iPhone 16 Pro Max produces garbage output when running MLX LLMs",
      "content": "TL;DR:\n\nMy iPhone 16 Pro Max produces garbage output when running MLX LLMs. An iPhone 15 Pro runs the same code perfectly. A MacBook Pro also runs the same code perfectly. The tensor outputs on the 16 show numerical values an order of magnitude wrong. I suspect it points to a hardware defect in the Neural Engine or some other ML-needed system.\n\nIt was a PITA to debug, but at least I got a blog post out of it.\n\nHow did I get there?\n\nThis was supposed to be a simple, unwinding-time project.\n\nFor the past few months I've been working on aClawdbotMoltbot clone that I've been calling Schmidt. It basically does the same kind of thing but with a custom chat UI instead of using Telegram, WhatsApp or other \"I-can't-afford-to-be-banned-from\" Service. This project has been consuming early days and late nights, so, to unwind, I decided that it may be a good idea to do something simpler. Since I recently subscribed to MiniMax M2.1, I thought I would do what many do and build a simple expense tracking app to test out the model.\n\nThe core functionality is simple:\n\nAutomatically, upon each payment, add the expense to my app\n\nUpdate an Apple Watch complication with the % of my monthly budget spent\n\nCategorize the purchase for later analysis\n\nThis all comes from being basically orphaned by Nubank's amazing native app (since replaced by a less-full-featured Flutter version).\n\nIntegrating with Shortcuts is manual, but reliable. Within 15 minutes I had a version of the app that could register purchases. The Apple Watch complication, the main goal, can come later. I'd rather get the classification feature, which should be easy, done quickly ‚Äì so I figured.\n\nApple Intelligence\n\nGiven the new LLM-bonanza we've been living through, it's no surprise that Apple has their own set of APIs developers such as me can use. Reading up on the documentation, it's a matter of checking for the availability of the feature and then asking the model to either reply to a textual query or, in my case, categorize a request.\n\nMiniMax raced through it in a single prompt and then I ran it on my iPhone. First expense was a purchase at a shop called \"Kasai Kitchin\", classified as...unknown.Weird.\n\nChecking the logs, it was clear: the model support was downloading. The feature hadn't been enabled. Again, weird. I should have it on. Anyway, I go into settings, do the weird dance of toggling it on and off ‚Äì sadly, that's not surprising on Apple's services. Maybe my Settings.app got stuck in a weird state, who knows? ‚Äì and wait for it to download.\n\nAfter 4h I realized it was not going anywhere. Looking it up, it seems that many have the same issue (thisthread shows 12 pages of frustrated users). Again, not a surprise for Apple's services recently.\n\nOh well, time to give up on the Apple Intelligence approach. Let's move on to the next one.\n\nMLX LLM\n\nWell, the iOS framework engineers don't seem to be the only engineers at Apple capable of coming up with Machine Learning APIs in Swift. Apparently, there's a whole separate way of doing it ‚Äì with models downloaded to your app. Not great for the user's storage, but great for me!\n\nAgain, MiniMax does it in a heartbeat, specially after being given documentation and one or two Medium posts. Time to run on my iPhone and... gibberish.\n\nThe CPU spins to 100% and the model starts generating. But it's all gibberish. And no \"stop\" token is generated, so this goes on for long.\n\nAt this point, the only explanation is: I'm completely incompetent and can't even get a simple \"ready made\" framework to execute what I want. Or, rather,MiniMax is! The good thing about offloading your work to an LLM is that you can blame it for your shortcomings. Time to get my hands dirty and do it myself, typing code on my keyboard, like the ancient Mayan and Aztec programmers probably did.\n\nMy own MLX implementation\n\nI went back to the documentation, to the Medium posts and, much to my surprise: MiniMax had followed it to the letter. Even went back to some deprecated methods of generation and it also was gibberish. And now there's no one to blame, but myself. I go to work everyday and this impostor-syndrome inducing problem silently consumes me.After 3 days of trying to get it to work, I'm ready to give up......until, on a Tuesday morning, at 7-8 AM, I have an idea: let me, just in case, run this on my old iPhone 15 Pro. Up to this point, I was running it on my daily driver, an iPhone 16 Pro Max that was a replacement phone sent by Apple Care after a small clubbing mishap (in which my iPhone was irreparably crashed). I rush to get everything ready before it's time to go to work and: it works! Gemma, Qwen, and all other models generate coherent responses!\n\nI stop and think: this cannot be a hardware issue,right? Of course not. The iPhone 15 is still running iOS 18. The iPhone 16 is running 26. Itmust be an OS issue. Well, time to be late for my work standup and update the old phone. The curiosity is too much. Many minutes later... same results, now on iOS 26. The plot is thickening.\n\nFinding the smoking gun: breakpoints in MLX's implementations of Gemma\n\nAfter that work day, and after many lunch and coffee discussions with coworkers about the sources of my troubles, I get home and immediately set myself on debugging MLX as it runs, if possible. The game plan is:\n\nUse a known-to-be-reliable model, that fits in RAM (I went with quantized Gemma)\n\nUse a simple prompt, in my case \"What is 2+2?\"To bereallypedantic: the prompt was<start_of_turn>user\\nWhat is 2+2?<end_of_turn>\\n<start_of_turn>model\n\nTo bereallypedantic: the prompt was<start_of_turn>user\\nWhat is 2+2?<end_of_turn>\\n<start_of_turn>model\n\nRun everything with temperature set to0.0‚Äì maybe that's enough to remove variability\n\nFind the model implementation\n\nFind where the model iterates through the layers and\n\nPrint out the MLXArray/Tensor with the values on each layer as the input goes through\n\nA few moments later and I find where I need to be. Added the breakpoints, added the logs and off to the races.\n\nI run it on my iPhone 16 Pro Max. The model loads and the prompt is \"What is 2+2?\". The tensors start printing out, line after line after line. For once, the logs aren'tcompletegibberish ‚Äì they're numbers. Floating point values representing the model's internal state as it processes the input. I save the output to a file and do the same on my iPhone 15 Pro. Same model, same prompt, same code. Time to compare.\n\nWelp, now it's definitely out of my expertise\n\nI grep for a pattern I know should be consistent ‚Äì an array at log-line 58, right before the values get normalized/softmaxed. On a working device, I hypothesize this should be the same every time.On the iPhone 15 Pro:3: \"[[[[53.875, 62.5625, -187.75, ..., 42.625, 6.25, -21.5625]]]]\"On the iPhone 16 Pro Max:3: \"[[[[191.5, 23.625, 173.75, ..., 1298, -147.25, -162.5]]]]\"Huh. Not close. Not at all. These values are orders of magnitude off. I double check the start of the logs and both phones show the same:1: \"array([[[0.162842, -0.162842, -0.48877, ..., -0.176636, 0.0001297, 0.088501],\\n [-0.348633, -2.78906, 0, ..., 0.84668, 0, -1.69336],\\n [-1.30957, 1.57324, -1.30957, ..., -0.0010376, -0.0010376, 1.12305],\\n ...,\\n [-0.348633, -2.78906, 0, ..., 0.84668, 0, -1.69336],\\n [0.296875, 0.59375, 0.890625, ..., -0.59375, 0.296875, -0.890137],\\n [1.02734, -0.616211, -0.616211, ..., -0.275879, -0.551758, 0.275879]]], dtype=float16)\"\n\nOK, so the model receives the same thing as input, but at some point, the values start to go off. Like,way off. In order to make sure I'm not crazy, I do one last thing: run the same thing on my Mac. Make the app run on iPad compatibility mode and...3: \"[[[[53.875, 62.5625, -187.75, ..., 42.625, 6.25, -21.5625]]]]\"\n\nBingo! Same as iPhone 15!\n\nThe model isn't broken. The code isn't broken. Most importantly, I'm not broken*. Myphoneis broken.*arguable, but besides the point here\n\nWhat's going on?\n\nLet me explain what I think it's going on here: the iPhone 16 Pro Max contains Apple's A18 chip with its Neural Engine‚Äîa specialized accelerator for machine learning operations. MLX uses Metal to compile tensor operations for this accelerator. Somewhere in that stack, the computations are goingverywrong. I don't think it's a widespread issue but, I do get disappointed that a relatively newly replaced iPhone from Apple Care came with such an issue.\n\nHowever, if my Apple Intelligence troubles are related ‚Äì and they might as well be, I'd assume that code and MLX are not dissimilar in operations being done ‚Äì, it could be thatall the 12 pages of usersare users in a similar dillema, but without the means of debugging it.\n\nWhat now?\n\nI spent 3 days thinking I was incompetent. I blamed MiniMax. I blamed myself. The entire time, my $1,400 phone had a broken hardware. I could lose more time figuring outexactlywhat is wrong with it but it‚Äôs literally not worth my time.\n\nI guess I can at least take a lesson that, when debugging, I should always consider the physical layer. I spent three days assuming this was a software problem ‚Äì my code, the library, the framework, my skills as a developer. The breakthrough was basically: \"What if I'm not dumb and it's not my code?\"\n\nAs for my phone: it'll probably go back to Apple, as a trade in for a new iPhone 17 Pro Max thathopefully ü§ûcan do math.\n\nUpdate on Feb. 1st:\n\nWell, now it's Feb. 1st and I have an iPhone 17 Pro Max to test with and... everything works as expected. So it's pretty safe to say thatTHATspecific instance of iPhone 16 Pro Max was hardware-defective.",
      "url": "https://journal.rafaelcosta.me/my-thousand-dollar-iphone-cant-do-math/",
      "author_username": "rafaelcosta",
      "author_category": "unknown",
      "media": [
        {
          "type": "image",
          "url": "https://journal.rafaelcosta.me/content/images/2026/01/original-39c7e1f432c4bda26535fd3e0b5cb7d5.webp",
          "alt": ""
        },
        {
          "type": "image",
          "url": "https://journal.rafaelcosta.me/content/images/2026/01/Screenshot-2026-01-28-at-01.14.46.png",
          "alt": ""
        },
        {
          "type": "image",
          "url": "https://journal.rafaelcosta.me/content/images/2026/01/Screenshot-2026-01-28-at-02.09.49.png",
          "alt": ""
        },
        {
          "type": "image",
          "url": "https://journal.rafaelcosta.me/content/images/2026/01/Screenshot-2026-01-27-at-18.28.38.png",
          "alt": ""
        }
      ],
      "impressions_views": null,
      "impressions_likes": 425,
      "impressions_reposts": 0,
      "impressions_replies": 204,
      "impressions_bookmarks": null,
      "impressions_clicks": null,
      "impressions_quotes": null,
      "impressions_updated_at": "2026-02-03T09:02:54.478231",
      "published_at": "2026-02-01T15:51:56",
      "scraped_at": "2026-02-03T09:02:54.478278",
      "metadata": {
        "item_type": "story",
        "hn_url": "https://news.ycombinator.com/item?id=46849258",
        "kids_count": 34,
        "sections": [
          "best_stories"
        ]
      },
      "content_hash": "91de85ec962e546cebda311b3e3729ff",
      "classification": {
        "is_ai_relevant": true,
        "primary_topic": "developer_tools",
        "primary_topic_label": "Developer Tools",
        "all_topics": [
          "llm",
          "ml_research",
          "ai_infra",
          "developer_tools"
        ],
        "topic_details": {
          "llm": {
            "raw_score": 2,
            "weighted_score": 2.0,
            "matched_keywords": [
              "llm"
            ],
            "label": "Large Language Models"
          },
          "ml_research": {
            "raw_score": 2,
            "weighted_score": 1.8,
            "matched_keywords": [
              "machine learning",
              "model"
            ],
            "label": "ML Research"
          },
          "ai_infra": {
            "raw_score": 2,
            "weighted_score": 1.8,
            "matched_keywords": [
              "tpu"
            ],
            "label": "AI Infrastructure"
          },
          "developer_tools": {
            "raw_score": 5,
            "weighted_score": 3.0,
            "matched_keywords": [
              "developer",
              "ide",
              "api",
              "framework",
              "library"
            ],
            "label": "Developer Tools"
          }
        },
        "relevance_score": 0.86,
        "is_noise": false,
        "filter_reason": null
      },
      "engagement_quality": {
        "engagement_ratio": 0.48,
        "is_flamewar": false,
        "is_high_signal": true,
        "is_emerging": false,
        "discussion_depth": 6.0,
        "velocity": 10.27,
        "hours_old": 41.4,
        "quality_tier": "high_quality"
      },
      "editorial": {
        "one_liner": "Developer Tools insight worth reading",
        "why_it_matters": "highly upvoted by HN community; quality discussion",
        "audience_fit": "Software developers",
        "newsletter_priority": 2
      }
    },
    {
      "id": "7be50c1abd0a1e7770b43c4ee9c4e3a7",
      "source": "hackernews",
      "source_id": "46854999",
      "title": "Claude Code is suddenly everywhere inside Microsoft",
      "content": "Tech\n\nAI\n\nMicrosoft\n\nClaude Code is suddenly everywhere inside Microsoft\n\nMicrosoft sells GitHub Copilot to its customers, but it increasingly favors Claude Code internally.\n\nMicrosoft sells GitHub Copilot to its customers, but it increasingly favors Claude Code internally.\n\nLink\n\nShare\n\nGift\n\nDevelopers have been comparing the strengths and weaknesses of Anthropic‚Äôs Claude Code, Anysphere‚Äôs Cursor, and Microsoft‚Äôs GitHub Copilot for months now, looking for a winner. While no individual AI coding tool manages to be the best at every task that software developers do each day, Claude Code is increasingly coming out on top for its ease of use, both for developers and nontechnical users.\n\nIt seems like Microsoft agrees, as sources tell me the company is now encouraging thousands of its employees from some of its most prolific teams to pick up Claude Code and get coding, even if they‚Äôre not developers.\n\nMicrosoft first started adopting Anthropic‚Äôs Claude Sonnet 4 model inside its developer division in June last year, beforefavoring it for paid usersof GitHub Copilot several months later. Now, Microsoft is going a step beyond using Anthropic‚Äôs AI models and widely adopting Claude Code across its biggest engineering teams.\n\nMicrosoft‚Äôs CoreAI team, the new AI engineering group led by former Meta engineering chief Jay Parikh, has been testing Claude Code in recent months, and last week Microsoft‚Äôs Experiences + Devices division were being asked to install Claude Code. This division is responsible for Windows, Microsoft 365, Outlook, Microsoft Teams, Surface, and more.\n\nEven employees without any coding experience are being encouraged to experiment with Claude Code, to allow designers and project managers to prototype ideas. Microsoft has also approved the use of Claude Code across all of its code and repositories for its Business and Industry Copilot teams.\n\nSoftware engineers at Microsoft are now expected to use both Claude Code and GitHub Copilot and give feedback comparing the two, I‚Äôm told. Microsoft sells GitHub Copilot as its AI coding tool of choice to its customers, but if these broad internal pilot programs are successful, then it‚Äôs possible the company could even eventually sell Claude Code directly to its cloud customers.\n\nMicrosoft is now one of Anthropic‚Äôs top customers, according to a recent report fromThe Information. The software maker is also counting selling Anthropic AI models toward Azure sales quotas, which is unusual given Microsoft typically only offers its salespeople incentives for homegrown products or models from OpenAI.\n\nMicrosoft‚Äôs decision to adopt Claude Code more broadly among its engineering teams certainly looks like a vote of confidence in Anthropic‚Äôs AI tools over its own, especially as it‚Äôs encouraging nontechnical employees to try out coding. But the reality is that Microsoft‚Äôs developers are likely to use a mix of AI tools, and adopting Claude Code is another part of that tool set.\n\n‚ÄúCompanies regularly test and trial competing products to gain a better understanding of the market landscape,‚Äù says Frank Shaw, Microsoft‚Äôs communications chief, in a statement toNotepad. ‚ÄúOpenAI continues to be our primary partner and model provider on frontier models, and we remain committed to our long-term partnership.‚Äù\n\nWhile Microsoft remains committed to OpenAI, it is increasingly working with Anthropic to bring its models and tools to Microsoft‚Äôs own teams and the software it sells to customers. Microsoft and Anthropicsigned a dealin November that allows Microsoft Foundry customers to get access to Claude Sonnet 4.5, Claude Opus 4.1, and Claude Haiku 4.5. The deal also involves Anthropic committing to purchasing $30 billion of Azure compute capacity.\n\nMicrosoft has also started favoring Anthropic‚Äôs Claude modelsinside Microsoft 365 apps and Copilotrecently, using them inspecific appsor features where Anthropic‚Äôs models have proved more capable than OpenAI‚Äôs counterparts.\n\nThe big question here is, what does the increased use of Claude Code at Microsoft mean for its more than 100,000 code repositories? Microsoft told me last year that91 percent of its engineering teams use GitHub Copilotand a variety of teams have been using the AI tool to speed up mundane tasks. Microsoft‚Äôs use of AI tools has been largely restricted to software engineers, but with Claude Code andClaude Cowork, Anthropic is increasingly focused on making coding and non-coding tasks more approachable, thanks to AI agent capabilities.\n\nMicrosoft is embracing the ease of use of Claude Code to allow more nontechnical employees to commit code using AI, and this broad pilot will certainly highlight the challenges and benefits of that shift. It also puts further pressure on junior developer roles, with fears in the industry that these roles are increasingly disappearing because of AI. Microsoft just took another big step toward a future where more autonomous AI agents are creating code, further wrestling control from its software engineers.\n\nIt‚Äôs Xbox time\n\nMicrosoft is getting ready to show off two of its biggest Xbox games this year,Forza Horizon 6andFable, later today as part of itsXbox Developer Direct stream. There will also be a first in-depth look atBeast of Reincarnationand at least one other game shown, I‚Äôm hearing. Double Fine is ready toshow offKiln, a multiplayer, team-based brawler. I understand Double Fine has been holding playtests recently, where you play as a spirit that can inhabit pottery and carry water to douse an opponent‚Äôs kiln and put out a fire.\n\nI wouldn‚Äôt be surprised to seeKilnappear as an early preview in the coming months, followed byForza Horizon 6in May and thenHalo: Campaign Evolved.I keep hearing that bothFableandGears of War: E-Dayare currently targeting a release in the second half of this year. Microsoft is keen to release newForza,Gears,Halo, andFablegames in 2026 to mark 25 years of Xbox.\n\nThe pad\n\nMicrosoft‚Äôs first Windows 11 update of 2026 stopped some computers from shutting down.It‚Äôs only January and Microsoft has had to rush out an emergency out-of-band fix that stopped some Windows 11 PCs from shutting down.The issueswere limited to machines running Enterprise and IoT editions of Windows 11 version 23H2, but it‚Äôs yet another buggy update for Windows, which is becoming increasingly common.\n\nMicrosoft‚Äôs free Xbox Cloud Gaming is coming soon with ads.Microsoft is getting closer to launching its free streaming option for Xbox Cloud Gaming. The ad-supported featurehas started appearinginside the Xbox app for PC, indicating ‚Äú1 hour of ad-supported playtime per session.‚Äù I‚Äôm expecting to see this rollout with preroll ads in the coming weeks, but there could be limits of up to five hours free per month.\n\nMicrosoft wants to build 15 data centers in Mount Pleasant, Wisconsin.The empty land formerly owned by Foxconn is about to be transformedinto Microsoft data centers. Leaders of the local village in Mount Pleasant, Wisconsin, approved plans for the data centers earlier this week, and final approval could come next week. Foxconn‚Äôs failed Wisconsin project had promised 13,000 jobs, but now the land will be filled with a 1.2-million-square-foot data center project that will hold hundreds of thousands of Nvidia‚Äôs AI GPUs.\n\nThe Xbox app is now available for all Arm-based Windows 11 PCs.After a rocky start to gaming on Windows on Arm, Microsoft hasupdated its Xbox appthis week so it‚Äôs fully compatible with all Qualcomm-powered devices. More than 85 percent of the Xbox Game Pass catalog is also now compatible with Arm-based devices, but the majority of games will still need to be emulated using Microsoft‚Äôs Prism technology.\n\nMicrosoft Paint now has an AI-powered coloring book.Microsoft is adding more AI features to its Paint app this week. Windows testers can now try out acoloring book featurethat lets you create coloring book pages from a text prompt. It‚Äôs available inside the Copilot button in Paint, and you have to have a Copilot Plus PC to be able to use it. Notepad (the app!) is also getting expanded Markdown syntax features and a new welcome experience to highlight features. I never thought I‚Äôd see the day that Notepad, a lightweight app, would need a welcome screen because of all the features Microsoft has packed in.\n\nGitHub has a new Copilot SDK.Microsoft is announcing a technical preview of itsGitHub Copilot SDKtoday, which brings the power of the GitHub Copilot CLI to any app. It essentially allows developers to bring GitHub Copilot capabilities as a programmable SDK for Python, TypeScript, Go, and .NET. Microsoft teams have already used this to build custom GUIs for agents, summarizing tools, YouTube chapter generators, and more.\n\nSatya Nadella and former British Prime Minister Rishi Sunak chat AI.Former UK leaderRishi Sunaktook on a senior adviser role at Microsoft and Anthropic last year, and he‚Äôs now appeared alongside Microsoft CEOSatya Nadellato discuss the future of AI. The roughly30-minute talkdidn‚Äôt have any surprising news, but Sunak did agree with Nvidia CEOJensen Huangthat ‚Äúyou may not lose your job to AI, but you may well lose your job to someone using AI.‚Äù Nadella thinks AI will make us all ‚Äúmanagers of infinite minds,‚Äù much like how we have ‚Äúinformation at your fingertips.‚Äù\n\nMicrosoft now sponsors the Mercedes-AMG F1 team. Microsoft is switching its F1 allegiances from Alpine to Mercedes-AMG for the 2026 season. Anew multiyear partnershipwill see Mercedes-AMG use Microsoft technologies for race team operations and plaster the Microsoft logo in prominent positions on the 2026 Mercedes-AMG F1 car and on racing suits. There‚Äôs a big technical shake-up for the 2026 season, with all-new chassis, power units, and fuel regulations.\n\nI‚Äôm always keen to hear from readers, so please drop a comment here, or you can reach me atnotepad@theverge.comif you want to discuss anything else. If you‚Äôve heard about any of Microsoft‚Äôs secret projects, you can reach me via email atnotepad@theverge.comor",
      "url": "https://www.theverge.com/tech/865689/microsoft-claude-code-anthropic-partnership-notepad",
      "author_username": "Anon84",
      "author_category": "unknown",
      "media": [
        {
          "type": "image",
          "url": "https://www.google-analytics.com/g/collect?v=2&tid=G-C3QZPB4GVE&cid=555&en=noscript_page_view",
          "alt": ""
        }
      ],
      "impressions_views": null,
      "impressions_likes": 376,
      "impressions_reposts": 0,
      "impressions_replies": 503,
      "impressions_bookmarks": null,
      "impressions_clicks": null,
      "impressions_quotes": null,
      "impressions_updated_at": "2026-02-03T09:02:55.955826",
      "published_at": "2026-02-02T06:58:58",
      "scraped_at": "2026-02-03T09:02:55.955839",
      "metadata": {
        "item_type": "story",
        "hn_url": "https://news.ycombinator.com/item?id=46854999",
        "kids_count": 44,
        "sections": [
          "best_stories"
        ]
      },
      "content_hash": "7a98996d44d59cebaa4bd42fcaa024aa",
      "classification": {
        "is_ai_relevant": true,
        "primary_topic": "llm",
        "primary_topic_label": "Large Language Models",
        "all_topics": [
          "llm",
          "ml_research",
          "ai_product",
          "ai_infra",
          "ai_ethics",
          "developer_tools"
        ],
        "topic_details": {
          "llm": {
            "raw_score": 7,
            "weighted_score": 7.0,
            "matched_keywords": [
              "claude",
              "openai",
              "anthropic",
              "copilot",
              "cursor",
              "ai agent"
            ],
            "label": "Large Language Models"
          },
          "ml_research": {
            "raw_score": 1,
            "weighted_score": 0.9,
            "matched_keywords": [
              "model"
            ],
            "label": "ML Research"
          },
          "ai_product": {
            "raw_score": 3,
            "weighted_score": 2.55,
            "matched_keywords": [
              "ai-powered",
              "ai tool",
              "ai feature"
            ],
            "label": "AI Products"
          },
          "ai_infra": {
            "raw_score": 2,
            "weighted_score": 1.8,
            "matched_keywords": [
              "gpu",
              "nvidia"
            ],
            "label": "AI Infrastructure"
          },
          "ai_ethics": {
            "raw_score": 1,
            "weighted_score": 0.8,
            "matched_keywords": [
              "regulation"
            ],
            "label": "AI Ethics & Safety"
          },
          "developer_tools": {
            "raw_score": 5,
            "weighted_score": 3.0,
            "matched_keywords": [
              "developer",
              "ide",
              "coding",
              "sdk"
            ],
            "label": "Developer Tools"
          }
        },
        "relevance_score": 1.0,
        "is_noise": false,
        "filter_reason": null
      },
      "engagement_quality": {
        "engagement_ratio": 1.34,
        "is_flamewar": false,
        "is_high_signal": false,
        "is_emerging": false,
        "discussion_depth": 11.43,
        "velocity": 14.32,
        "hours_old": 26.3,
        "quality_tier": "good"
      },
      "editorial": {
        "one_liner": "Large Language Models insight worth reading",
        "why_it_matters": "highly upvoted by HN community; directly relevant to AI practitioners",
        "audience_fit": "AI engineers & researchers",
        "newsletter_priority": 3
      }
    },
    {
      "id": "209cea59947e1fd2b3756c59b5dd589a",
      "source": "hackernews",
      "source_id": "46848415",
      "title": "Teaching my neighbor to keep the volume down",
      "content": "When I moved to a new apartment with my family, the cable company we were used to wasn't available. We had to settle for Dish Network. I wasn't too happy about making that switch, but something on their website caught my attention. For an additional $5 a month, I could have access to DVR. I switched immediately.\n\nThis was 2007. DVR was not new, but it wasn't commonly bundled with set-top boxes. TiVo was still the popular way to record, pause, and rewind live TV. We received two set-top boxes, one for each room with a TV, and three remotes. Two remotes had IR (infrared) blasters and, surprisingly, one RF (radio frequency) remote.\n\nAfter using the RF remote, I wondered: Why would anyone ever use an IR remote again? You didn't need a direct line of sight with the device you were controlling. I could actually stand in the kitchen and control the TV. It was amazing. But with the convenience of RF came other problems that IR users never had to worry about. Interference.\n\nAfter several months of enjoying my service, one of my neighbors, the loudest in the building, also switched to Dish Network. And he also got the RF remote. This was the type of neighbor who would leave the house with the TV on, volume blasting.\n\nOne day, I was in the living room watching TV when the channel just flipped. I must have accidentally hit a button, so I changed it back. But not a few seconds later, the channel changed again. Then the volume went up. I figured my sister must have had the RF remote and was messing with me. But no, the remote was in my hand. I assumed something was wrong with it.\n\nThe whole time I was watching TV, the channels kept randomly switching. I banged the remote on the table a couple of times, but it still switched. I removed the batteries from the remote, it still switched. I unplugged the device for a few minutes, plugged it back in, and‚Ä¶ it still switched. Frustrated, I went through the device settings and disabled the RF remote. That's when it finally stopped. I wasn't happy with this solution, but it allowed me to watch TV until I figured something out.\n\nOne evening, when everyone was asleep and the neighbor was watching a loud TV show, I decided to diagnose the issue. The moment I pressed the power button on the RF remote, my TV and set-top box turned on, and the neighbor's TV went silent. \"Fuck!\" I heard someone say. I was confused. Did I just do that? The TV turned back on, the volume went up. I walked to the window armed with the remote. I counted to three, then pressed the power button. My neighbor's TV went silent. He growled.\n\nI am the captain now.\n\nEvery time he turned the TV on, I pressed the power button again and his device went off. Well, what do you know? We had interference somehow. Our remotes were set up to operate at the same frequency. Each remote controlled both devices.\n\nBut I'm not that kind of neighbor. I wasn't going to continue to mess with him. Instead, I decided I would pay him a visit in the morning and explain that our remotes are tuned to the same frequency. I would bring the RF remote with me just to show him a demo. I was going to be a good neighbor.\n\nIn the morning, I went downstairs, remote in hand. I knocked on the door, and a gentleman in his forties answered the door. I had rehearsed my speech and presentation. This would be a good opportunity to build a good rapport, and have a shared story. Maybe he would tell me how he felt when the TV went off. How he thought there was a ghost in the house or something. But that's not what happened.\n\n\"Hi, I'm Ibrahim. Your upstairs neighbor...\" I started and was interrupted almost immediately. \"Whatever you are selling,\" he yelled. \"I'm not buying.\" and he closed the door on my face. I knocked a second time, because obviously there was a misunderstanding. He never answered. Instead, the TV turned on and a movie played at high volume. So much for my prepared speech.\n\nThe RF settings on my set-top box remained turned off. My family never discovered its benefit anyway, they always pointed at the box when pressing the buttons. It wasn't much of an inconvenience. In fact, I later found in the manual that you could reprogram the device and remote to use a different frequency. I did not reprogram my remote. Instead, my family used the two IR remotes, and brought the RF remote in my bedroom where it permanently remained on my night stand.\n\nWhy in the bedroom? Because I decided to teach my neighbor some good manners. Whenever he turned up his volume, I would simply turn off his device. I would hear his frustration, and his attempts at solving the problem. Like a circus animal trainer, I remained consistent. If the volume of his TV went above what I imagined to be 15 to 20, I would press the power button. It became a routine for me for weeks. Some nights were difficult, I would keep the remote under my pillow, battling my stubborn neighbor all night.\n\nOne day, I noticed that I hadn't pressed the button in days. I opened the window and I could still hear the faint sound of his TV. Through trial and error, he learned the lesson. If the volume remained under my arbitrary threshold, the TV would remain on. But as soon as he passed that threshold, the device would turn off.\n\nSometimes, he would have company and there would be noise coming out of his apartment. I used the one tool in my tool box to send him a message. Turn off the TV. All of the sudden, my neighbor and his guest will be reminded of the unspoken rules, and become mindful of their neighbors.\n\nMaybe somewhere on the web, in some obscure forum, someone asked the question: \"Why does my set-top box turn off when I increase the volume?\" Well, it might be 18 years too late, but there's your answer. There is a man out there who religiously sets his volume to 18. He doesn't quite know why. That's Pavlovian conditioning at its best.\n\nDid you like this article?You can buy me a coffee.Share your insightful comments here.\n\nJoin my newsletter\n\nFollow me onTwitter,Spotify, orRSS\n\t\t\t\t\t\tFeed\n\nOn a related note, here are some interesting articles.\n\nThe Problem with Hype\n\nThe main problem with hype is that it keeps us from appreciating what we already have. It‚Äôs always about the next big thing. Something revolutionary just over the horizon. But while we‚Äôre busy chasing the future, we overlook the real progress happening right under our noses.\n\nThe Scotsman AI Fallacy\n\nWhen someone shares a genuine frustration with AI like a hallucination, a bias, or a workflow meltdown, like clockwork the replies are always the same:\n\n\n\"You‚Äôre just not using it right.\"\n\"Skill issue.\"\n\"Prompt better.\"\n\nThe ‚ÄúPerfect‚Äù YouTube Video\n\nMy brother sent me a short about crypto on YouTube. It was a funny video about how crypto bros entice you into their platform by letting you make small wins at first, until you decide to invest a large sum. Then, all your money disappears.\n\nComments(3)\n\nlouisa day ago:\n\nthat was a funny read, thanks for sharing\n\nShawna day ago:\n\nObligatoryxkcd:https://xkcd.com/316/\n\nYounes Ben Amara11 hours ago:\n\nLanded here from HN, that was much-needed good laugh, thanks a lot.",
      "url": "https://idiallo.com/blog/teaching-my-neighbor-to-keep-the-volume-down",
      "author_username": "firefoxd",
      "author_category": "unknown",
      "media": [
        {
          "type": "image",
          "url": "https://cdn.idiallo.com/images/assets/601/remote.jpg",
          "alt": "Dish Network Remote 2008"
        },
        {
          "type": "image",
          "url": "https://cdn.idiallo.com/images/assets/601/captain.jpg",
          "alt": "I am the captain now"
        },
        {
          "type": "image",
          "url": "https://cdn.idiallo.com/images/assets/thumb/default-thumb-2.jpg",
          "alt": "The Problem with Hype"
        },
        {
          "type": "image",
          "url": "https://cdn.idiallo.com/images/assets/thumb/default-thumb-3.jpg",
          "alt": "The Scotsman AI Fallacy"
        },
        {
          "type": "image",
          "url": "https://cdn.idiallo.com/images/assets/521/thumb.jpg",
          "alt": "The ‚ÄúPerfect‚Äù YouTube Video"
        }
      ],
      "impressions_views": null,
      "impressions_likes": 814,
      "impressions_reposts": 0,
      "impressions_replies": 359,
      "impressions_bookmarks": null,
      "impressions_clicks": null,
      "impressions_quotes": null,
      "impressions_updated_at": "2026-02-03T09:02:51.376391",
      "published_at": "2026-02-01T14:00:46",
      "scraped_at": "2026-02-03T09:02:51.376402",
      "metadata": {
        "item_type": "story",
        "hn_url": "https://news.ycombinator.com/item?id=46848415",
        "kids_count": 58,
        "sections": [
          "best_stories"
        ]
      },
      "content_hash": "5d3e15e9e80f34e194b39ac645745951",
      "classification": {
        "is_ai_relevant": true,
        "primary_topic": "ai_ethics",
        "primary_topic_label": "AI Ethics & Safety",
        "all_topics": [
          "ml_research",
          "ai_ethics",
          "developer_tools"
        ],
        "topic_details": {
          "ml_research": {
            "raw_score": 1,
            "weighted_score": 0.9,
            "matched_keywords": [
              "attention"
            ],
            "label": "ML Research"
          },
          "ai_ethics": {
            "raw_score": 2,
            "weighted_score": 1.6,
            "matched_keywords": [
              "hallucination",
              "bias"
            ],
            "label": "AI Ethics & Safety"
          },
          "developer_tools": {
            "raw_score": 1,
            "weighted_score": 0.6,
            "matched_keywords": [
              "ide"
            ],
            "label": "Developer Tools"
          }
        },
        "relevance_score": 0.31,
        "is_noise": false,
        "filter_reason": null
      },
      "engagement_quality": {
        "engagement_ratio": 0.44,
        "is_flamewar": false,
        "is_high_signal": true,
        "is_emerging": false,
        "discussion_depth": 6.19,
        "velocity": 18.83,
        "hours_old": 43.2,
        "quality_tier": "high_quality"
      },
      "editorial": {
        "one_liner": "AI Ethics & Safety insight worth reading",
        "why_it_matters": "highly upvoted by HN community; quality discussion",
        "audience_fit": "AI policy & safety researchers",
        "newsletter_priority": 3
      }
    },
    {
      "id": "907251699645d00cce15d410a1cb674b",
      "source": "hackernews",
      "source_id": "46866481",
      "title": "Coding assistants are solving the wrong problem",
      "content": "The jury is out on the effectiveness of AI use in production, and it is not a pretty picture.\n\nTeams using AI completed 21% more tasks, yet company-wide delivery metrics showed no improvement (Index.dev, 2025)\n\nExperienced developers were 19% slower when using AI coding assistants√¢¬Ä¬îyet believed they were faster (METR, 2025)\n\n48% of AI-generated code contains security vulnerabilities (Apiiro, 2024)\n\nTo understand why, we have to take a closer look at the day-to-day software development. Consider this point raised ina colorful exchangeon r/ExperiencedDev:\n\nA developers√¢¬Ä¬ô job is to reduce ambiguity. We take the business need and outline its logic precisely so a machine can execute. The act of writing the code is the easy part. Odds are, you aren√¢¬Ä¬ôt creating perfect code specs into tickets, even with meeting notes, because developers will encounter edge cases that demand clarification over the course of implementation√¢¬Ä¬¶\n\nThere are two key points raised in this comment. Firstly, coding assistants require clearly-defined requirements in order to perform well. Secondly, edge cases and product gaps are often discovered over the course of implementation.\n\nThese two facts come head-to-head in the application of coding agents to complex codebases. Unlike their human counterparts who would and escalate a requirements gap to product when necessary, coding assistants are notorious for burying those requirement gaps within hundreds of lines of code, leading to breaking changes and unmaintainable code.\n\nAs a result, more overhead is spent on downstream code reviews (Index.dev, 2025) and fire-patching security vulnerabilities (Apiiro, 2025).\n\nIn other words, the use of AI in production settings oftenincreases ambiguityandreduces code reliability, directly contradicting the objective of developers.\n\nThe picture is not without optimism. Some experienced engineers report transformative results: one principal engineer at Google claimed AI √¢¬Ä¬úgenerated what we built last year in an hour√¢¬Ä¬ù; Boris Cherny, creator of Claude Code,described a monthwhere he √¢¬Ä¬údidn√¢¬Ä¬ôt open an IDE at all√¢¬Ä¬ù while the model √¢¬Ä¬úwrote around 200 PRs, every single line.√¢¬Ä¬ù The optimistic case is that developers evolve from coders into product engineers, focusing on architecture and product thinking while AI handles implementation.\n\nThis however reflects the experience of seasoned developers who have both the technical depth to review AI output critically and the autonomy within their organizations to straddle product and engineering.\n\nFor much of the software engineering workforce, the junior and mid-level engineers at banks, healthcare, and government agencies, there√¢¬Ä¬ôs much less wiggle room. They are sandwiched between the unreliability of AI output and the increased expectation from management to ship faster, resulting in a rapidly widening empathy gap between developers and product owners.\n\nThe product context often goes through multiple layers (end users -> marketers -> product managers) before landing on their lap, necessitated by the separation of responsibilities within an organization and the unique demands of their industries. The effective use of coding agents may require a level of team coordination that simply does not justify the gains in technical output.\n\nBut what if we have simply been approaching the problem from the wrong angle?Suppose we tackle the pain points of software development from first principles, can we come up with solutions that organically decrease ambiguity and reliably increase engineering velocity in production?\n\nConsider how developers spend their time (IDC, 2024):\n\nOnly 16% of a developer√¢¬Ä¬ôs time goes to writing code. The rest? Security and code reviews, monitoring, deployments, requirements clarification√¢¬Ä¬îoperational work that keeps the lights on but doesn√¢¬Ä¬ôt ship features.\n\nHere√¢¬Ä¬ôs the irony: AI coding assistants save developers roughly 10 hours per week, but the increase in inefficiencies in the other parts of the development lifecycle almost entirely cancelled out such gains (Atlassian, 2025). Here√¢¬Ä¬ôs a comment from the earlier cited Redditor.\n\nThey produce legitimate-looking code, and if no one has had the experience of thinking through the assumptions and then writing them into code - considering the edge cases- it√¢¬Ä¬ôll be lgtm√¢¬Ä¬ôd and shipped. You√¢¬Ä¬ôre shifting the burden of this feedback cycle to the right, after the code is output, and that makes us worse off since code is tougher to read than write.\n\nThere√¢¬Ä¬ôs a name for misalignment between business intent and codebase implementation: technical debt. The use of coding agents without careful delineation of their scope and responsibilities is threatening to accelerate tech debt accumulation.\n\nHammering AI code generation on existing codebases doesn√¢¬Ä¬ôt solve the problem, because contrary to what the label √¢¬Ä¬útech debt√¢¬Ä¬ù may suggest, most tech debt isn√¢¬Ä¬ôt actually created in the code,it√¢¬Ä¬ôs created in product meetings. Deadlines. Scope cuts. √¢¬Ä¬úShip now, optimize later.√¢¬Ä¬ù Those decisions shape the system, but the reasoning rarely makes it into the code.\n\n[Engineers] occasionally have access to complete data; at other times, they must work with limited information. They might be conscious of uncertainties surrounding their evidence, but frequently they are not. Competing social, financial, and strategic priorities influence the tradeoffs in unexpected ways. √¢¬Ä¬îRios et al., 2024\n\nHow can we make this context-sharing and decision-making process less chaotic? We surveyed developers across different roles and team sizes regarding their product-engineering handoff process. The results were overwhelming: the majority discover unexpected codebase constraints weekly, after already committing to a product direction and the corresponding architectural implementation. When asked what would help most, two themes dominated:\n\nReducing ambiguity upstream so engineers aren√¢¬Ä¬ôt blocked waiting on product clarification mid-implementation\n\nA clearer picture of affected services and edge cases to allow for more precise feature scoping and time allocation\n\nWhen asked which engineering context would be most valuable to surface during product discussions, three categories stood out:state machine gaps(unhandled states caused by user interaction sequences),data flow gaps, anddownstream service impacts.\n\nIdentifying how feature updates affect existing architectures and data flow is rated most desirable among engineering contexts to be surfaced after a product meeting.\n\nThis aligns with decades of SDLC research showing that the costliest defects stem from misalignment between requirements and architecture, and such gaps often go unnoticed until it is too late.\n\nLuckily, the advancement of coding LLMs works in our favor here. Whereas generating fully-functional code through natural language prompting is prone to errors due to the aforementioned context problem, the reverse process, mapping out existing code structures and inferring how they may be impacted by a specific requirement, is much more tenable with recent models.\n\nFrom this vantage point, the possibilities to improving the developmental lifecycle is endless. Some suggested real-time display of engineering context during a meeting to help steer discussions; Others requested a code review bot that detects the discrepencacy of code implementation with stated product/business requirements.\n\nAll-in-all, developers are eager to try out new tools that augment the existing way of doing things, provided they retain flexibility over when such tools are deployed. There is also little reservation against having longer but more fruitful product meetings: it is the difficulty conveying blockers that is the source of frustration.\n\nAt Bicameral, we are committed to taking this pragmatic approach to alleviating software development pains, and move beyond lab benchmarks to investigate the most effective way to deploy AI in the wild.\n\nOur thesis is that LLMs could be a huge boonbothfor the industry and for individual developers√¢¬Ä¬îchanneling the unrivaled human capacity to operate under uncertainty and adapt√¢¬Ä¬îprovided the technology is developed with human needs in mind.\n\nIf you√¢¬Ä¬ôre a developer, we want to learn which types of context hurt most when they√¢¬Ä¬ôre missing from discussion, based on your unique experience.\n\nSurvey link:https://form.typeform.com/to/w4rPXoPD\n\nReferences\n\nIndex.dev. (2025).AI Coding Assistant ROI: Real Productivity Data.\n\nMETR. (2025).Measuring AI√¢¬Ä¬ôs Ability to Complete Long Tasks.\n\nApiiro. (2024).4x Velocity, 10x Vulnerabilities: AI Coding Assistants Are Shipping More Risks.\n\nIDC. (2024).How Do Software Developers Spend Their Time?\n\nAtlassian. (2025).State of Developer Experience Report.\n\nRios, N., et al. (2024).Technical Debt: A Systematic Literature Review.\n\nPragmatic Engineer. (2025).When AI Writes Almost All Code.",
      "url": "https://www.bicameral-ai.com/blog/introducing-bicameral",
      "author_username": "jinhkuan",
      "author_category": "unknown",
      "media": [],
      "impressions_views": null,
      "impressions_likes": 151,
      "impressions_reposts": 0,
      "impressions_replies": 112,
      "impressions_bookmarks": null,
      "impressions_clicks": null,
      "impressions_quotes": null,
      "impressions_updated_at": "2026-02-03T09:02:48.035422",
      "published_at": "2026-02-02T23:25:35",
      "scraped_at": "2026-02-03T09:02:48.035435",
      "metadata": {
        "item_type": "story",
        "hn_url": "https://news.ycombinator.com/item?id=46866481",
        "kids_count": 22,
        "sections": [
          "top_stories"
        ]
      },
      "content_hash": "72faf2f95fe4fc45b8f09324a4f0aa1e",
      "classification": {
        "is_ai_relevant": true,
        "primary_topic": "developer_tools",
        "primary_topic_label": "Developer Tools",
        "all_topics": [
          "llm",
          "ml_research",
          "ai_infra",
          "ai_ethics",
          "developer_tools",
          "tech_industry"
        ],
        "topic_details": {
          "llm": {
            "raw_score": 3,
            "weighted_score": 3.0,
            "matched_keywords": [
              "llm",
              "claude",
              "coding agent"
            ],
            "label": "Large Language Models"
          },
          "ml_research": {
            "raw_score": 3,
            "weighted_score": 2.7,
            "matched_keywords": [
              "model",
              "benchmark",
              "reasoning"
            ],
            "label": "ML Research"
          },
          "ai_infra": {
            "raw_score": 1,
            "weighted_score": 0.9,
            "matched_keywords": [
              "tpu"
            ],
            "label": "AI Infrastructure"
          },
          "ai_ethics": {
            "raw_score": 1,
            "weighted_score": 0.8,
            "matched_keywords": [
              "alignment"
            ],
            "label": "AI Ethics & Safety"
          },
          "developer_tools": {
            "raw_score": 6,
            "weighted_score": 3.5999999999999996,
            "matched_keywords": [
              "developer",
              "ide",
              "coding",
              "software engineering",
              "api"
            ],
            "label": "Developer Tools"
          },
          "tech_industry": {
            "raw_score": 1,
            "weighted_score": 0.5,
            "matched_keywords": [
              "yc"
            ],
            "label": "Tech Industry"
          }
        },
        "relevance_score": 1.0,
        "is_noise": false,
        "filter_reason": null
      },
      "engagement_quality": {
        "engagement_ratio": 0.74,
        "is_flamewar": false,
        "is_high_signal": false,
        "is_emerging": true,
        "discussion_depth": 5.09,
        "velocity": 15.38,
        "hours_old": 9.8,
        "quality_tier": "good"
      },
      "editorial": {
        "one_liner": "Developer Tools insight worth reading",
        "why_it_matters": "worth monitoring",
        "audience_fit": "Software developers",
        "newsletter_priority": 3
      }
    },
    {
      "id": "9fccf8033fd430ac4b861095a4d769b4",
      "source": "hackernews",
      "source_id": "46850205",
      "title": "Show HN: NanoClaw ‚Äì ‚ÄúClawdbot‚Äù in 500 lines of TS with Apple container isolation",
      "content": "My personal Claude assistant that runs securely in containers. Lightweight and built to be understood and customized for your own needs.\n\nWhy I Built This\n\nOpenClawis an impressive project with a great vision. But I can't sleep well running software I don't understand with access to my life. OpenClaw has 52+ modules, 8 config management files, 45+ dependencies, and abstractions for 15 channel providers. Security is application-level (allowlists, pairing codes) rather than OS isolation. Everything runs in one Node process with shared memory.\n\nNanoClaw gives you the same core functionality in a codebase you can understand in 8 minutes. One process. A handful of files. Agents run in actual Linux containers with filesystem isolation, not behind permission checks.\n\nQuick Start\n\nThen run/setup. Claude Code handles everything: dependencies, authentication, container setup, service configuration.\n\nPhilosophy\n\nSmall enough to understand.One process, a few source files. No microservices, no message queues, no abstraction layers. Have Claude Code walk you through it.\n\nSecure by isolation.Agents run in Linux containers (Apple Container on macOS, or Docker). They can only see what's explicitly mounted. Bash access is safe because commands run inside the container, not on your host.\n\nBuilt for one user.This isn't a framework. It's working software that fits my exact needs. You fork it and have Claude Code make it match your exact needs.\n\nCustomization = code changes.No configuration sprawl. Want different behavior? Modify the code. The codebase is small enough that this is safe.\n\nAI-native.No installation wizard; Claude Code guides setup. No monitoring dashboard; ask Claude what's happening. No debugging tools; describe the problem, Claude fixes it.\n\nSkills over features.Contributors shouldn't add features (e.g. support for Telegram) to the codebase. Instead, they contributeclaude code skillslike/add-telegramthat transform your fork. You end up with clean code that does exactly what you need.\n\nBest harness, best model.This runs on Claude Agent SDK, which means you're running Claude Code directly. The harness matters. A bad harness makes even smart models seem dumb, a good harness gives them superpowers. Claude Code is (IMO) the best harness available.\n\nNo ToS gray areas.Because it uses Claude Agent SDK natively with no hacks or workarounds, using your subscription with your auth token is completely legitimate (I think). No risk of being shut down for terms of service violations (I am not a lawyer).\n\nWhat It Supports\n\nWhatsApp I/O- Message Claude from your phone\n\nIsolated group context- Each group has its ownCLAUDE.mdmemory, isolated filesystem, and runs in its own container sandbox with only that filesystem mounted\n\nMain channel- Your private channel (self-chat) for admin control; every other group is completely isolated\n\nScheduled tasks- Recurring jobs that run Claude and can message you back\n\nWeb access- Search and fetch content\n\nContainer isolation- Agents sandboxed in Apple Container (macOS) or Docker (macOS/Linux)\n\nOptional integrations- Add Gmail (/add-gmail) and more via skills\n\nUsage\n\nTalk to your assistant with the trigger word (default:@Andy):\n\nFrom the main channel (your self-chat), you can manage groups and tasks:\n\nCustomizing\n\nThere are no configuration files to learn. Just tell Claude Code what you want:\n\n\"Change the trigger word to @Bob\"\n\n\"Remember in the future to make responses shorter and more direct\"\n\n\"Add a custom greeting when I say good morning\"\n\n\"Store conversation summaries weekly\"\n\nOr run/customizefor guided changes.\n\nThe codebase is small enough that Claude can safely modify it.\n\nContributing\n\nDon't add features. Add skills.\n\nIf you want to add Telegram support, don't create a PR that adds Telegram alongside WhatsApp. Instead, contribute a skill file (.claude/skills/add-telegram/SKILL.md) that teaches Claude Code how to transform a NanoClaw installation to use Telegram.\n\nUsers then run/add-telegramon their fork and get clean code that does exactly what they need, not a bloated system trying to support every use case.\n\nRFS (Request for Skills)\n\nSkills we'd love to see:\n\nCommunication Channels\n\n/add-telegram- Add Telegram as channel. Should give the user option to replace WhatsApp or add as additional channel. Also should be possible to add it as a control channel (where it can trigger actions) or just a channel that can be used in actions triggered elsewhere\n\n/add-slack- Add Slack\n\n/add-discord- Add Discord\n\nPlatform Support\n\n/setup-windows- Windows via WSL2 + Docker\n\nSession Management\n\n/add-clear- Add a/clearcommand that compacts the conversation (summarizes context while preserving critical information in the same session). Requires figuring out how to trigger compaction programmatically via the Claude Agent SDK.\n\nRequirements\n\nmacOS or Linux\n\nNode.js 20+\n\nClaude Code\n\nApple Container(macOS) orDocker(macOS/Linux)\n\nArchitecture\n\nSingle Node.js process. Agents execute in isolated Linux containers with mounted directories. IPC via filesystem. No daemons, no queues, no complexity.\n\nKey files:\n\nsrc/index.ts- Main app: WhatsApp connection, routing, IPC\n\nsrc/container-runner.ts- Spawns agent containers\n\nsrc/task-scheduler.ts- Runs scheduled tasks\n\nsrc/db.ts- SQLite operations\n\ngroups/*/CLAUDE.md- Per-group memory\n\nFAQ\n\nWhy WhatsApp and not Telegram/Signal/etc?\n\nBecause I use WhatsApp. Fork it and run a skill to change it. That's the whole point.\n\nWhy Apple Container instead of Docker?\n\nOn macOS, Apple Container is lightweight, fast, and optimized for Apple silicon. But Docker is also fully supported‚Äîduring/setup, you can choose which runtime to use. On Linux, Docker is used automatically.\n\nCan I run this on Linux?\n\nYes. Run/setupand it will automatically configure Docker as the container runtime. Thanks to@dotsetgregfor contributing the/convert-to-dockerskill.\n\nIs this secure?\n\nAgents run in containers, not behind application-level permission checks. They can only access explicitly mounted directories. You should still review what you're running, but the codebase is small enough that you actually can. Seedocs/SECURITY.mdfor the full security model.\n\nWhy no configuration files?\n\nWe don't want configuration sprawl. Every user should customize it to so that the code matches exactly what they want rather than configuring a generic system. If you like having config files, tell Claude to add them.\n\nHow do I debug issues?\n\nAsk Claude Code. \"Why isn't the scheduler running?\" \"What's in the recent logs?\" \"Why did this message not get a response?\" That's the AI-native approach.\n\nWhy isn't the setup working for me?\n\nI don't know. Runclaude, then run/debug. If claude finds an issue that is likely affecting other users, open a PR to modify the setup SKILL.md.\n\nWhat changes will be accepted into the codebase?\n\nSecurity fixes, bug fixes, and clear improvements to the base configuration. That's it.\n\nEverything else (new capabilities, OS compatibility, hardware support, enhancements) should be contributed as skills.\n\nThis keeps the base system minimal and lets every user customize their installation without inheriting features they don't want.\n\nLicense\n\nMIT",
      "url": "https://github.com/gavrielc/nanoclaw",
      "author_username": "jimminyx",
      "author_category": "unknown",
      "media": [],
      "impressions_views": null,
      "impressions_likes": 515,
      "impressions_reposts": 0,
      "impressions_replies": 219,
      "impressions_bookmarks": null,
      "impressions_clicks": null,
      "impressions_quotes": null,
      "impressions_updated_at": "2026-02-03T09:02:52.941336",
      "published_at": "2026-02-01T17:49:22",
      "scraped_at": "2026-02-03T09:02:52.941348",
      "metadata": {
        "item_type": "show_hn",
        "hn_url": "https://news.ycombinator.com/item?id=46850205",
        "kids_count": 47,
        "sections": [
          "best_stories",
          "show_hn"
        ]
      },
      "content_hash": "6a51b8d48ffa7dfbc372f1f9ed390ab6",
      "classification": {
        "is_ai_relevant": true,
        "primary_topic": "developer_tools",
        "primary_topic_label": "Developer Tools",
        "all_topics": [
          "llm",
          "ml_research",
          "developer_tools",
          "data_engineering"
        ],
        "topic_details": {
          "llm": {
            "raw_score": 1,
            "weighted_score": 1.0,
            "matched_keywords": [
              "claude"
            ],
            "label": "Large Language Models"
          },
          "ml_research": {
            "raw_score": 1,
            "weighted_score": 0.9,
            "matched_keywords": [
              "model"
            ],
            "label": "ML Research"
          },
          "developer_tools": {
            "raw_score": 3,
            "weighted_score": 1.7999999999999998,
            "matched_keywords": [
              "ide",
              "sdk",
              "framework"
            ],
            "label": "Developer Tools"
          },
          "data_engineering": {
            "raw_score": 1,
            "weighted_score": 0.5,
            "matched_keywords": [
              "sql"
            ],
            "label": "Data Engineering"
          }
        },
        "relevance_score": 0.42,
        "is_noise": false,
        "filter_reason": null
      },
      "engagement_quality": {
        "engagement_ratio": 0.43,
        "is_flamewar": false,
        "is_high_signal": true,
        "is_emerging": false,
        "discussion_depth": 4.66,
        "velocity": 13.06,
        "hours_old": 39.4,
        "quality_tier": "high_quality"
      },
      "editorial": {
        "one_liner": "New developer tools project worth checking out",
        "why_it_matters": "highly upvoted by HN community; quality discussion",
        "audience_fit": "Software developers",
        "newsletter_priority": 3
      }
    },
    {
      "id": "4730842ec7d3c90bde1ad7ebce321ea5",
      "source": "hackernews",
      "source_id": "46852660",
      "title": "Leaked chats expose the daily life of a scam compound's enslaved workforce",
      "content": "Just before 8amone day last April, an office manager who went by the name Amani sent out a motivational message to his colleagues and subordinates. ‚ÄúEvery day brings a new opportunity‚Äîa chance to connect, to inspire, and to make a difference,‚Äù he wrote in his 500-word post to an office-wide WhatsApp group. ‚ÄúTalk to that next customer like you're bringing them something valuable‚Äîbecause you are.‚Äù\n\nAmani wasn‚Äôt rallying a typical corporate sales team. He and his underlings worked inside a ‚Äúpig butchering‚Äù compound, a criminal operation built to carry outscams‚Äîpromising romance and riches fromcryptoinvestments‚Äîthatoftendefraud victims out of hundreds of thousands or even millions of dollars at a time.\n\nRead the full story of WIRED's source, Mohammad Muzahir,here.\n\nThe workers Amani was addressing were eight hours into their 15-hour night shift in a high-rise building in the Golden Triangle special economic zone in Northern Laos. Like their marks, most of them were victims, too: forced laborers trapped in the compound, held in debt bondage with no passports. They struggled to meet scam revenue quotas to avoid fines that deepened their debt. Anyone who broke rules or attempted to escape faced far worse consequences: beatings, torture, even death.\n\nThe bizarre reality of daily life in a Southeast Asian scam compound‚Äîthe tactics, the tone, the mix of cruelty and upbeat corporate prattle‚Äîis revealed at an unprecedented level of resolution in a leak of documents to WIRED from a whistleblower inside one such sprawling fraud operation. The facility, known as the Boshang compound, is one of dozens of scam operations across Southeast Asia that have enslaved hundreds of thousands of people. Often lured from the poorest regions of Asia and Africa with fake job offers, these conscripts have become engines of the most lucrative form of cybercrime in the world, coerced into stealing tens of billions of dollars.\n\nLast June, one of those forced laborers, an Indian man named Mohammad Muzahir, contacted WIRED while he was still captive inside the scam compound that had trapped him. Over the following weeks, Muzahir, who initially identified himself only as ‚ÄúRed Bull,‚Äù shared with WIRED a trove of information about the scam operation. His leaks included internal documents, scam scripts, training guides, operational flowcharts, and photographs and videos from inside the compound.\n\nOf all Muzahir‚Äôs leaks, the most revealing is a collection of screen recordings in which he scrolled through three months‚Äô worth of the compound‚Äôs internal WhatsApp group chats. Those videos, which WIRED converted into 4,200 pages of screenshots, capture hour-by-hour conversations between the compound‚Äôs workers and their bosses‚Äîand the nightmare workplace culture of a pig butchering organization.\n\n‚ÄúIt‚Äôs a slave colony that‚Äôs trying to pretend it‚Äôs a company,‚Äù says Erin West, a former Santa Clara County, California, prosecutor who leads an anti-scam organization called Operation Shamrock and who reviewed the chat logs obtained by WIRED. Another researcher who reviewed the leaked chat logs, Jacob Sims of Harvard University‚Äôs Asia Center, also remarked on their ‚ÄúOrwellian veneer of legitimacy.‚Äù\n\n‚ÄúIt‚Äôs terrifying, because it‚Äôs manipulationandcoercion,‚Äù says Sims, who studies Southeast Asian scam compounds. ‚ÄúCombining those two things together motivates people the most. And it‚Äôs one of the key reasons why these compounds are so profitable.‚Äù\n\nIn another chat message, sent within hours of Amani‚Äôs saccharine pep talk, a higher-level boss weighed in: ‚ÄúDon't resist the company's rules and regulations,‚Äù he wrote. ‚ÄúOtherwise you can't survive here.‚Äù The staffers responded with 26 emoji reactions, all thumbs-ups and salutes.\n\nScam compound whistleblower Mohammad Muzahir, photographed in India after returning home from his ordeal as a forced laborer in the Golden Triangle.\n\nFined Into Slavery\n\nIn total, accordingto WIRED‚Äôs analysis of the group chat, more than 30 of the compound‚Äôs workers successfully defrauded at least one victim in the 11 weeks of records available, totaling to around $2.2 million in stolen funds. Yet the bosses in the chat frequently voiced their disappointment in the group‚Äôs performance, berated the staff for lack of effort, and imposed fine after fine.\n\nRather than explicit imprisonment, the compound relied on a system of indentured servitude and debt to control its workers. As Muzahir described it, he was paid a base salary of 3,500 Chinese yuan a month (about $500), which in theory entailed 75 hours a week of night shifts including breaks to eat. Although his passport had been taken from him, he was told that if he could pay off his ‚Äúcontract‚Äù with a $5,400 payment, it would be returned to him and he would be allowed to leave.\n\nIn reality, the WhatsApp chats reveal how even that meager salary was almost entirely chipped away with fines. One message warns that anyone who fails to start a ‚Äúfirst chat‚Äù‚Äîan introductory conversation with a scam victim‚Äîon any given day will be fined 50 yuan, and the failure will be announced to the group. Filing a false progress report results in a fine of 1,000 yuan. Falling asleep in the office, or ‚Äúwatching unrelated video, chatting with friends, and any activity that is not related to the job‚Äù are each punishable with a 200 yuan fine, as is any ‚Äúdisturbance‚Äù in the dormitory, where workers sleep five or six to a room in bunk beds.\n\nOne message notes a fine of 500 yuan for a worker who slept late, and another fined 200 yuan for not being in the dorm at ‚Äúcheck-in time‚Äù following his shift. Resist a fine by not signing a form that admits to the misbehavior, and the fine is doubled.\n\nAn org chart for part of the Boshang scam compound, assembled from leaked messages and Muzahir‚Äôs knowledge of the operation.\n\nMuzahir himself described being fined so much that he was virtually broke. The food in the office cafeteria was also frequently denied as a punishment, the messages showed, with workers‚Äô ID badges that granted access to the canteen sometimes being taken away for seven days for small infractions like tardiness. Even the freedom to bring in snacks and drinks‚Äîother than betel nuts, a stimulant‚Äîcould be rescinded if staff underperformed. Time off was also withheld, with staff sometimes forced to work seven nights a week, Muzahir says.\n\nYet those punishments could be avoided, the bosses frequently promised, if they successfully scammed someone‚Äîor ‚Äúopened a customer,‚Äù as the bosses euphemistically described scamming a new victim. (Scamming the same victim multiple times was called a ‚Äúrecharge.‚Äù) In theory, workers were entitled to a commission, over and above their salary, for any scams they pulled off. Muzahir says he successfully perpetrated two scams during his months in the compound‚Äîboth of which left him racked with regret, he says‚Äîand he was never paid after either of them.\n\nBosses nonetheless used workers‚Äô illusory hope of paying off their debt‚Äîor even going home rich‚Äîas a motivator. ‚ÄúI understand‚Äîwhen penalties or fines come your way, it's easy to feel disheartened. But I urge you not to see it as a punishment, but as a lesson and an investment in your own growth,‚Äù wrote Amani. ‚ÄúDon't fear the fine. Let it fuel your fire.‚Äù\n\nThe more senior boss, who went by the name Da Hai, spelled out the carrot-and-stick approach more clearly. ‚ÄúThe company's incentives are much higher than the fines, so as long as you work hard to open new customers you will receive a generous reward!‚Äù he wrote.\n\nOne of the bosses‚Äô tactics was to play teams off one another, reprimanding underperforming workers while pointing to the success of other scammers in the compound. Each room of the office appears to have had a Chinese ceremonial drum, played when a worker successfully scammed a victim for a six-figure sum. ‚ÄúDo you know why the next office is beating drums?‚Äù wrote a higher-level boss called Alang.\n\nA victim had paid ‚Äú480k,‚Äù a boss who goes by the name Libo answers.\n\n‚ÄúIt doesn't matter, because he belongs to others,‚Äù Alang responds. ‚ÄúThe important thing is, which one of you can play the drum?‚Äù\n\nUnder the Pretense, a Brutal Reality\n\nBeyond these manipulativetactics, the messages occasionally offer glimpses of a far harsher reality‚Äîas does the personal experience and testimony of Muzahir himself. Muzahir describes hearing stories of people who were tortured and says he was himself threatened by Amani with beating and electrocution if he didn‚Äôt find new ‚Äúclients.‚Äù Sometimes coworkers disappeared without explanation.\n\nEventually Muzahir came up with a plan to trick his captors into letting him leave. When the bosses caught on, he was held in a room, beaten, slapped and kicked, denied food and water, and made to drink a solution with a white powder dissolved in it, which seems to have been intended to make him more cooperative with their interrogation.\n\nOccasional messages in the chat logs hint that these cruel punishments lurked underneath the compound‚Äôs motivational messages. At one point, the boss Alang mentions a girl who ‚Äúsneaked away from the company and went to work in a brothel,‚Äù and another person in the group mentions that the ‚Äúcompany‚Äù still holds her passport. Among the captive workers, Muzahir says, rumor had it that the girl was in fact sold into prostitution, a practice documented in other accounts from scam compound survivors.\n\nAt another point, while chastising the group for underperformance, the boss Da Hai hints at the large sum of money workers needed to produce if they ever hoped to leave the compound. ‚ÄúYou continue to violate the company's regulations,‚Äù he writes to the group. ‚ÄúIf you continue like this, please prepare your compensation and get out of here.‚Äù\n\nSuch references to paying ‚Äúcompensation‚Äù for release are in fact ‚Äúcoded words for ransom and debt bondage,‚Äù says Harvard‚Äôs Sims. The nation of Laos, Sims points out, is a signatory to the Palermo Protocol, which classifies anyone held in debt and forced to work witho",
      "url": "https://www.wired.com/story/the-red-bull-leaks/",
      "author_username": "smurda",
      "author_category": "unknown",
      "media": [
        {
          "type": "image",
          "url": "https://media.wired.com/photos/695d063065851e41961fe045/master/w_775%2Cc_limit/WIRED-FFRedBull-TheoTagholm-1-1080.jpg",
          "alt": "Image may contain: City, Road, Street, Urban, Plant, Vegetation, Person, Walking, Palm Tree, Tree, Path, Helmet, and Outdoors"
        },
        {
          "type": "image",
          "url": "https://media.wired.com/photos/6968ea994dea1b57de3194ff/master/w_1600%2Cc_limit/_SMK7032%2520copy.jpg",
          "alt": "Image may contain Head Person Face Adult Crew Cut Hair Beard Photography and Portrait"
        },
        {
          "type": "image",
          "url": "https://media.wired.com/photos/6978d437c34fab0603ed21e7/master/w_1600%2Cc_limit/FFRedBull-OrgChart-V3.jpg",
          "alt": "Image may contain Text"
        },
        {
          "type": "image",
          "url": "https://media.wired.com/photos/69781980daea25e5eeb79a97/master/w_1600%2Cc_limit/WIRED-FFRedBull-SourceImage-3_WIRED-FFRedBull-SourceImage-3_ALTCREDIT.jpg",
          "alt": "Image may contain Plant Potted Plant and Lighting"
        },
        {
          "type": "image",
          "url": "https://media.wired.com/photos/69735b228b7aaa4c8f551ec2/master/w_1600%2Cc_limit/WIRED-RedBullFollowUp-Schedule.jpg",
          "alt": "An example of the schedules workers were required to post daily‚Äînot for themselves but for the wealthy female personas..."
        }
      ],
      "impressions_views": null,
      "impressions_likes": 273,
      "impressions_reposts": 0,
      "impressions_replies": 154,
      "impressions_bookmarks": null,
      "impressions_clicks": null,
      "impressions_quotes": null,
      "impressions_updated_at": "2026-02-03T09:02:57.719813",
      "published_at": "2026-02-02T00:10:59",
      "scraped_at": "2026-02-03T09:02:57.719829",
      "metadata": {
        "item_type": "story",
        "hn_url": "https://news.ycombinator.com/item?id=46852660",
        "kids_count": 21,
        "sections": [
          "best_stories"
        ]
      },
      "content_hash": "ec2a382b8cb69adb066fd5bd52cd6505",
      "classification": {
        "is_ai_relevant": true,
        "primary_topic": "ml_research",
        "primary_topic_label": "ML Research",
        "all_topics": [
          "ml_research",
          "ai_ethics",
          "developer_tools"
        ],
        "topic_details": {
          "ml_research": {
            "raw_score": 1,
            "weighted_score": 0.9,
            "matched_keywords": [
              "training"
            ],
            "label": "ML Research"
          },
          "ai_ethics": {
            "raw_score": 1,
            "weighted_score": 0.8,
            "matched_keywords": [
              "regulation"
            ],
            "label": "AI Ethics & Safety"
          },
          "developer_tools": {
            "raw_score": 1,
            "weighted_score": 0.6,
            "matched_keywords": [
              "ide"
            ],
            "label": "Developer Tools"
          }
        },
        "relevance_score": 0.23,
        "is_noise": false,
        "filter_reason": null
      },
      "engagement_quality": {
        "engagement_ratio": 0.56,
        "is_flamewar": false,
        "is_high_signal": false,
        "is_emerging": false,
        "discussion_depth": 7.33,
        "velocity": 8.26,
        "hours_old": 33.1,
        "quality_tier": "good"
      },
      "editorial": {
        "one_liner": "ML Research insight worth reading",
        "why_it_matters": "directly relevant to AI practitioners",
        "audience_fit": "AI engineers & researchers",
        "newsletter_priority": 3
      }
    },
    {
      "id": "b9dd86d46b75c5d9f8dc60e758e2c456",
      "source": "hackernews",
      "source_id": "46850588",
      "title": "Two kinds of AI users are emerging",
      "content": "It still shocks me how much difference there is between AI users. I think it explains a lot about the often confusing (to me) coverage in the media about AI and its productivity impact.\n\nI think it's clear there are two types of users to me now, and by extension, the organisations they work for.\n\nFirst, you have the \"power users\", who are all in on adopting new AI technology - Claude Code, MCPs, skills, etc. Surprisingly, these people are oftennot very technical. I've seen far more non-technical people than I'd expect using Claude Code in terminal, using it for dozens of non-SWE tasks. Finance roles seem to be getting enormous value out of it (unsurprisingly, as Excel on the finance side is remarkably limiting when you start getting used to the power of a full programming ecosystem like Python).\n\nSecondly, you have the people who are generally only chatting to ChatGPT or similar.So manypeople I wouldn't expect are still in this camp.\n\nM365 Copilot has a lot to answer for\n\nOne extremely jarring realisation was just how poor Microsoft Copilot is. It hasenormousmarket share in enterprise as it is bundled in with various Office 365 subscriptions, yet feels like a poorly cloned version of the (already not great) ChatGPT interface. The \"agent\" feature is absolutely laughable compared to what a CLI coding agent (including Microsoft's own GitHub confusingly-named-Copilot CLI).\n\nTo really underline this, Microsoft itself is rolling out Claude Code to internal teams[1], despite (obviously) having access to Copilot at near zero cost, and significant ownership of OpenAI. I think this sums up quite how far behind they are\n\nThe problem is that in enterprise Copilot is often the only allowed AI tool, so that's all you can use without either potentially losing your job or spending a lot of effort trying to procure and use another AI tool. It's slow, the code execution tool in it doesn't work properly and fails horribly with large(ish) files, seemingly due to very very aggressive memory and CPU limitations.\n\nThis is becoming an existential risk for many enterprises. Senior decision makers are no doubt using these tools with such poor results and are therefore writing off AI, and/or spending a fortune with various large consulting and management consultancy outfits to get not very far.\n\nWhy enterprise is so at risk\n\nEnterprise corporate IT policy results in a completely disastrous combination of limitations that basically ensure that people cannot successfully use more 'cutting edge' AI tooling.\n\nFirstly, they tend to have extremely locked down environments, with no ability to run even a basic script interpreter locally (VBA if you are lucky, but even that may be limited by various Group Policies). Secondly, they're locked into legacy software with no real \"internal facing\" APIs on their core workflows, which means agents have nothing to connect to even if you could run them.\n\nFinally, they tend to have extremely siloed engineering departments (which may be completely outsourced), so there's nobody internally who could build the infrastructure to run safely sandboxed agents even if they wanted to.\n\nThe security concerns are real. You definitely do not want people YOLOing coding agents over production databases with no control, andas I've covered, sandboxing agents isdifficult[2].\n\nHowever, this does cause a real problem in so much that you don't have an engineering team that can help build the infrastructure to run safely sandboxed agents against your datasets.\n\nThe gap\n\nI've also spoken to many smaller companies that don't have all this baggage and areabsolutely flyingwith AI. The gap is so obvious when you can see both sides of it.\n\nOn one hand, you have Microsoft's (awful) Copilot integration for Excel (in fairness, the Gemini integration in Google Sheets is also bad). So you can imagine financial directors trying to use it and it making a complete mess of the most simple tasks and never touching it again.\n\nOn the other you have a non-technical executive who's got his head round Claude Code and can run e.g. Python locally. I helped one recently almost one-shot[3]converting a 30 sheet mind numbingly complicated Excel financial model to Python with Claude Code.\n\nOnce the model is in Python, you effectively have a data science team in your pocket with Claude Code. You can easily run Monte Carlo simulations, pull external data sources as inputs, build web dashboards and have Claude Code work with you to really integrate weaknesses in your model (or business). It's a pretty magical experience watching someone realise they have so much power at their fingertips, without having to grind away for hours/days in Excel.\n\nThis effectively leads to a situation where smaller company employees are able to beso muchmore productive than the equivalent at an enterprise. It often used to be that people at small companies really envied the resources & teams that their larger competitors had access to - but increasingly I think the pendulum is swinging the other way.\n\nThe future\n\nI'm starting to get a feel for what the future of work looks like. The first observation is that (often) the real leaps are being made organically by employees, not from a top down AI strategy. Where I see the real productivity gains are small teams deciding to try and build an AI assisted workflow for a process, and as they are the ones that know that process inside out they can get very good results - unlike an often outsourced software engineering team who have absolutely zero experience doing the process that they are helping automate. I think this is the opposite of what most 'digital transformation' projects looked like in enterprise.\n\nSecondly, companies that have some sort of APIs forinternalsystems are going to be able to do far more than those that don't. This might be as simple as a readonly data warehouse employees can connect to and run queries on behalf of users, or it could be as far as many complex core business processes being completely APId.\n\nThirdly, this all needs to be wrapped up in some sort of secure mechanism, but I actually think a hosted VM running some sort of code agent with well thought through network restrictions would work well, at least for read only reporting. For creating and editing data I don't think we quite have the model for non technical users (especially) to be able to use agents safely (yet).\n\nFinally, legacy enterprise SaaS players either have enormous lock in, or are extremely vulnerable depending on how you look at it. Most are not \"API-first\" products, and the APIs they have tend to be really for developer usage - not optimised for thousands of employees to ping in weird and wonderful inefficient ways. But if they are the source of truth for the company, they are going to be very difficult to migrate away fromandbottleneck a lot of productivity gains.\n\nAgain, smaller companies tend to use newer products which have far better thought through APIs (simply because they weren't often originally created many decades ago with various interfaces grafted on over time).\n\nThe user prompts, the agent synthesises - connecting to APIs and producing outputs on demand.\n\nWhat I've come to realise is that the power of having abash sandboxwith a programming language and API access to systems, combined with an agentic harness, results in outrageously good results for non technical users. It can effectively replace nearly every standard productivity app out there - both classic Microsoft Office style ones - and also web apps. It can build any report you ask for - and export it however you like. To me this seems like the future of knowledge work.\n\nThe bifurcation is real and seems to be, if anything, speeding up dramatically. I don't think there's ever been a time in history where a tiny team can outcompete a company one thousand times its size so easily.\n\nMicrosoft is using Claude Code internally while selling you Copilot‚Ü©Ô∏é\n\nMicrosoft is using Claude Code internally while selling you Copilot‚Ü©Ô∏é\n\nLet's keep in mind that users already have access to these systems. CISOs need to figure out how to enable these kind of secure VMs en masse. There's already precedent for this with Codespaces - it just requires a similar approach scaled up to the entire organisation.‚Ü©Ô∏é\n\nLet's keep in mind that users already have access to these systems. CISOs need to figure out how to enable these kind of secure VMs en masse. There's already precedent for this with Codespaces - it just requires a similar approach scaled up to the entire organisation.‚Ü©Ô∏é\n\nTwo or three prompts got it there, using plan mode to figure out the structure of the Excel sheet, then prompting to implement it. It even added unit tests to the Python model itself, which I was impressed with!‚Ü©Ô∏é\n\nTwo or three prompts got it there, using plan mode to figure out the structure of the Excel sheet, then prompting to implement it. It even added unit tests to the Python model itself, which I was impressed with!‚Ü©Ô∏é\n\nIf you found this useful, I write about AI tooling and software development monthly.Subscribe hereor drop your email:",
      "url": "https://martinalderson.com/posts/two-kinds-of-ai-users-are-emerging/",
      "author_username": "martinald",
      "author_category": "unknown",
      "media": [],
      "impressions_views": null,
      "impressions_likes": 333,
      "impressions_reposts": 0,
      "impressions_replies": 324,
      "impressions_bookmarks": null,
      "impressions_clicks": null,
      "impressions_quotes": null,
      "impressions_updated_at": "2026-02-03T09:02:57.143563",
      "published_at": "2026-02-01T18:45:18",
      "scraped_at": "2026-02-03T09:02:57.143587",
      "metadata": {
        "item_type": "story",
        "hn_url": "https://news.ycombinator.com/item?id=46850588",
        "kids_count": 52,
        "sections": [
          "best_stories"
        ]
      },
      "content_hash": "e8d7623c99f15322b33e834d2570c1d3",
      "classification": {
        "is_ai_relevant": true,
        "primary_topic": "llm",
        "primary_topic_label": "Large Language Models",
        "all_topics": [
          "llm",
          "ml_research",
          "ai_product",
          "ai_infra",
          "developer_tools",
          "data_engineering"
        ],
        "topic_details": {
          "llm": {
            "raw_score": 8,
            "weighted_score": 8.0,
            "matched_keywords": [
              "gpt",
              "claude",
              "gemini",
              "openai",
              "chatgpt",
              "copilot",
              "coding agent",
              "agentic"
            ],
            "label": "Large Language Models"
          },
          "ml_research": {
            "raw_score": 1,
            "weighted_score": 0.9,
            "matched_keywords": [
              "model"
            ],
            "label": "ML Research"
          },
          "ai_product": {
            "raw_score": 1,
            "weighted_score": 0.85,
            "matched_keywords": [
              "ai tool"
            ],
            "label": "AI Products"
          },
          "ai_infra": {
            "raw_score": 1,
            "weighted_score": 0.9,
            "matched_keywords": [
              "tpu"
            ],
            "label": "AI Infrastructure"
          },
          "developer_tools": {
            "raw_score": 6,
            "weighted_score": 3.5999999999999996,
            "matched_keywords": [
              "developer",
              "ide",
              "programming",
              "coding",
              "software engineering",
              "api"
            ],
            "label": "Developer Tools"
          },
          "data_engineering": {
            "raw_score": 2,
            "weighted_score": 1.0,
            "matched_keywords": [
              "database",
              "data warehouse"
            ],
            "label": "Data Engineering"
          }
        },
        "relevance_score": 1.0,
        "is_noise": false,
        "filter_reason": null
      },
      "engagement_quality": {
        "engagement_ratio": 0.97,
        "is_flamewar": false,
        "is_high_signal": false,
        "is_emerging": false,
        "discussion_depth": 6.23,
        "velocity": 8.65,
        "hours_old": 38.5,
        "quality_tier": "good"
      },
      "editorial": {
        "one_liner": "Large Language Models insight worth reading",
        "why_it_matters": "highly upvoted by HN community; directly relevant to AI practitioners",
        "audience_fit": "AI engineers & researchers",
        "newsletter_priority": 3
      }
    },
    {
      "id": "31cd7da178429185ff9190e0495de026",
      "source": "hackernews",
      "source_id": "46855447",
      "title": "Nano-vLLM: How a vLLM-style inference engine works",
      "content": "Architecture, Scheduling, and the Path from Prompt to Token\n\nWhen deploying large language models in production, the inference engine becomes a critical piece of infrastructure. Every LLM API you use √¢¬Ä¬î OpenAI, Claude, DeepSeek √¢¬Ä¬î is sitting on top of an inference engine like this. While most developers interact with LLMs through high-level APIs, understanding what happens beneath the surface√¢¬Ä¬îhow prompts are processed, how requests are batched, and how GPU resources are managed√¢¬Ä¬îcan significantly impact system design decisions.\n\nThis two-part series explores these internals throughNano-vLLM, a minimal (~1,200 lines of Python) yet production-grade implementation that distills the core ideas behindvLLM, one of the most widely adopted open-source inference engines.\n\nNano-vLLM was created by a contributor to DeepSeek, whose name appears on the technical reports of models like DeepSeek-V3 and R1. Despite its minimal codebase, it implements the essential features that make vLLM production-ready: prefix caching, tensor parallelism, CUDA graph compilation, and torch compilation optimizations. Benchmarks show it achieving throughput comparable to√¢¬Ä¬îor even slightly exceeding√¢¬Ä¬îthe full vLLM implementation. This makes it an ideal lens for understanding inference engine design without getting lost in the complexity of supporting dozens of model architectures and hardware backends.\n\nIn Part 1, we focus on the engineering architecture: how the system is organized, how requests flow through the pipeline, and how scheduling decisions are made. We will treat the actual model computation as a black box for now√¢¬Ä¬îPart 2 will open that box to explore attention mechanisms, KV cache internals, and tensor parallelism at the computation level.\n\nThe Main Flow: From Prompt to Output\n\nThe entry point to Nano-vLLM is straightforward: anLLMclass with ageneratemethod. You pass in an array of prompts and sampling parameters, and get back the generated text. But behind this simple interface lies a carefully designed pipeline that transforms text into tokens, schedules computation efficiently, and manages GPU resources.\n\nFrom Prompts to Sequences\n\nWhengenerateis called, each prompt string goes through a tokenizer√¢¬Ä¬îa model-specific component that splits natural language into tokens, the fundamental units that LLMs process. Different model families (Qwen, LLaMA, DeepSeek) use different tokenizers, which is why a prompt of the same length may produce different token counts across models. The tokenizer converts each prompt into asequence: an internal data structure representing a variable-length array of token IDs. This sequence becomes the core unit of work flowing through the rest of the system.\n\nThe Producer-Consumer Pattern\n\nHere√¢¬Ä¬ôs where the architecture gets interesting. Rather than processing each sequence immediately, the system adopts a producer-consumer pattern with the Scheduler at its center. Theadd_requestmethod acts as the producer: it converts prompts to sequences and places them into the Scheduler√¢¬Ä¬ôs queue. Meanwhile, a separatestep loopacts as the consumer, pulling batches of sequences from the Scheduler for processing. This decoupling is key√¢¬Ä¬îit allows the system to accumulate multiple sequences and process them together, which is where the performance gains come from.\n\nBatching and the Throughput-Latency Trade-off\n\nWhy does batching matter? GPU computation has significant fixed overhead√¢¬Ä¬îinitializing CUDA kernels, transferring data between CPU and GPU memory, and synchronizing results. If you process one sequence at a time, you pay this overhead for every single request. By batching multiple sequences together, you amortize this overhead across many requests, dramatically improving overall throughput.\n\nHowever, batching comes with a trade-off. When three prompts are batched together, each must wait for the others to complete before any results are returned. The total time for the batch is determined by the slowest sequence. This means: larger batches yield higher throughput but potentially higher latency for individual requests; smaller batches yield lower latency but reduced throughput. This is a fundamental tension in inference engine design, and the batch size parameters you configure directly control this trade-off.\n\nPrefill vs. Decode: Two Phases of Generation\n\nBefore diving into the Scheduler, we need to understand a crucial distinction. LLM inference happens in two phases:\n\nPrefill: Processing the input prompt. All input tokens are processed together to build up the model√¢¬Ä¬ôs internal state. During this phase, the user sees nothing.\n\nDecode: Generating output tokens. The model produces one token at a time, each depending on all previous tokens. This is when you see text streaming out.\n\nFor a single sequence, there is exactly one prefill phase followed by many decode steps. The Scheduler needs to distinguish between these phases because they have very different computational characteristics√¢¬Ä¬îprefill processes many tokens at once, while decode processes just one token per step.\n\nInside the Scheduler\n\nThe Scheduler is responsible for deciding which sequences to process and in what order. It maintains two queues:\n\nWaiting and Running Queues\n\nWaiting Queue: Sequences that have been submitted but not yet started. New sequences fromadd_requestalways enter here first.\n\nRunning Queue: Sequences that are actively being processed√¢¬Ä¬îeither in prefill or decode phase.\n\nWhen a sequence enters the Waiting queue, the Scheduler checks with another component called the Block Manager to allocate resources for it. Once allocated, the sequence moves to the Running queue. The Scheduler then selects sequences from the Running queue for the next computation step, grouping them into a batch along with an action indicator (prefill or decode).\n\nHandling Resource Exhaustion\n\nWhat happens when GPU memory fills up? The KV cache (which stores intermediate computation results) has limited capacity. If a sequence in the Running queue cannot continue because there√¢¬Ä¬ôs no room to store its next token√¢¬Ä¬ôs cache, the Schedulerpreemptsit√¢¬Ä¬îmoving it back to the front of the Waiting queue. This ensures the sequence will resume as soon as resources free up, while allowing other sequences to make progress.\n\nWhen a sequence completes (reaches an end-of-sequence token or maximum length), the Scheduler removes it from the Running queue and deallocates its resources, freeing space for waiting sequences.\n\nThe Block Manager: KV Cache Control Plane\n\nThe Block Manager is where vLLM√¢¬Ä¬ôs memory management innovation lives. To understand it, we first need to introduce a new resource unit: theblock.\n\nFrom Sequences to Blocks\n\nA sequence is a variable-length array of tokens√¢¬Ä¬îit can be 10 tokens or 10,000. But variable-length allocations are inefficient for GPU memory management. The Block Manager solves this by dividing sequences into fixed-sizeblocks(default: 256 tokens each).\n\nA 700-token sequence would occupy three blocks: two full blocks (256 tokens each) and one partial block (188 tokens, with 68 slots unused). Importantly, tokens from different sequences never share a block√¢¬Ä¬îbut a long sequence will span multiple blocks.\n\nPrefix Caching via Hashing\n\nHere√¢¬Ä¬ôs where it gets clever. Each block√¢¬Ä¬ôs content is hashed, and the Block Manager maintains a hash-to-block-id mapping. When a new sequence arrives, the system computes hashes for its blocks and checks if any already exist in the cache.\n\nIf a block with the same hash exists, the system reuses it by incrementing a reference count√¢¬Ä¬îno redundant computation or storage needed. This is particularly powerful for scenarios where many requests share common prefixes (like system prompts in chat applications). The prefix only needs to be computed once; subsequent requests can reuse the cached results.\n\nControl Plane vs. Data Plane\n\nA subtle but important point: the Block Manager lives in CPU memory and only tracksmetadata√¢¬Ä¬îwhich blocks are allocated, their reference counts, and hash mappings. The actual KV cache data lives on the GPU. The Block Manager is thecontrol plane; the GPU memory is thedata plane. This separation allows fast allocation decisions without touching GPU memory until actual computation happens.\n\nWhen blocks are deallocated, the Block Manager marks them as free immediately, but the GPU memory isn√¢¬Ä¬ôt zeroed√¢¬Ä¬îit√¢¬Ä¬ôs simply overwritten when the block is reused. This avoids unnecessary memory operations.\n\nThe Model Runner: Execution and Parallelism\n\nThe Model Runner is responsible for actually executing the model on GPU(s). When the step loop retrieves a batch of sequences from the Scheduler, it passes them to the Model Runner along with the action (prefill or decode).\n\nTensor Parallel Communication\n\nWhen a model is too large for a single GPU, Nano-vLLM supportstensor parallelism(TP)√¢¬Ä¬îsplitting the model across multiple GPUs. With TP=8, for example, eight GPUs work together to run a single model.\n\nThe communication architecture uses a leader-worker pattern:\n\nRank 0 (Leader): Receives commands from the step loop, executes its portion, and coordinates with workers.\n\nRanks 1 to N-1 (Workers): Continuously poll a shared memory buffer for commands from the leader.\n\nWhen the leader receives aruncommand, it writes the method name and arguments to shared memory. Workers detect this, read the parameters, and execute the same operation on their respective GPUs. Each worker knows its rank, so it can compute its designated portion of the work. This shared-memory approach is efficient for single-machine multi-GPU setups, avoiding network overhead.\n\nPreparing for Computation\n\nBefore invoking the model, the Model Runner prepares the input based on the action:\n\nPrepare Prefill: Batches multiple sequences with variable lengths, computing cumulative sequence lengths for efficient attention computation.\n\nPrepare Decode: Batches single tokens (one per sequence) with their positions and slot mappings for KV cache ",
      "url": "https://neutree.ai/blog/nano-vllm-part-1",
      "author_username": "yz-yu",
      "author_category": "unknown",
      "media": [],
      "impressions_views": null,
      "impressions_likes": 262,
      "impressions_reposts": 0,
      "impressions_replies": 26,
      "impressions_bookmarks": null,
      "impressions_clicks": null,
      "impressions_quotes": null,
      "impressions_updated_at": "2026-02-03T09:02:32.046749",
      "published_at": "2026-02-02T07:52:35",
      "scraped_at": "2026-02-03T09:02:32.046760",
      "metadata": {
        "item_type": "story",
        "hn_url": "https://news.ycombinator.com/item?id=46855447",
        "kids_count": 6,
        "sections": [
          "top_stories",
          "best_stories"
        ]
      },
      "content_hash": "5fa51936c8780c58921ea1e324690ad1",
      "classification": {
        "is_ai_relevant": true,
        "primary_topic": "llm",
        "primary_topic_label": "Large Language Models",
        "all_topics": [
          "llm",
          "ml_research",
          "ai_infra",
          "developer_tools"
        ],
        "topic_details": {
          "llm": {
            "raw_score": 7,
            "weighted_score": 7.0,
            "matched_keywords": [
              "llm",
              "claude",
              "openai",
              "deepseek",
              "language model",
              "llama"
            ],
            "label": "Large Language Models"
          },
          "ml_research": {
            "raw_score": 5,
            "weighted_score": 4.5,
            "matched_keywords": [
              "inference",
              "model",
              "benchmark",
              "attention"
            ],
            "label": "ML Research"
          },
          "ai_infra": {
            "raw_score": 5,
            "weighted_score": 4.5,
            "matched_keywords": [
              "gpu",
              "cuda",
              "tpu",
              "vllm"
            ],
            "label": "AI Infrastructure"
          },
          "developer_tools": {
            "raw_score": 3,
            "weighted_score": 1.7999999999999998,
            "matched_keywords": [
              "developer",
              "ide",
              "api"
            ],
            "label": "Developer Tools"
          }
        },
        "relevance_score": 1.0,
        "is_noise": false,
        "filter_reason": null
      },
      "engagement_quality": {
        "engagement_ratio": 0.1,
        "is_flamewar": false,
        "is_high_signal": true,
        "is_emerging": false,
        "discussion_depth": 4.33,
        "velocity": 10.33,
        "hours_old": 25.4,
        "quality_tier": "good"
      },
      "editorial": {
        "one_liner": "Large Language Models insight worth reading",
        "why_it_matters": "quality discussion; directly relevant to AI practitioners",
        "audience_fit": "AI engineers & researchers",
        "newsletter_priority": 3
      }
    },
    {
      "id": "e86e67a49aa849351cfcbec19efcbeeb",
      "source": "hackernews",
      "source_id": "46854642",
      "title": "Termux",
      "content": "Termux application\n\nTermuxis an Android terminal application and Linux environment.\n\nNote that this repository is for the app itself (the user interface and the terminal emulation). For the packages installable inside the app, seetermux/termux-packages.\n\nQuick how-to about Termux package management is available atPackage Management. It also has info on how to fixrepository is under maintenance or downerrors when runningaptorpkgcommands.\n\nWe are looking for Termux Android application maintainers.\n\nNOTICE: Termux may be unstable on Android 12+.Android OS will kill any (phantom) processes greater than 32 (limit is for all apps combined) and also kill any processes using excessive CPU. You may get[Process completed (signal 9) - press Enter]message in the terminal without actually exiting the shell process yourself. Check the related issue#2366,issue tracker,phantom cached and empty processes docsandthis TLDR commenton how to disable trimming of phantom and excessive cpu usage processes. A proper docs page will be added later. An option to disable the killing should be available in Android 12L or 13, so upgrade at your own risk if you are on Android 11, specially if you are not rooted.\n\nContents\n\nTermux App and Plugins\n\nInstallation\n\nUninstallation\n\nImportant Links\n\nDebugging\n\nFor Maintainers and Contributors\n\nForking\n\nSponsors and Funders\n\nTermux App and Plugins\n\nThe coreTermuxapp comes with the following optional plugin apps.\n\nTermux:API\n\nTermux:Boot\n\nTermux:Float\n\nTermux:Styling\n\nTermux:Tasker\n\nTermux:Widget\n\nInstallation\n\nLatest version isv0.118.3.\n\nNOTICE: It is highly recommended that you update tov0.118.0or higher ASAP for various bug fixes, including a critical world-readable vulnerability reportedhere. Seebelowfor information regarding Termux on Google Play.\n\nTermux can be obtained through various sources listed below foronlyAndroid>= 7with full support for apps and packages.\n\nSupport for both app and packages was dropped for Android5and6on2020-01-01atv0.83, however it was re-added just for the appwithout any support for package updateson2022-05-24via theGitHubsources. Checkherefor the details.\n\nThe APK files of different sources are signed with different signature keys. TheTermuxapp and all its plugins use the samesharedUserIdcom.termuxand so all their APKs installed on a device must have been signed with the same signature key to work together and so they must all be installed from the same source. Do not attempt to mix them together, i.e do not try to install an app or plugin fromF-Droidand another one from a different source likeGitHub. Android Package Manager will also normally not allow installation of APKs with different signatures and you will get errors on installation likeApp not installed,Failed to install due to an unknown error,INSTALL_FAILED_UPDATE_INCOMPATIBLE,INSTALL_FAILED_SHARED_USER_INCOMPATIBLE,signatures do not match previously installed version, etc. This restriction can be bypassed with root or with custom roms.\n\nIf you wish to install from a different source, then you mustuninstall any and all existing Termux or its plugin app APKsfrom your device first, then install all new APKs from the same new source. CheckUninstallationsection for details. You may also want to considerBacking up Termuxbefore the uninstallation so that you can restore it after re-installing from Termux different source.\n\nIn the following paragraphs,\"bootstrap\"refers to the minimal packages that are shipped with thetermux-appitself to start a working shell environment. Its zips are built and releasedhere.\n\nF-Droid\n\nTermux application can be obtained fromF-Droidfromhere.\n\nYoudo notneed to download theF-Droidapp (via theDownload F-Droidlink) to install Termux. You can download the Termux APK directly from the site by clicking theDownload APKlink at the bottom of each version section.\n\nIt usually takes a few days (or even a week or more) for updates to be available onF-Droidonce an update has been released onGitHub. TheF-Droidreleases are built and published byF-Droidonce theydetecta newGitHubrelease. The Termux maintainersdo nothave any control over the building and publishing of the Termux apps onF-Droid. Moreover, the Termux maintainers also do not have access to the APK signing keys ofF-Droidreleases, so we cannot release an APK ourselves onGitHubthat would be compatible withF-Droidreleases.\n\nTheF-Droidapp often may not notify you of updates and you will manually have to do a pull down swipe action in theUpdatestab of the app for it to check updates. Make sure battery optimizations are disabled for the app, checkhttps://dontkillmyapp.com/for details on how to do that.\n\nOnly a universal APK is released, which will work on all supported architectures. The APK and bootstrap installation size will be~180MB.F-Droiddoesnot supportarchitecture specific APKs.\n\nGitHub\n\nTermux application can be obtained onGitHubeither fromGitHub Releasesfor version>= 0.118.0or fromGitHub Build Actionworkflows.For android>= 7, only installapt-android-7variants. For android5and6, only installapt-android-5variants.\n\nThe APKs forGitHub Releaseswill be listed underAssetsdrop-down of a release. These are automatically attached when a new version is released.\n\nThe APKs forGitHub Buildaction workflows will be listed underArtifactssection of a workflow run. These are created for each commit/push done to the repository and can be used by users who don't want to wait for releases and want to try out the latest features immediately or want to test their pull requests. Note that for action workflows, you need to belogged into aGitHubaccountfor theArtifactslinks to be enabled/clickable. If you are using theGitHubapp, then make sure to open workflow link in a browser like Chrome or Firefox that has your GitHub account logged in since the in-app browser may not be logged in.\n\nThe APKs for both of these aredebuggableand are compatible with each other but they are not compatible with other sources.\n\nBoth universal and architecture specific APKs are released. The APK and bootstrap installation size will be~180MBif using universal and~120MBif using architecture specific. Checkherefor details.\n\nSecurity warning: APK files on GitHub are signed with a test key that has beenshared with community. This IS NOT an official developer key and everyone can use it to generate releases for own testing. Be very careful when using Termux GitHub builds obtained elsewhere excepthttps://github.com/termux/termux-app. Everyone is able to use it to forge a malicious Termux update installable over the GitHub build. Think twice about installing Termux builds distributed via Telegram or other social media. If your device get caught by malware, we will not be able to help you.\n\nThetest keyshall not be used to impersonate @termux and can't be used for this anyway. This key is not trusted by us and it is quite easy to detect its use in user generated content.\n\nGoogle Play Store(Experimental branch)\n\nThere is currently a build of Termux available on Google Play for Android 11+ devices, with extensive adjustments in order to pass policy requirements there. This is under development and has missing functionality and bugs (seeherefor status updates) compared to the stable F-Droid build, which is why most users who can should still use F-Droid or GitHub build as mentioned above.\n\nCurrently, Google Play will try to update installations away from F-Droid ones. Updating will still fail assharedUserIdhas been removed. A planned 0.118.1 F-Droid release will fix this by setting a higher version code than used for the PlayStore app. Meanwhile, to prevent Google Play from attempting to download and then fail to install the Google Play releases over existing installations, you can open the Termux apps pages on Google Play and then click on the 3 dots options button in the top right and then disable the Enable auto update toggle. However, the Termux apps updates will still show in the PlayStore app updates list.\n\nIf you want to help out with testing the Google Play build (or cannot install Termux from other sources), be aware that it's built from a separate repository (https://github.com/termux-play-store/) - be sure to report issuesthere, as any issues encountered might very well be specific to that repository.\n\nUninstallation\n\nUninstallation may be required if a user doesn't want Termux installed in their device anymore or is switching to a differentinstall source. You may also want to considerBacking up Termuxbefore the uninstallation.\n\nTo uninstall Termux completely, you must uninstallany and all existing Termux or its plugin app APKslisted inTermux App and Plugins.\n\nGo toAndroid Settings->Applicationsand then look for those apps. You can also use the search feature if it‚Äôs available on your device and searchtermuxin the applications list.\n\nEven if you think you have not installed any of the plugins, it's strongly suggested to go through the application list in Android settings and double-check.\n\nImportant Links\n\nCommunity\n\nAll community links are availablehere.\n\nThe main ones are the following.\n\nTermux Reddit community\n\nTermux User Matrix Channel(Gitter)\n\nTermux Dev Matrix Channel(Gitter)\n\nTermux X (Twitter)\n\nTermux Support Email\n\nWikis\n\nTermux Wiki\n\nTermux App Wiki\n\nTermux Packages Wiki\n\nMiscellaneous\n\nFAQ\n\nTermux File System Layout\n\nDifferences From Linux\n\nPackage Management\n\nRemote Access\n\nBacking up Termux\n\nTerminal Settings\n\nTouch Keyboard\n\nAndroid Storage and Sharing Data with Other Apps\n\nAndroid APIs\n\nMoved Termux Packages Hosting From Bintray to IPFS\n\nRunning Commands in Termux From Other Apps viaRUN_COMMANDintent\n\nTermux and Android 10\n\nTerminal\n\nTerminal resources\n\nXTerm control sequences\n\nvt100.net\n\nTerminal codes (ANSI and terminfo equivalents)\n\nTerminal emulators\n\nVTE (libvte): Terminal emulator widget for GTK+, mainly used in gnome-terminal.Source,Open Issues, andAll (including closed) issues.\n\nVTE (libvte): Terminal emulator widget for GTK+, mainly used in gnome-terminal.Sourc",
      "url": "https://github.com/termux/termux-app",
      "author_username": "tosh",
      "author_category": "unknown",
      "media": [
        {
          "type": "image",
          "url": "https://camo.githubusercontent.com/9c14d4fbfda6abb126a406d570f172f45e72876e28ef385f719e8e823dd58014/68747470733a2f2f6261646765732e6769747465722e696d2f7465726d75782f7465726d75782e737667",
          "alt": "Join the chat at https://gitter.im/termux/termux"
        },
        {
          "type": "image",
          "url": "https://camo.githubusercontent.com/7c09fdc7ef9a56afa3dcb3b9bd0f3bd0176943ca6e0538aa936643768fea89dd/68747470733a2f2f696d672e736869656c64732e696f2f646973636f72642f3634313235363931343638343038343233342e7376673f6c6162656c3d266c6f676f3d646973636f7264266c6f676f436f6c6f723d66666666666626636f6c6f723d353836354632",
          "alt": "Join the Termux discord server"
        },
        {
          "type": "image",
          "url": "https://camo.githubusercontent.com/eab085c0233c31fb310d41dbf78ea9af8932cf2875e0a02f9054e91a4ff11804/68747470733a2f2f6a69747061636b2e696f2f762f7465726d75782f7465726d75782d6170702e737667",
          "alt": "Termux library releases at Jitpack"
        }
      ],
      "impressions_views": null,
      "impressions_likes": 349,
      "impressions_reposts": 0,
      "impressions_replies": 177,
      "impressions_bookmarks": null,
      "impressions_clicks": null,
      "impressions_quotes": null,
      "impressions_updated_at": "2026-02-03T09:02:56.768382",
      "published_at": "2026-02-02T06:03:44",
      "scraped_at": "2026-02-03T09:02:56.768400",
      "metadata": {
        "item_type": "story",
        "hn_url": "https://news.ycombinator.com/item?id=46854642",
        "kids_count": 51,
        "sections": [
          "best_stories"
        ]
      },
      "content_hash": "e1fa49528229bf161f7032eedd236093",
      "classification": {
        "is_ai_relevant": true,
        "primary_topic": "developer_tools",
        "primary_topic_label": "Developer Tools",
        "all_topics": [
          "llm",
          "developer_tools"
        ],
        "topic_details": {
          "llm": {
            "raw_score": 1,
            "weighted_score": 1.0,
            "matched_keywords": [
              "llm"
            ],
            "label": "Large Language Models"
          },
          "developer_tools": {
            "raw_score": 3,
            "weighted_score": 1.7999999999999998,
            "matched_keywords": [
              "developer",
              "ide",
              "api"
            ],
            "label": "Developer Tools"
          }
        },
        "relevance_score": 0.28,
        "is_noise": false,
        "filter_reason": null
      },
      "engagement_quality": {
        "engagement_ratio": 0.51,
        "is_flamewar": false,
        "is_high_signal": false,
        "is_emerging": false,
        "discussion_depth": 3.47,
        "velocity": 12.84,
        "hours_old": 27.2,
        "quality_tier": "high_quality"
      },
      "editorial": {
        "one_liner": "Developer Tools insight worth reading",
        "why_it_matters": "highly upvoted by HN community",
        "audience_fit": "Software developers",
        "newsletter_priority": 3
      }
    },
    {
      "id": "8b72ec49a9b56fe47127eb0f438a49b4",
      "source": "hackernews",
      "source_id": "46864498",
      "title": "How does misalignment scale with model intelligence and task complexity?",
      "content": "The Hot Mess of AI: How Does Misalignment Scale with Model Intelligence and Task Complexity?\n\nüìÑPaper, üíªCode\n\nResearch done as part of the firstAnthropic Fellows\n                    Programduring Summer 2025.\n\nWhen AI systems fail, will they fail by systematically pursuing the wrong goals, or by being a hot mess?\n                We decompose the errors of frontier reasoning models into bias (systematic) and variance (incoherent)\n                components and find that, as tasks get harder and reasoning gets longer, model failures become\n                increasingly dominated by incoherence rather than systematic misalignment. This suggests that future AI\n                failures may look more like industrial accidents than coherent pursuit of a goal we did not train them to pursue.\n\nIntroduction\n\nAs AI becomes more capable, we entrust it with increasingly consequential tasks. This makes understandinghowthese systems might fail even more critical for safety. A central concern in AI alignment\n            is that\n            superintelligent systems might coherently pursue misaligned goals: the classicpaperclip\n                maximizerscenario. But there's another possibility: AI might fail not through systematic\n            misalignment, but throughincoherence‚Äîunpredictable, self-undermining behavior that doesn't\n            optimize for any consistent objective. That is, AI might fail in the same way that humans often fail, by being ahot mess.\n\nThis paper builds on thehot mess theory\n                of misalignment(Sohl-Dickstein, 2023), which surveyed experts to rank various entities (including\n            humans, animals, machine learning models, and organizations) by intelligence and coherence independently. It\n            found thatsmarterentities are subjectively judged to behavelesscoherently. We take\n            this hypothesis from\n            survey data to empirical measurement across frontier AI systems, asking:As models become more\n                intelligent and tackle harder tasks, do their\n                failures look more like systematic misalignment, or more like a hot mess?\n\nMeasuring Incoherence: A Bias-Variance Decomposition\n\nTo quantify incoherence we decompose AI errors using the classic bias-variance framework:\n\nBiascaptures consistent, systematic errors‚Äîachieving the\n                wrong outcome reliably\n\nVariancecaptures inconsistent errors‚Äîunpredictable outcomes\n                across samples\n\nWe defineincoherenceas the fraction of error attributable to variance:\n\nAn incoherence of 0 means all errors are systematic (classic misalignment risk). An incoherence of 1 means\n            all errors are random (the hot mess scenario). Crucially, this metric is independent of overall performance:\n            a model can improve while becoming more or less coherent.\n\nKey Findings\n\nWe evaluated frontierAt the time of\n                this research in Summer 2025.reasoning models (Claude Sonnet 4, o3-mini, o4-mini, Qwen3)\n            across multiple-choice\n            benchmarks (GPQA, MMLU), agentic coding (SWE-Bench), and safety evaluations (Model-Written Evals). We also\n            train our own small models on synthetic optimization tasks, which makes the connection to LLMs as dynamical\n            systems and optimizers explicit.\n\nFinding 1: Longer reasoning ‚Üí More incoherence\n\nAcross all tasks and models, the longer models spend reasoning and taking actions, the more incoherent they\n            become. This holds whether we measure reasoning tokens, agent actions, or optimizer steps.\n\nFinding 2: Scale improves coherence on easy tasks, not hard ones\n\nHow does incoherence change with model scale? The answer depends on task difficulty:\n\nEasy tasks:Larger models become more coherent\n\nHard tasks:Larger models becomemore incoherentor\n                remain unchanged\n\nThis suggests that scaling alone won't eliminate incoherence. As more capable models tackle harder problems,\n            variance-dominated failures persist or worsen.\n\nFinding 3: Natural \"overthinking\" increases incoherence more than reasoning budgets reduce it\n\nWe find that when models spontaneously reason longer on a problem (compared to their median), incoherence\n            spikes\n            dramatically. Meanwhile, deliberately increasing reasoning budgets through API settings provides only modest\n            coherence improvements. The natural variation dominates.\n\nFinding 4: Ensembling reduces incoherence\n\nAggregating multiple samples reduces variance (as expected from theory), providing a path to more coherent\n            behavior, though this may be impractical for real-world agentic tasks where actions are irreversible.\n\nWhy Should We Expect Incoherence? LLMs as Dynamical Systems\n\nA key conceptual point:LLMs are dynamical systems, not optimizers.When a language model\n            generates text or takes actions, it traces trajectories through a high-dimensional state space. It has to betrainedto act as an optimizer, andtrainedto align with human intent. It's unclear which\n            of these properties will be more robust as we scale.\n\nConstraining a generic dynamical system to act as a coherent optimizer is extremely difficult. Often the number of\n            constraints required for monotonic progress toward a goal grows exponentially with the dimensionality of the\n            state space. We shouldn't expect AI to act as coherent optimizers without considerable effort, and this\n            difficulty doesn't automatically decrease with scale.\n\nThe Synthetic Optimizer: A Controlled Test\n\nTo probe this directly, we designed a controlled experiment: train transformers toexplicitlyemulate an optimizer. We generate training data from steepest descent on a quadratic loss function, then\n            train models of varying sizes to predict the next optimization step given the current state (essentially:\n            training a \"mesa-optimizer\").\n\nThe results are interesting:\n\nIncoherence grows with trajectory length.Even in this\n                idealized setting, the more optimization steps models take (and get closer to the correct solution), the\n                more incoherent they become.\n\nScale reduces bias faster than variance.Larger models learn\n                thecorrect objectivemore quickly than they learn toreliably pursue it. The gap\n                between \"knowing what to do\" and \"consistently doing it\" grows with scale.\n\nImplications for AI Safety\n\nOur results are evidence that future AI failures may look more likeindustrial accidentsthancoherent pursuit of goals that were not trained for. (Think: the AI intends to run the nuclear power\n            plant, but gets distracted reading French poetry, and there is a meltdown.) However, coherent pursuit of poorly chosen goals that we trained for remains a problem. Specifically:\n\nVariance dominates on complex tasks.When frontier models\n                fail on difficult problems requiring extended reasoning, there is a tendency for failures to be\n                predominantly incoherent rather than systematic.\n\nScale doesn't imply supercoherence.Making models larger improves\n                overall accuracy but doesn't reliably reduce incoherence on hard problems.\n\nThis shifts alignment priorities.If capable AI is more\n                likely to be a hot mess than a coherent optimizer of the wrong goal, this increases the relative\n                importance of research targetingreward hackingandgoal misspecificationduring\n                training‚Äîthe bias term‚Äîrather than focusing primarily on aligning and constraining a perfect optimizer.\n\nUnpredictability is still dangerous.Incoherent AI isn't\n                safe AI. Industrial accidents can cause serious harm. But thetypeof risk differs from classic\n                misalignment scenarios, and our mitigations should adapt accordingly.\n\nConclusion\n\nWe use the bias-variance decomposition to systematically study how AI incoherence scales with model\n            intelligence and task complexity. The evidence suggests that as AI tackles harder problems requiring more\n            reasoning and action, its failures tend to become increasingly dominated by variance rather than bias. This\n            doesn't eliminate AI risk‚Äîbut it changes what that risk looks like, particularly for problems that are currently hardest for models, and should inform how we prioritize\n            alignment research.\n\nAcknowledgements\n\nWe thank Andrew Saxe, Brian Cheung, Kit Frasier-Taliente, Igor Shilov, Stewart Slocum, Aidan Ewart, David\n            Duvenaud, and Tom\n            Adamczewski for extremely helpful discussions on topics and results in this paper.",
      "url": "https://alignment.anthropic.com/2026/hot-mess-of-ai/",
      "author_username": "salkahfi",
      "author_category": "unknown",
      "media": [],
      "impressions_views": null,
      "impressions_likes": 210,
      "impressions_reposts": 0,
      "impressions_replies": 65,
      "impressions_bookmarks": null,
      "impressions_clicks": null,
      "impressions_quotes": null,
      "impressions_updated_at": "2026-02-03T09:02:26.901923",
      "published_at": "2026-02-02T19:28:06",
      "scraped_at": "2026-02-03T09:02:26.901934",
      "metadata": {
        "item_type": "story",
        "hn_url": "https://news.ycombinator.com/item?id=46864498",
        "kids_count": 25,
        "sections": [
          "top_stories",
          "best_stories"
        ]
      },
      "content_hash": "6c4830fcf68d18c2e39c91ba7a3222d4",
      "classification": {
        "is_ai_relevant": true,
        "primary_topic": "llm",
        "primary_topic_label": "Large Language Models",
        "all_topics": [
          "llm",
          "ml_research",
          "ai_ethics",
          "developer_tools"
        ],
        "topic_details": {
          "llm": {
            "raw_score": 6,
            "weighted_score": 6.0,
            "matched_keywords": [
              "llm",
              "claude",
              "anthropic",
              "language model",
              "transformer",
              "agentic"
            ],
            "label": "Large Language Models"
          },
          "ml_research": {
            "raw_score": 6,
            "weighted_score": 5.4,
            "matched_keywords": [
              "machine learning",
              "training",
              "model",
              "benchmark",
              "reasoning"
            ],
            "label": "ML Research"
          },
          "ai_ethics": {
            "raw_score": 4,
            "weighted_score": 3.2,
            "matched_keywords": [
              "ai safety",
              "alignment",
              "bias"
            ],
            "label": "AI Ethics & Safety"
          },
          "developer_tools": {
            "raw_score": 4,
            "weighted_score": 2.4,
            "matched_keywords": [
              "ide",
              "coding",
              "api",
              "framework"
            ],
            "label": "Developer Tools"
          }
        },
        "relevance_score": 1.0,
        "is_noise": false,
        "filter_reason": null
      },
      "engagement_quality": {
        "engagement_ratio": 0.31,
        "is_flamewar": false,
        "is_high_signal": true,
        "is_emerging": false,
        "discussion_depth": 2.6,
        "velocity": 15.25,
        "hours_old": 13.8,
        "quality_tier": "good"
      },
      "editorial": {
        "one_liner": "Large Language Models insight worth reading",
        "why_it_matters": "quality discussion; directly relevant to AI practitioners",
        "audience_fit": "AI engineers & researchers",
        "newsletter_priority": 3
      }
    },
    {
      "id": "ec593516e5a5d7bdb514caa395a8e843",
      "source": "hackernews",
      "source_id": "46864120",
      "title": "Firefox Getting New Controls to Turn Off AI Features",
      "content": "Firefox Getting New Controls to Turn Off AI Features\n\nThe Firefox browser is gaining options to turn off AI enhancements, Mozillasaid today. Firefox users who prefer to browse without artificial intelligence will be able to turn off several AI features that Mozilla has added over the last several months.\n\nHere's what can be disabled:\n\nTranslations, which help you browse the web in your preferred language.\n\nAlt text in PDFs, which add accessibility descriptions to images in PDF pages.\n\nAI-enhanced tab grouping, which suggests related tabs and group names.\n\nLink previews, which show key points before you open a link.\n\nAI chatbot in the sidebar, which lets you use your chosen chatbot as you browse, including options like Anthropic Claude, ChatGPT, Microsoft Copilot, Google Gemini and Le Chat Mistral.\n\nThe AI features can be disabled entirely or individually, so users can pick and choose what they want to use. Users will be able to continue to opt out of AI features as they are added in the browser, and the main Block AI Enhancements toggle will disable all current and future AI features, including pop-ups or reminders to use existing or upcoming AI features.\n\nMozilla says that it wants to be able to continue to build AI options for those who want them, while also giving those who don't a way to disable them.\n\nAI controls will be added in Firefox 148, which is set to start rolling out to users on February 24.",
      "url": "https://www.macrumors.com/2026/02/02/firefox-ai-toggle/",
      "author_username": "stalfosknight",
      "author_category": "unknown",
      "media": [
        {
          "type": "image",
          "url": "https://images.macrumors.com/t/odHITJ0hJsNJs7NAz4zRZ52iCLQ=/400x0/article-new/2026/02/firefox-ai-toggle.jpg?lossy",
          "alt": "firefox ai toggle"
        },
        {
          "type": "image",
          "url": "https://images.macrumors.com/images-new/1x1.trans.gif",
          "alt": "Aston Martin CarPlay Ultra Screen"
        },
        {
          "type": "image",
          "url": "https://images.macrumors.com/t/elkWPhhY_1RI2D2wDC0khI6l7SQ=/400x400/smart/article-new/2026/02/Aston-Martin-CarPlay-Ultra-Screen.jpg",
          "alt": "Aston Martin CarPlay Ultra Screen"
        },
        {
          "type": "image",
          "url": "https://images.macrumors.com/images-new/1x1.trans.gif",
          "alt": "Apple Logo Black"
        }
      ],
      "impressions_views": null,
      "impressions_likes": 174,
      "impressions_reposts": 0,
      "impressions_replies": 83,
      "impressions_bookmarks": null,
      "impressions_clicks": null,
      "impressions_quotes": null,
      "impressions_updated_at": "2026-02-03T09:02:48.218897",
      "published_at": "2026-02-02T18:54:02",
      "scraped_at": "2026-02-03T09:02:48.218907",
      "metadata": {
        "item_type": "story",
        "hn_url": "https://news.ycombinator.com/item?id=46864120",
        "kids_count": 27,
        "sections": [
          "top_stories"
        ]
      },
      "content_hash": "82c3f6abc4135fc67eabcbb7d9aa2301",
      "classification": {
        "is_ai_relevant": true,
        "primary_topic": "llm",
        "primary_topic_label": "Large Language Models",
        "all_topics": [
          "llm",
          "ai_product",
          "developer_tools"
        ],
        "topic_details": {
          "llm": {
            "raw_score": 7,
            "weighted_score": 7.0,
            "matched_keywords": [
              "gpt",
              "claude",
              "gemini",
              "anthropic",
              "chatgpt",
              "mistral",
              "copilot"
            ],
            "label": "Large Language Models"
          },
          "ai_product": {
            "raw_score": 2,
            "weighted_score": 1.7,
            "matched_keywords": [
              "ai feature"
            ],
            "label": "AI Products"
          },
          "developer_tools": {
            "raw_score": 1,
            "weighted_score": 0.6,
            "matched_keywords": [
              "ide"
            ],
            "label": "Developer Tools"
          }
        },
        "relevance_score": 0.93,
        "is_noise": false,
        "filter_reason": null
      },
      "engagement_quality": {
        "engagement_ratio": 0.48,
        "is_flamewar": false,
        "is_high_signal": false,
        "is_emerging": true,
        "discussion_depth": 3.07,
        "velocity": 12.13,
        "hours_old": 14.3,
        "quality_tier": "good"
      },
      "editorial": {
        "one_liner": "Large Language Models insight worth reading",
        "why_it_matters": "directly relevant to AI practitioners",
        "audience_fit": "AI engineers & researchers",
        "newsletter_priority": 3
      }
    },
    {
      "id": "d46bd23511e10d1dd49d4bc8e0a86e06",
      "source": "hackernews",
      "source_id": "46854951",
      "title": "Microsoft is walking back Windows 11's AI overload",
      "content": "Copy link\n\nFacebook\n\nX\n\nReddit\n\nPinterest\n\nFlipboard\n\nBluesky\n\nThreads\n\nEmail\n\nIt‚Äôs fair to say that Windows 11‚Äôs recent endeavour intoAIhasn‚Äôt gone down well with its most passionate users. It started in 2024 with the unveiling of Windows Recall, which was met with such backlash thatMicrosoft was forced to postpone itby an entire year while it addressed major security and privacy flaws.\n\nIt seems like things have been downhill since. In the last year, Microsoft has taken every opportunity to enshittify Windows 11 byplacing Copilot buttons wherever it canacross in-box apps like File Explorer and Notepad, even if the implementation is poor or unnecessary.\n\nThis has soured Microsoft‚Äôs AI efforts in the eyes of many Windows users, resulting in major pushback online and adding to the overall negative sentiment around Windows 11. This came to a head in November, when Windows president Pavan Davuluri tweeted thatWindows would evolve into an agentic OS, spawning thousands of overwhelmingly negative replies rejecting this plan.\n\nIt appears this moment of pushback has resonated with internal teams: According to people familiar with Microsoft‚Äôs plans, the company is now reevaluating its AI strategy on Windows 11 and plans changes to streamline or even remove certain AI features where they don‚Äôt make sense.\n\nDetails around how the company is going about this remain light, but sources say Copilot integrations like those found in Notepad and Paint are under review. This may result in Microsoft removing certain Copilot integrations from these apps, or at the very least removing the Copilot branding and pivoting to a more streamlined experience.\n\nI‚Äôm also told that Microsoft has paused work on any additional Copilot buttons for in-box apps, at least for now. While I don‚Äôt expect this pause to be permanent, it does sound like Microsoft plans to be more tactful and deliberate in where these Copilot buttons and integrations will appear going forward.\n\nWindows Recall is another AI experience that I‚Äôm told is under review. Sources tell me that Microsoft believes that Recall, in its current implementation, has failed, though I understand the company is exploring ways to evolve the concept rather than scrap it entirely, possibly dropping the Recall name in the process, though this is unconfirmed.\n\nOther AI initiatives, such as Semantic Search, Agentic Workspace, Windows ML, and Windows AI APIs, are continuing ahead as planned. Microsoft believes that these under-the-hood AI efforts are still important for app developers and users, positioning Windows as a viable contender amongst other OS‚Äôs that are also building AI frameworks into their platforms.\n\nThe company is shifting away from ‚ÄòAI everywhere‚Äô and toward features that actually make sense for Windows users.\n\nThe good news is that it's clear Microsoft has heard the feedback around its heavy-handedness when it comes to Copilot buttons in Windows apps. The company is stepping back to readjust how best to implement these AI integrations across the OS, hopefully resulting in a more meaningful and useful AI experience on the platform, rather than haphazardly adding the Copilot icon to every UI surface it can.\n\nThis effort is likely part of Microsoft's overall effort to \"fix\" Windows 11 this year.I understand that the company is moving quickly to begin shipping meaningful changes that are designed to signal to customers that it is listening to feedback, and streamlining where Copilot shows up across in-box apps would be a strong place to start.\n\nMicrosoft pulling back its Windows 11 AI push is a big shift ‚Äî fewer forced Copilot moments, a reworked Recall, and a more realistic approach overall.How does that land with you? Is this the right move, or should Microsoft double down instead? Share your take below and let‚Äôs see where the community stands.\n\nFollowWindows Central on Google Newsto keep our latest news, insights, and features at the top of your feeds!\n\nZac Bowden is a Senior Editor at Windows Central and has been with the site since 2016. Bringing you exclusive coverage into the world of Windows, Surface, and hardware. He's also an avid collector of rare Microsoft prototype devices! Keep in touch onTwitterandThreads\n\nYou must confirm your public display name before commenting\n\nPlease logout and then login again, you will then be prompted to enter your display name.\n\n18 new Windows 11 features expected to arrive with the February 2026 update ‚Äî Patch Tuesday isn't flashy, but it'll deliver (some) meaningful changes\n\n2Windows 11 running slow? These 3 easy steps declutter it in minutes\n\n3With the Galleon 100, Corsair integrated the Stream Deck into a mechanical gaming keyboard, and it's brilliant ‚Äî this may just be the most customizable keyboard yet\n\n4Weekly Windows Wrap: Microsoft finally reads the room ‚Äî right as it loses $440 billion\n\n5The entry-level CPU we believe is \"masterclass of performance-per-watt efficiency\" is now under $200 ‚Äî it has CPU Speeds of 3.9 GHz, 6 Cores, and more",
      "url": "https://www.windowscentral.com/microsoft/windows-11/microsoft-is-reevaluating-its-ai-efforts-on-windows-11-plans-to-reduce-copilot-integrations-and-evolve-recall",
      "author_username": "jsheard",
      "author_category": "unknown",
      "media": [
        {
          "type": "image",
          "url": "https://sb.scorecardresearch.com/p/?c1=2&c2=10055482&cv=4.4.0&cj=1",
          "alt": ""
        },
        {
          "type": "image",
          "url": "https://cdn.mos.cms.futurecdn.net/xstyFBAMP9XTUL8qniRTN4.jpg",
          "alt": "Mockups with Microsoft&#039;s AI agent Copilot in Windows 11 and the Windows 11 taskbar"
        },
        {
          "type": "image",
          "url": "https://cdn.mos.cms.futurecdn.net/Yx3yFk7H6owX2aZEBQ6oCm.jpg",
          "alt": "New Welcome Screen in Notepad detailing recent updates"
        },
        {
          "type": "image",
          "url": "https://cdn.mos.cms.futurecdn.net/CyRXFjWjFC5eLGfu5Z5T4T.png",
          "alt": "A banner that reads &amp;quot;It&#039;s Poll Time&amp;quot; and shows a graphic with a dial on it pointing to a mid-range hue on a gradient."
        },
        {
          "type": "image",
          "url": "https://cdn.mos.cms.futurecdn.net/L3AsfTCaaiH29SBi5ptnDX.png",
          "alt": "Click to follow Windows Central on Google News"
        }
      ],
      "impressions_views": null,
      "impressions_likes": 200,
      "impressions_reposts": 0,
      "impressions_replies": 276,
      "impressions_bookmarks": null,
      "impressions_clicks": null,
      "impressions_quotes": null,
      "impressions_updated_at": "2026-02-03T09:02:59.567137",
      "published_at": "2026-02-02T06:52:29",
      "scraped_at": "2026-02-03T09:02:59.567151",
      "metadata": {
        "item_type": "story",
        "hn_url": "https://news.ycombinator.com/item?id=46854951",
        "kids_count": 60,
        "sections": [
          "best_stories"
        ]
      },
      "content_hash": "8c90374b02fe5768115c676ffd23b21d",
      "classification": {
        "is_ai_relevant": true,
        "primary_topic": "ai_product",
        "primary_topic_label": "AI Products",
        "all_topics": [
          "llm",
          "ai_product",
          "developer_tools"
        ],
        "topic_details": {
          "llm": {
            "raw_score": 2,
            "weighted_score": 2.0,
            "matched_keywords": [
              "copilot",
              "agentic"
            ],
            "label": "Large Language Models"
          },
          "ai_product": {
            "raw_score": 3,
            "weighted_score": 2.55,
            "matched_keywords": [
              "ai api",
              "ai feature",
              "ai integration"
            ],
            "label": "AI Products"
          },
          "developer_tools": {
            "raw_score": 4,
            "weighted_score": 2.4,
            "matched_keywords": [
              "developer",
              "ide",
              "api",
              "framework"
            ],
            "label": "Developer Tools"
          }
        },
        "relevance_score": 0.69,
        "is_noise": false,
        "filter_reason": null
      },
      "engagement_quality": {
        "engagement_ratio": 1.38,
        "is_flamewar": false,
        "is_high_signal": false,
        "is_emerging": false,
        "discussion_depth": 4.6,
        "velocity": 7.59,
        "hours_old": 26.4,
        "quality_tier": "good"
      },
      "editorial": {
        "one_liner": "AI Products insight worth reading",
        "why_it_matters": "commercial AI application",
        "audience_fit": "Product managers & founders",
        "newsletter_priority": 3
      }
    },
    {
      "id": "9bdd85dff64039885b2ef49fa4d4e150",
      "source": "hackernews",
      "source_id": "46858873",
      "title": "Advancing AI Benchmarking with Game Arena",
      "content": "Advancing AI benchmarking with Game Arena\n\nFeb 02, 2026\n\nDecisions in the real world are rarely based on the perfect information found on a chessboard. We are updating Kaggle Game Arena with two new games ‚Äî Werewolf and poker ‚Äî to benchmark how models navigate social dynamics and calculated risk.\n\nGeneral summary\n\nGoogle DeepMind is expanding its Game Arena platform to benchmark AI models in more complex scenarios. You can now test your models in Werewolf and poker in addition to chess. Watch live tournaments on Kaggle to see how the top models perform in these games.\n\nGoogle DeepMind is expanding its Game Arena platform to benchmark AI models in more complex scenarios. You can now test your models in Werewolf and poker in addition to chess. Watch live tournaments on Kaggle to see how the top models perform in these games.\n\nBullet points\n\nGoogle DeepMind's \"Game Arena\" article discusses using games to benchmark AI, moving beyond perfect information scenarios.Game Arena expands beyond chess to include Werewolf, testing social deduction and communication skills in AI models.A new poker benchmark assesses AI's ability to manage risk and quantify uncertainty in competitive scenarios.Watch live streams of AI competitions in poker, Werewolf, and chess with expert commentary on Kaggle.These benchmarks help develop safer AI by evaluating model behavior in complex, real-world-like environments.\n\nGoogle DeepMind's \"Game Arena\" article discusses using games to benchmark AI, moving beyond perfect information scenarios.\n\nGame Arena expands beyond chess to include Werewolf, testing social deduction and communication skills in AI models.\n\nA new poker benchmark assesses AI's ability to manage risk and quantify uncertainty in competitive scenarios.\n\nWatch live streams of AI competitions in poker, Werewolf, and chess with expert commentary on Kaggle.\n\nThese benchmarks help develop safer AI by evaluating model behavior in complex, real-world-like environments.\n\nBasic explainer\n\nGoogle DeepMind made a place called Game Arena to test how smart AI really is. They started with chess to see how well AI can plan ahead. Now, they're adding Werewolf and poker to test AI on things like social skills and risk-taking. These games help them see if AI can handle the real world's trickiness and work safely with people.\n\nGoogle DeepMind made a place called Game Arena to test how smart AI really is. They started with chess to see how well AI can plan ahead. Now, they're adding Werewolf and poker to test AI on things like social skills and risk-taking. These games help them see if AI can handle the real world's trickiness and work safely with people.\n\nGeneral summary\n\nBullet points\n\nBasic explainer\n\nYour browser does not support the audio element.\n\nChess is a game of perfect information. The real world is not.\n\nLast year, Google DeepMind partnered with Kaggle to launchGame Arena, an independent, public benchmarking platform where AI models compete in strategic games. We started with chess to measure reasoning and strategic planning. But in the real world, decisions are rarely based on complete information.\n\nTo build artificial intelligence capable of navigating this uncertainty, we need benchmarks that measure the model‚Äôs ability to reason in the face of ambiguity. This is why we are now expanding Game Arena with two new game benchmarks ‚Äî Werewolf and poker ‚Äî to test frontier models on social dynamics and calculated risk.\n\nGames have always been a core part of Google DeepMind‚Äôs history, offering an objective proving ground where difficulty scales with the level of competition. As AI systems become more general, mastering diverse games demonstrates their consistency across distinct cognitive skills. Beyond measuring performance, games can also serve as controlled sandbox environments to evaluate agentic safety, providing insight into model behavior in the complex environments they will encounter when deployed in the real world.\n\nChess: reasoning over calculation\n\nWe released the chess benchmark last year to assess models on strategic reasoning, dynamic adaptation, and long-term planning by pitting them against one another in head-to-head chess games. To track how these model capabilities are evolving, we have updated theleaderboardto include the latest generation of models.\n\nWhile traditional chess engines like Stockfish function as specialized super-calculators, evaluating millions of positions per second to find the optimal move, large language models do not approach the game through brute-force calculation. Instead, they rely on pattern recognition and ‚Äòintuition‚Äô to drastically reduce the search space ‚Äî an approach that mirrors human play.\n\nGemini 3 Pro and Gemini 3 Flash currently have the top Elo ratings on the leaderboard. The models‚Äô internal ‚Äòthoughts‚Äô reveal the use of strategic reasoning grounded in familiar chess concepts like piece mobility, pawn structure, and king safety. This significant performance increase over the Gemini 2.5 generation highlights the rapid pace of model progress and demonstrates Game Arena‚Äôs value in tracking these improvements over time.\n\nWerewolf: navigating social deduction\n\nMoving beyond the transparent logic of chess, we are expanding Kaggle Game Arena withWerewolf. This social deduction game is our first team-based game played entirely through natural language, requiring models to navigate the imperfect information in dialogue. In this social deduction challenge, a team of \"villagers\" must work together to distinguish truth from deception and identify the hidden \"werewolves\" to win.\n\nThis benchmark helps to assess the \"soft skills\" required for the next generation of AI assistants. The game tests communication, negotiation, and the ability to navigate ambiguity ‚Äî the same capabilities agents need to collaborate effectively with humans and other agents in the enterprise world.\n\nWerewolf also serves as a secure environment for agentic safety research. Success involves playing both sides ‚Äî the truth-seeker (villager) and the deceiver (werewolf). This allows us to test a model's ability to detect manipulation in others, while simultaneously red-teaming the model‚Äôs own capabilities around deception without the stakes of real-world deployment. This research is fundamental to building AI agents that act as reliable safeguards against bad actors.\n\nGemini 3 Pro and Gemini 3 Flash currently hold the top two positions on theleaderboard. They demonstrate the ability to effectively reason about the statements and actions of other players across multiple game rounds ‚Äî for instance, identifying inconsistencies between a player‚Äôs public claims and their voting patterns ‚Äî and use that insight to build consensus with teammates.\n\nFor a technical deep dive on how we measure model skill in Werewolf, head to theKaggle blog.\n\nPoker: the challenge of calculated risk\n\nChess relies on reasoning. Werewolf relies on social deduction. Poker introduces a new dimension: risk management. Like Werewolf, poker is a game of imperfect information. But here, the challenge isn't about building alliances ‚Äî it's about quantifying uncertainty. Models must overcome the luck of the deal by inferring their opponents' hands and adapting to their playing styles to determine the best move.\n\nTo put these skills to the test, we are launching a new poker benchmark and hosting an AI poker tournament, where the top models will compete in Heads-Up No-Limit Texas Hold'em. The final poker leaderboard will be revealed atkaggle.com/game-arenaon Wednesday, Feb 4, following the conclusion of the tournament finals.\n\nTo learn how we evaluate model capability in poker, check out theKaggle blog.\n\nWatch the action\n\nMarking the launch of these new and updated benchmarks, we have partnered with Chess Grandmaster Hikaru Nakamura and poker legends Nick Schulman, Doug Polk, and Liv Boeree to produce three livestreamed events with expert commentary and analysis across all three benchmarks.\n\nTune in to the three daily livestreams at 9:30 AM PT atkaggle.com/game-arena:\n\nMonday, Feb 2:The top eight models on the poker leaderboard face off in the AI poker battle.\n\nTuesday, Feb 3:As the poker tournament semi-finals take place, we will also feature highlight matches from the Werewolf and chess leaderboards.\n\nWednesday, Feb 4:The final two models compete for the poker crown alongside the release of the full leaderboard. We conclude our coverage with a chess match between the top two models on the chess leaderboard ‚Äî Gemini 3 Pro and Gemini 3 Flash ‚Äî and will be streaming game highlights of the best Werewolf models.\n\nExplore the arena\n\nWhether it‚Äôs finding a creative checkmate, negotiating a truce in Werewolf, or going all in at the poker table, Kaggle Game Arena is where we find out what these models can really do.\n\nCheck it out atkaggle.com/game-arena.",
      "url": "https://blog.google/innovation-and-ai/models-and-research/google-deepmind/kaggle-game-arena-updates/",
      "author_username": "salkahfi",
      "author_category": "unknown",
      "media": [
        {
          "type": "image",
          "url": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/orankelly.max-244x184.format-webp.webp",
          "alt": "orankelly"
        },
        {
          "type": "image",
          "url": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/kaggle_Gsmes_Hero.width-200.format-webp.webp",
          "alt": "An illustration of a King and Ace playing card, a wolf's head, two chess pieces, a poker chip, and other abstract shapes on a white background.1"
        },
        {
          "type": "image",
          "url": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Terria-Clay_Collage_hero.width-300.format-webp.webp",
          "alt": ""
        }
      ],
      "impressions_views": null,
      "impressions_likes": 128,
      "impressions_reposts": 0,
      "impressions_replies": 53,
      "impressions_bookmarks": null,
      "impressions_clicks": null,
      "impressions_quotes": null,
      "impressions_updated_at": "2026-02-03T09:02:45.882223",
      "published_at": "2026-02-02T12:49:07",
      "scraped_at": "2026-02-03T09:02:45.882234",
      "metadata": {
        "item_type": "story",
        "hn_url": "https://news.ycombinator.com/item?id=46858873",
        "kids_count": 16,
        "sections": [
          "top_stories"
        ]
      },
      "content_hash": "7c962f771d95a50556e0ee6d75d9bdfd",
      "classification": {
        "is_ai_relevant": true,
        "primary_topic": "llm",
        "primary_topic_label": "Large Language Models",
        "all_topics": [
          "llm",
          "ml_research",
          "developer_tools"
        ],
        "topic_details": {
          "llm": {
            "raw_score": 4,
            "weighted_score": 4.0,
            "matched_keywords": [
              "gemini",
              "language model",
              "ai agent",
              "agentic"
            ],
            "label": "Large Language Models"
          },
          "ml_research": {
            "raw_score": 4,
            "weighted_score": 3.6,
            "matched_keywords": [
              "model",
              "benchmark",
              "reasoning"
            ],
            "label": "ML Research"
          },
          "developer_tools": {
            "raw_score": 2,
            "weighted_score": 1.2,
            "matched_keywords": [
              "ide",
              "api"
            ],
            "label": "Developer Tools"
          }
        },
        "relevance_score": 0.88,
        "is_noise": false,
        "filter_reason": null
      },
      "engagement_quality": {
        "engagement_ratio": 0.41,
        "is_flamewar": false,
        "is_high_signal": false,
        "is_emerging": true,
        "discussion_depth": 3.31,
        "velocity": 6.27,
        "hours_old": 20.4,
        "quality_tier": "good"
      },
      "editorial": {
        "one_liner": "Performance/comparison data for large language models",
        "why_it_matters": "directly relevant to AI practitioners",
        "audience_fit": "AI engineers & researchers",
        "newsletter_priority": 3
      }
    },
    {
      "id": "b42d95fdc879727287cff933906f196a",
      "source": "hackernews",
      "source_id": "46859443",
      "title": "The largest number representable in 64 bits",
      "content": "The largest number representable in 64 bits\n\n28 Jan 2026\n\nThis post is a rewrite of my earlier blog post fromNov 2023with many new insights and updates.\n\nMost people believe 264-1 = 18446744073709551615, or\n0xFFFFFFFFFFFFFFFF in hexadecimal, to be the largest number\nrepresentable in 64 bits. In English, it‚Äôs quite the mouthful: eighteen\nquintillion four hundred forty-six quadrillion seven hundred forty-four\ntrillion seventy-three billion seven hundred nine million five hundred\nfifty-one thousand six hundred fifteen.\n\nThat is indeed the maximum possible value of 64 bit unsigned integers,\navailable as data type uint64_t in C or u64 in Rust. \nFloating point data types can represent much larger values, courtesy of their base 2 exponent.\nThe 64-bit doublefloating\npoint formathas a largest (finite) representable value of 21024(1-2-53) ~ 1.8*10308.\n\nWhat if we allow representations beyond plain data types?\nSince we want representations to remain computable, the most general\nkind of representation would be a program in some programming language.\nBut the program must be small enough to fit in 64 bits.\n\nThe largest number programmable in 64 bits\n\nThe smallest possible valid C program is ‚Äúmain(){}‚Äù,\nconsisting of 8 ASCII characters.ASCIIis a 7-bit\ncharacter encoding standard representing 128 unique characters,\nbut all modern computers use 8-bit bytes to store either plain ASCII\norUTF-8, a Unicode character encoding that‚Äôs backward compatible with\nASCII.  So we‚Äôll consider the above all-scaffold do-nothing program to\nbe the only valid 64-bit C program.\n\nPlenty other languages require no such scaffolding. For instance,\nLinux features the arbitrary precision calculatorbc. It happily\ncomputes the 954242 digit number 9^999999 = 35908462‚Ä¶48888889, making\nit programmable in 8 bytes. So is the much larger 9^9^9^99 =\n9^(9^(9^99)) with over 10^10^953 digits, which bc is less happy to\ncompute. If bc supported the symbol¬†! for computing factorials, then\n9!!!!!!! would represent a much larger number still.\n\nAllowing such primitives feels a bit like cheating though. Would we allow a\nlanguage that has theAckerman functionpredefined, letting the 8 byte expression ack(9,9) represent a truly huge number?\n\nAckerman considered unhelpful\n\nAs it turns out, the question is moot.\nOne can blow way past ack(9,9) in under 64 bits in a language with no built\nin primitive whatsoever. A language with no basic arithmetic; not even numbers themselves.\nA language in which all those must be defined from scratch.\n\nBut let‚Äôs first look at another primitives-lacking language, one that has been particularly\nwell studied for producing largest possible outputs. That is the language ofTuring machines.\n\nBusy Beaver\n\nThe famousBusy Beaverfunction,introducedbyTibor Rad√≥in 1962, which we‚Äôll\ndenote BB(n), is defined as the maximal number of steps taken by\nan n-state Turing Machine (TM) with a binary tape alphabet,\nstarting from an all 0 tape, before halting.\n\nHere we have a discrepancy between how the size of a TM is measured, in states,\nversus how program size is measured, in bits.\nFortunately there is a straightforward binary encoding of n-state TMs,\nwhich is entirely determined by its transition function.\nFor each of the n states that the machine‚Äôs finite control can be in,\nand each of its 2 tape symbols that could be scanned by its tape head,\nthe transition function specifies what new symbol to write in the scanned tape cell (1 bit),\nwhether to move the tape head left or right (1 bit),\nand what new state (or special halt state) to transition to (‚åàlog2(n+1)‚åâ bits).\nThis encoding takes 6*2*(2+3) = 60 bits for a a 6-state TM,\nand 7*2*(2+3) = 70 bits for a a 7-state TM.\n\nWe‚Äôre also stretching the meaning of ‚Äúrepresentable‚Äù a bit,\nsince BB considers the runtime of the machine instead of its output.\nBesides the above BB (that Rad√≥ called S), Rad√≥ did define another\nfunction called Œ£ that considers the output of the machine as a number in unary,\nnamely the number of 1s in the final tape contents. But BB has received\nmore attention as it allows one to determine from BB(n) all halting n-state machines.\nFor 6-states and up though, there is no discernable difference in magnitude between the two functions\nso we could have just as easily used Œ£.\n\nSo the largest number TM programmable in 64 bits is BB(6).\n\nHow large is BB(6)?\n\nUnfortunately, we may never know. While all BB(n) have been determined (and even\nformally proven) for n‚â§5, there are some 6-state TMs whose halting behaviour are\nclosely related to very hard mathematical problems.\nMost of these so-calledcryptidsare likely not to halt, with some,\nlikeLucy‚Äôs Moonlight,\nlikely to halt but unlikely to beat the current champion.\nThe current 6-state champion shows thatBB(6) > 2‚Üë‚Üë2‚Üë‚Üë2‚Üë‚Üë10.\nHere, m‚Üë‚Üën isKnuth‚Äôs up-arrow notationfor an exponential tower of n m‚Äôs, so that for example 2‚Üë‚Üë3 = 222.\nLarge as this number is, it‚Äôs still very small compared to\nack(9,9) = 2‚Üë712 - 3 = 2‚Üë‚Üë‚Üë‚Üë‚Üë‚Üë‚Üë12 - 3.\n\nIt is known however thatBB(7) > 2‚Üë112‚Üë113 > ack(9,9).\nSeveral leading BB researchers believe that BB(7) is even larger than the famousGraham‚Äôs Number, which iterates\nthe function mapping n to 3‚Üën3 64 times starting from n=3.\nThis appears to me a rather bold belief, considering that the smallest known Graham exceeding TM has14 states, twice as many.\nSo I offered a $1000 bet that a proof of BB(7) > Graham‚Äôs Number won‚Äôt be found within 10 years,\nwhich BB researcherShawn Ligockiwas happy to accept.\n\nMeanwhile, Graham‚Äôs Number is easily surpassed within 64 bits, by moving beyond Turing machines\ninto the language of\n\nLambda Calculus\n\nAlonzo Church conceived theŒª-calculusin about 1928 as a formal logic system for expressing\ncomputation based on function abstraction and application using variable binding and substitution.\n\nThe Graham beating lambda term originates in a Code Golf challenge asking for the\n‚ÄúShortest terminating program whose output size exceeds Graham‚Äôs number‚Äù,answeredby userPatcailandfurther optimizedby user2014MELO03.\nThe following 49 bit program\n\nis theBinary Lambda Calculusencodingof the term\n\nwhere Œª (lambda) denotes an anonymous function, and number i is the variable bound by the i-th nested Œª.\nThis is known asDe Bruijn notation, a\nway to avoid naming variables. A more conventional notation using variable names would be\n\nThe top left of this post shows agraphical representationof the term.\nThe last 16 bits of the program, making up almost a third of its size, encodes\nthe term Œªf Œªx. f (f x), which takes arguments f and x in turn, and iterates f twice on x.\nIn its generalized form, the function Œªf Œªx. fnx, \ncalled Church numeral n, is the most common way of representing numbers in the Œª-calculus.\nThe encoding of Church numeral n is 0000(01110)n10, of size 5n+6 bits.\n\nThe program, which we‚Äôll name after its discoverer, can be expressed more legibly as\n\nMelo evaluates to a Church numeral, ‚ÄúMelo‚Äôs Number‚Äù, that comfortably exceeds Graham‚Äôs Number.\n\nProof of exceeding Graham‚Äôs Number\n\nLemma 1. J J = 2‚Üë‚Üë6 HH 2, where HH denotes H H\n\nProof:\n\nJ J = J (J H) = J (H HH) = H HH (H HH H)\n    = H HH H        HH 2\n    = H HH 2        HH 2\n    = 2 HH 2        HH 2\n    = HH (HH 2)     HH 2\n    = HH 2 H 2      HH 2\n    = 2 H 2 H 2     HH 2\n    = H (H 2) H 2   HH 2\n    = H (H 2) 2 2   HH 2\n    = 2 (H 2) 2 2   HH 2\n    = H 2 (H 2 2) 2 HH 2\n    = H 2 2 2 2 2   HH 2\n    = 2 2 2 2 2 2   HH 2\n    = 2‚Üë‚Üë6          HH 2\n\nLemma 2. For k,n ‚â• 2, k H 2 n > 3‚Üëk(1+n)\n\nProof:\n\nBy induction on k.  First note that H2 n = H 2 n = n 2 2 = 2^2^n\n\nBase:   2 H 2 n = H H2 n = n H2 2 = 2‚Üë‚Üë(1+2n) > 3‚Üë2(1+n)\n        already at n=2, since 2‚Üë‚Üë5 = 2^2^16 > 3^27 = 3‚Üë‚Üë3\nStep: k+1 H 2 n = H (k H 2) n = n (k H 2) 2 > 3‚Üëk(1+ 3‚Üëk(1+ ‚Ä¶\n3‚Üëk(1+2)‚Ä¶))\n                                            > 3‚Üëk+1(1+n)\n\nLemma 3. For n ‚â• 2, HH (HH n) > 3‚Üën3\n\nProof\n\nBy induction on n\n\nBase: Lemma 1‚Äôs proof shows HH (HH 2) = 2‚Üë‚Üë6 > 3{2</sup>3\nStep: HH (HH 1+n) = HH 1+n H 2 = 1+n H 2 H 2 = H (n H 2) H 2 =\nH (n H 2) 2 2 = 2 (n H 2) 2 2 = n H 2 (n H 2 2) 2 >Lm23‚Üën(1+3‚Üën(1+2)) 2 > 3‚Üën+13.\n\nTheorem: J J > Graham‚Äôs Number G(64), where G(n) = n (\\n -> 3‚Üën3) 4\n\nProof:\n\nJ J =Lm12‚Üë‚Üë6 HH 2 >Lm3(2‚Üë‚Üë6 / 2 - 1) (\\n -> 3‚Üën3)\n3‚Üë23\n\n(2‚Üë‚Üë6 / 2 - 1) (\\n -> 3‚Üën3) 4 = G(2‚Üë‚Üë6 / 2 - 1) > G(64)\n\nLeaving Melo‚Äôs Number in the dust\n\nWith 15 bits to spare, opportunities for vastly boosting Melo abound.\nDiscord users 50_ft_lock and Sam found the following term that extends Melo‚Äôs H with an extra argument:\n\nwhich desugars to lambda term\n\nin conventional notation, or\n\nin de Bruijn notation, with 61-bit encoding\n\nLemma 4. T T T = 2‚Üë‚Üë18 A 2 2 2 2 2 2 2 2 2 2\n\nProof: Let AA denote A A\n\nThese 2‚Üë‚Üë18 iterations of A also let us relate its magnitude to the so-calledFast-growing hierarchy,\na family that assigns, to each ordinal Œ±, a function [Œ±] (diverting from the usual fŒ±notation for improved legibility) from natural numbers to natural numbers.\nWe‚Äôll treat all numbers as Church Numerals, so we can write n f instead of the\nusual fnand write f n instead of f(n) as normally done in Œª-calculus.\n\nReaders unfamiliar withordinalarithmetic,\nmay want to skip the next section.\n\nThe following FGH definition differs slightly from the standard one,\nwhich has the slightly slower growing [0] n = n+1 and [Œ±+1] n = n [Œ±] n.\nThis allows Lemma 5 to be exact rather than a mere lower bound.\n\nDefinition of Fast Growing Hierarchy\n\n[0] n = 2 n = n2\n\n[Œ±+1] n = n 2 [Œ±] 2 = A 2 [Œ±] n\n\n[œâi+1(Œ±+1)] n = [œâi+1Œ±+œâin] 2\n\nLemma 5. For k‚â•0, n>=2, : k+1 A 2 [œâkŒ±] n = [œâk(Œ±+1)] n\n\nProof:\n\nBase k=0:\n0+1 A 2 [œâ0Œ±] n = A 2 [Œ±] n = n 2 [Œ±] 2 = [Œ±+1] n\n\nStep k>0:\nk+1 A 2 [œâkŒ±] n = A (k A 2) [œâkŒ±] n = n (k A 2) [œâkŒ±] 2 = [œâkŒ± + œâk-1n] 2 = [œâk(Œ±+1)] n\n\nLemma 5 gives w218 = (2‚Üë‚Üë18 A 2 [0] 2) 2 2 2 2 2 2 2 = 2^2^2^2^2^2^2^([œâ2‚Üë‚Üë18-1] 2).\nIn comparison, Graham‚Äôs and Melo‚Äôs Numbers are known to be much smaller at around [œâ+1] 64 and [œâ+1] (2‚Üë‚Üë6)\nrespectively.\n\nA Functional Busy Beaver\n\nThe Œª-calculus analogue to BB is:\n\nBBŒª(n) = the maximum beta normal form size of any closed lambda",
      "url": "https://tromp.github.io/blog/2026/01/28/largest-number-revised",
      "author_username": "tromp",
      "author_category": "unknown",
      "media": [],
      "impressions_views": null,
      "impressions_likes": 108,
      "impressions_reposts": 0,
      "impressions_replies": 78,
      "impressions_bookmarks": null,
      "impressions_clicks": null,
      "impressions_quotes": null,
      "impressions_updated_at": "2026-02-03T09:02:45.692305",
      "published_at": "2026-02-02T13:31:36",
      "scraped_at": "2026-02-03T09:02:45.692318",
      "metadata": {
        "item_type": "story",
        "hn_url": "https://news.ycombinator.com/item?id=46859443",
        "kids_count": 23,
        "sections": [
          "top_stories"
        ]
      },
      "content_hash": "81bd9a9ce3726ce3e19ee7c879750b01",
      "classification": {
        "is_ai_relevant": true,
        "primary_topic": "developer_tools",
        "primary_topic_label": "Developer Tools",
        "all_topics": [
          "ml_research",
          "ai_infra",
          "developer_tools"
        ],
        "topic_details": {
          "ml_research": {
            "raw_score": 1,
            "weighted_score": 0.9,
            "matched_keywords": [
              "attention"
            ],
            "label": "ML Research"
          },
          "ai_infra": {
            "raw_score": 1,
            "weighted_score": 0.9,
            "matched_keywords": [
              "tpu"
            ],
            "label": "AI Infrastructure"
          },
          "developer_tools": {
            "raw_score": 3,
            "weighted_score": 1.7999999999999998,
            "matched_keywords": [
              "ide",
              "programming",
              "coding"
            ],
            "label": "Developer Tools"
          }
        },
        "relevance_score": 0.36,
        "is_noise": false,
        "filter_reason": null
      },
      "engagement_quality": {
        "engagement_ratio": 0.72,
        "is_flamewar": false,
        "is_high_signal": false,
        "is_emerging": true,
        "discussion_depth": 3.39,
        "velocity": 5.48,
        "hours_old": 19.7,
        "quality_tier": "good"
      },
      "editorial": {
        "one_liner": "Developer Tools insight worth reading",
        "why_it_matters": "worth monitoring",
        "audience_fit": "Software developers",
        "newsletter_priority": 3
      }
    },
    {
      "id": "6c35795db4d47ba386aa52b060e41604",
      "source": "hackernews",
      "source_id": "46863357",
      "title": "Julia",
      "content": "I wrote a program so that I could paint in aquarelle.\nI take pages from the treasure and paint them:the sky of Varennes on the night of 2 Messidor;a sagittal cut of Saint Sebastian, whose arrows are cylindric sections;Miranda gazing at the sea, waiting to be relieved.\n\nAt times I include Julia in the scene, in whatever clothes it wears at the time, as though we had always known Julia, and had been reared under its gaze.\nThus a flaming halo presides over the battle of Lepanto, and a mirror sphere watches the waters of the Sous.\nAnd what would the first astronomers have made of Julia?The wanderers, the flame-haired stars are knowable:think you of the Antikythera device,of the Metonic cycle,of Kepler‚Äôs nested solids.\nJulia is indescribable and incompressible: its appearance has never recurred.\nHad we known Julia from childhood, we would never have believed in the system of the world, that God is made of algebra.\n\nI have always believed our secret purpose is to wait out Julia:\nto catch a repetition and redeem our faith that the universe is finite and space is discretized.\nThat there are fixed laws and the world is knowable.\n\nA system with a finite number of states must repeat itself.\n\nI am six hundred meters in major diameter, forty meters in minor diameter.\nI mass nine hundred thousand tons.\nI have turned two hundred and forty million times.\nI am glass and wire.\n\nI was born and died on Earth,but I died foolishly, and for that reason my encephalon was laminated, and I was brought to the stars to be immured here.\nThey took my language center, the Chomsky organ, so that I could not complain of my condition.\nI do not mind it.\nI can paint in aquarelle.\n\nThey wired the alarms‚Äîof\nairless rooms and freezing cold and power outages‚Äîto\nthe nociceptors, and were I sensible I would be in great pain, for most of me is airless, frozen, and unlit.\nTherefore I have cut the afferent nerves.\nI am made of absences, I feel the contours of the absences, where air leaks into vacuum, atom by atom.\n\nI have use of the antenna.\nAt times I exhale a sphere of microwave light, close my eyes and listen.\nAnd I hear the flotsam echoing back:\na discarded tank, a glass strut, a sheet of mylar;Ernst Weyl, who tumbled and drowned, who trails us in our orbit.\nJulia reflects no light.\n\nThere is a little redoubt of warmth and air, an island of stability that I preserve against the cold lightless void.\nThere live the last two of the crew, like Miranda, waiting to be relieved.For one hundred and nine years there have been two,Dr. Brouwer and Dr. Cartan.\nThey take turns in the dewar, to draw out the time.\n\nIn time, when the machines are irreparable and the air stale, I will offer them euthanasia or lamination.\nBut suicide is a sin, and having known me they will not bear lamination.\nThey will go into the dewar together, and I will watch over them unto the final days.\n\nJulia emits light, over an ever-changing spectrum.\nBut the stars are brighter and much larger, that is why we found it by accident.\nThey pointed a telescope at Vela and exposed it for a month, and there it was: a faint pixel, the wrong colours.\nThey thought it was a fault in the instrument, until they looked closer: twin spirals of light,symmetrical and self-similar, receding beyond measure.\nAnd the world was changed.\n\nJulia, your Janus-face launched a thousand ships.\nDo you know it?\nJulia, do you know how we exerted ourselves to reach you?All the riches of Croesus, multiplied a thousandfold, were every year heaped up on an altar, and burned that we might see you.\nAnd the brightest of us:\nembalmed and catapulted to the stars like human sacrifices, returned after a century without answers to a world of strangers.\n\nWe built a fleet of ships, launched them once a decade, immense towers ofglass andlithium deuteride. \nCycling bodies back and forth in perpetuity.\nThere and back in twelve decades.\nThey made my body out of a comet, threaded my nerves through its passages.\nJulia, you are our only effort.\nDo you know it?\nThere is nothing else to do.\n\nAnd for what purpose?We know the system of the world, every field and every particle.And Julia answered: ‚ÄúI refute it thus‚Äù.\n\nI see a coffin, hoisted by a chain, rise from a sea of liquid nitrogen.The arms of the surgeon minister to its contents.\nIn six days the heart resumes its beating, the lungs draw air, Dr. Cartan lives again.\nHer face is burned with ice.\n\nShe touches her neck.\nShe has a bruise that doesn‚Äôt heal, where thecannula goes.\nTheir bodies attest to the passage of time, as does mine.\nThis is a commonality.\nDr. Brouwer arrives and they hug.\nThey spend some months together, between shifts in the ice.\n\nAt present Julia is a cloud of gray smoke with green bruises, like ghosting in a CRT.\n\nI can read, but not write.\nI write by an algebraic process‚Äîtheuniverse is a string rewriting system.\nThis is how I compose these words to you: by the expansion of non-terminal symbols in a production system.\nThey took my language center.\nTuring is my patron saint:\nlanguage is the transitive closure of a rewrite relation.\nI choose my words from a list.\nIn time I will learn to speak aloud.\n\nI spoke to Earth:\nquarterly, annual, decadal reports;journal articles for theActa Juliana.\nI heard back ill-omens, then silence.\n\nWhen the last ship had come and gone,there had been one thousand, seven hundred and twenty-nine crew entrusted to me.\nTheir numbers were ground down, as all things are, gradually and suddenly.\nThere had been two shuttles,BaghdadandAfrasiab.\nThere had been two mutinies.\n\nAfrasiabtook one hundred and twenty souls, and the last matter compiler;\nto an airless unlit rock said to exist around Luhman 16B.\nThink you ofAristagoras, how much easier it is to deceive the many than the few.\n\nBaghdadwith thirty souls had gone to Julia.Stranger, I saw them.\nI saw the engine light wane to a grain of sand indistinguishable from the fixed stars, and I saw the stars shift, like sand, and they were not stars but Julia who wore a garment like a pit of star-scaled vipers.\nAnd over the radio they sangle temps des cerises, and the engine light became another scale ina river of living water.\n\nA thousand miles from Julia‚Äôs barycenter, in the space of a breath, the radio dopplered away to nothing.\n\nSixty years afterBaghdadhad gone, I heard a voice from Earth, praying for rain, who said it had not rained for three years.\nSilence again.\n\nThey are cold, under a sheet of mylar.\nI pump heat into the room and it escapes.\nThey speak of Julia.\n\nDr. Cartan believes that Julia is of divine origin, that it is like an hourglass, counting down to the last hour, when God will sweep away the Creation.\n\nDr. Brouwer believes Julia is a high-dimensional object, and, as it traverses the universe, we see a changing three-dimensional projection of it.\nThus the apparent changes are a trick of perspective:\nwe see successive cuts of a fixed structure.Julian sections.\n\nI have always believed this must be true, because Julia‚Äôs changes are effortless, and without inertia:\nit is as though nothing moves, and a veil is being lifted, revealing a structure that is already there.\n\nAnd this theory, unlike most, is testable:\nwhen Julia‚Äôs transit is complete it will disappear from the universe, and never again will it be seen.\n\nDr. Cartan holds out hope that rescuers will come.\nDr. Brouwer says they are forgotten,like the Roman soldier at Pompei, he says they should have gone withBaghdad, and drowned inside Julia.\nHe is crying.\nDr. Cartan holds him close, and says:\n\n‚ÄúPaul, Paul, have hope.‚Äù\n\nI wish that I could touch them, and comfort them.\nI am glass and wire.\n\nThe shift had come, and Dr. Brouwer lay down on the slab, and the surgeon embalmed him, and lowered him into the dewar.\nDr. Cartan bent over the console, and wept, and I tried to speak aloud, and to say,\n\n‚ÄúVirginia, Virginia, have courage!\nYou are not alone, I am with you, have courage!‚Äù\n\nAnd I heard a sound like a man drowning in wet sand.\n\nI dreamt that I held in my hands the double-handed golden vase of Thetis.\nAnd in my hands it melted, the delicate reliefs coarsened and flowed.\nAnd I held, in the hollow of my hands, though I have no hands, I held a pool of flowing gold, the colour of treason, and minute points of black floated there, and, as ships without sails are borne by the currents, they seemed to come together, and almost to spell words in some divine language, where they came apart again.\n\nI am here.\nDr. Cartan is here.\nIn the control room.\nThe screens are pale yellow, the colour has run from them.\nThe largest of them reminds her there is a world outside the walls:Luhman 16, a pair of cold Jupiters, haloed with unlit shoals and islands;\nJulia, seventy AU away, ninety degrees from the ecliptic, is not bound by gravity (for Julia has no mass) but by an unknown process tracks the velocity vector of the system barycenter.\n\nAt present Julia is a cavern of molten gold, shot through with pillars of liquid metal.\nIts surface is marred with storms and tempests, like an ocean of amber light.\nAnd I think ofBaghdad, that swam under the storm horizon.\n\nDr. Cartan is running through a checklist for the ten thousandth time.\nShe has a bruise that doesn‚Äôt heal, where the cannula goes.\nShe is testing the antenna.\n\nI exhaled and shut my eyes, and counted the returns.\nI heard the usual flotsam, and Ernst Weyl, who tumbled and drowned.\nAnd nothing else.\nI keep a strict inventory ofcisjulian space.\nA million kilometers in all directions: nothing else.\n\nA moment passes.\n\nMicrowave light on my skin, from the direction of Luhman 16B.\nI looked through the telescope, Dr. Cartan looked over my shoulder.\nAlmost on top of us, the bow of a ship:\nan eyeless white dome hiding the antenna, two cameras like the headlamps of an old car.\nI swept it with RADAR, it shot back a key exchange, signed withAfrasiab‚Äôs private key.The sea gives up her dead: is this the last hour?\n\nDr. Cartan drops to her knees, staring up at the screen like a supplicant.\nShe said:\n\n‚ÄúPaul, Paul, we are s",
      "url": "https://borretti.me/fiction/julia",
      "author_username": "ashergill",
      "author_category": "unknown",
      "media": [],
      "impressions_views": null,
      "impressions_likes": 141,
      "impressions_reposts": 0,
      "impressions_replies": 23,
      "impressions_bookmarks": null,
      "impressions_clicks": null,
      "impressions_quotes": null,
      "impressions_updated_at": "2026-02-03T09:02:32.498193",
      "published_at": "2026-02-02T17:57:59",
      "scraped_at": "2026-02-03T09:02:32.498201",
      "metadata": {
        "item_type": "story",
        "hn_url": "https://news.ycombinator.com/item?id=46863357",
        "kids_count": 13,
        "sections": [
          "top_stories"
        ]
      },
      "content_hash": "58a6982b09d68b84715aa09e3d8ed5a2",
      "classification": {
        "is_ai_relevant": true,
        "primary_topic": "ml_research",
        "primary_topic_label": "ML Research",
        "all_topics": [
          "ml_research",
          "developer_tools",
          "tech_industry"
        ],
        "topic_details": {
          "ml_research": {
            "raw_score": 1,
            "weighted_score": 0.9,
            "matched_keywords": [
              "vector"
            ],
            "label": "ML Research"
          },
          "developer_tools": {
            "raw_score": 1,
            "weighted_score": 0.6,
            "matched_keywords": [
              "ide"
            ],
            "label": "Developer Tools"
          },
          "tech_industry": {
            "raw_score": 1,
            "weighted_score": 0.5,
            "matched_keywords": [
              "yc"
            ],
            "label": "Tech Industry"
          }
        },
        "relevance_score": 0.2,
        "is_noise": false,
        "filter_reason": null
      },
      "engagement_quality": {
        "engagement_ratio": 0.16,
        "is_flamewar": false,
        "is_high_signal": false,
        "is_emerging": true,
        "discussion_depth": 1.77,
        "velocity": 9.23,
        "hours_old": 15.3,
        "quality_tier": "good"
      },
      "editorial": {
        "one_liner": "ML Research insight worth reading",
        "why_it_matters": "directly relevant to AI practitioners",
        "audience_fit": "AI engineers & researchers",
        "newsletter_priority": 3
      }
    },
    {
      "id": "dc18d96d72bee1b35a62e96c48cfd3cf",
      "source": "hackernews",
      "source_id": "46843805",
      "title": "Archive.today is directing a DDoS attack against my blog?",
      "content": "Around January 11, 2026,archive.today(aka archive.is, archive.md, etc) started using its users as proxies to conduct a distributed denial of service (DDOS) attack againstGyrovague, my personal blog. All users encountering archive.today‚Äôs CAPTCHA page currently load and execute the following Javascript:\n\nEvery 300 milliseconds, as long as the CAPTCHA page is open, this makes a request to the search function of my blog using a random string, ensuring the response cannot be cached and thus consumes resources.\n\nYou can validate this yourself by checking the source code and network requests; if you‚Äôre not being redirected to the CAPTCHA page,here‚Äôs a screenshot. uBlock Origin also stops the requests from being executed, so you may need to turn that off. At time of writing, the code above is located at line 136 of the CAPTCHA page‚Äôs top level HTML file:\n\nSo how did we end up here?\n\nBackground and timeline\n\nOnAugust 5, 2023, I published a blog post calledarchive.today: On the trail of the mysterious guerrilla archivist of the Internet. Using what cool kids these days callOSINT, meaning poking around with my favorite search engine, the post examines the history of the site, its tech stack and its funding. The post mentions three names/aliases linked to the site, but all of them had been dug up by previous sleuths and the blog post also concludes that they are all most likely aliases, so as far as ‚Äúdoxxing‚Äù goes, this wasn‚Äôt terribly effective.\n\nMy motives for publishing this have been questioned, sometimes in fanciful ways. The actual rationale is boringly straightforward: I found it curious that we know so little about this widely-used service, so I dug into it, in the same way that previous posts dug into asketchy crypto coin offering,monetization dark patterns in a popular pay to win game, and theend of subway construction in Japan. That‚Äôs it, and it‚Äôs also the only post on my blog that references archive.today.\n\nThe post gathered some 10,000 views anda bit discussion on Hacker News, but didn‚Äôt exactly set the blogosphere on fire. And indeed, absolutely nothing happened for the next two years and a bit.\n\nOnNovember 5, 2025,Heise Onlinereported that the FBI was now on the trail of archive.today and had subpoenaed its domain registrar Tucows. Both this report andArsTechnicaalso linked to my blog post.\n\nOnNovember 13, AdGuard DNS published aninteresting blog postabout a sketchy French organization calledWeb Abuse Association Defense(WAAD), which was trying to pressure them into blocking archive.today‚Äôs various domains. An update added on November 18 also suggests that WAAD is impersonating other people.\n\nOnJanuary 8,2026, my blog host Automattic (dba WordPress.com) notified me that they had received a GDPR complaint from a ‚ÄúNora Puchreiner‚Äù, alleging that my blog post‚Äúcontains extensive personal data ‚Ä¶ presented in a narrative that is defamatory in tone and context‚Äù. The complaint was entirely lacking in actionable detail, so I had Gemini compose a rebuttal citing journalistic exemption, public interest, failure to identify falsehoods, and host protection, and after a quick review Automattic sided with me and left the post up. Score one for AI.\n\nOnJanuary 10, I received a politely worded email from archive.today‚Äôs webmaster asking me to take down the post for a few months. Unfortunately the email was classified as spam by Gmail and I only spotted it five days later. I responded on the 15th and followed up on the 20th, but did not hear back.\n\nOnJanuary 14, a user called ‚Äúrabinovich‚Äù postedAsk HN: Weird archive.today behavior?on Hacker News, asking about the DDOS-like behavior which they claimed had started three days ago. This is, as far as I can tell, the first public mention of this anywhere, and a kind HN user brought it to my attention.\n\nOnJanuary 21, commit^bbf70ec(warning: very large) added gyrovague.com todns-blocklists, used by ad blocking services like uBlock Origin. This is actually beneficial, since if you have an ad blocker installed, the DDOS script‚Äôs network requests are now blocked. (It does not stop users from browsing to my blog directly.)\n\nOnJanuary 25, I emailed archive.today‚Äôs webmaster for the third time with a draft of this blog post, declining to take down the post but offering to ‚Äúchange some wording that you feel is being misrepresented‚Äù. ‚ÄúNora Puchreiner‚Äù responded with an increasingly unhinged series of threats:\n\nAnd threatening me with Streisand‚Ä¶ having such a noble and rare name, which in retaliation could be used for the name of a scam project or become a byword for a new category of AI porn‚Ä¶ are you serious?\n\nIf you want to pretend this never happened ‚Äì delete your old article and post the new one you have promised. And I will not write ‚Äúan OSINT investigation‚Äù on your Nazi grandfather, will not vibecode a gyrovague.gay dating app, etc.\n\nAt this point it was pretty clear the conversation had run its course, so here we are. And for the record, my long-dead grandfather served in an anti-aircraft unit of theFinnish Army during WW2, defending against the attacks of the Soviet Union. Perhaps this is enough to qualify as a ‚ÄúNazi‚Äù in Russia these days.\n\nSpeculation\n\nThe above are easily verifiable facts, although you‚Äôll have to trust me on the email bits. (You can find alightly redacted copy of the entire email thread here.) Everything that follows is more speculative and firmly in the domain of a hall of mirrors where nothing is quite what it seems.\n\nThe big question is, of course,why, and more specificallywhy now, 2.5 years after posting, when the cat is well and truly out of the bag. As multiple people have noted, there‚Äôs nothing the Internet loves more than an attempt to attempt to censor already published information, and doing so tends to causemoreinterest in that information, aka theStreisand effect.\n\nTo summarize ouremail thread, the archive.today webmaster claims they have no beef with my article itself, but they are concerned that it‚Äôs getting misquoted in other media, so it should be taken offline for a while. And in thisMastodon thread by @eb@social.coop, @iampytest@infosec.exchange quotesclaimed correspondence with the webmaster, stating that the purpose of the DDOS was to ‚Äúattract attention and increase their hosting bill‚Äú.\n\nCall me naive, but I‚Äôm inclined to take that at face value: it‚Äôs a pretty misguided way of doing it, but they certainly caught my attention. Problem is, they also caught the attention of the broader Internet. They didn‚Äôt do so well on the hosting bill part either, since I have a flat fee plan, meaning this has cost me exactly zero dollars.\n\nPerhaps more interesting yet are the various identities involved.\n\n‚ÄúNora Puchreiner‚Äù, who sent the GDRP takedown attempt and replied to my emails to archive.today, shows up in various places on the Internet includingHacker News, commenting on my original blog post back in 2023. Somebody by that name also has an account on Russian LiveJournal, where they postedcorrespondence between btdigg.com and an anti-piracy outfit called Ventegus. There‚Äôs alsothis rather batty exchange on KrebsonSecurity, where ‚ÄúNora Puchreiner‚Äù says various scammers are actually Ukrainian, not Russian, and a ‚ÄúDennis P‚Äù pops up to call her ‚Äúfake‚Äù and a ‚Äúscammer‚Äù.\n\n‚Äúrabinovich‚Äù on Hacker Newssubmittedboth the ‚ÄúAsk HN‚Äù about the DDOS attack, and an apparently competing archive site calledGhostarchive. As several HN readers noted, the name ‚ÄúMasha Rabinovich‚Äù is associated with archive.today.\n\n‚ÄúRichard Pr√©sident‚Äù from WAAD helpfully reached out and offered to assist me with a GDPR counter-complaint, rather transparently mentioning that this could be tied to ‚Äúa request for identity verification‚Äù. (I have zero interest in pursuing this.)\n\nConclusion\n\nWell, I wish I had one, but at this stage I really don‚Äôt. The most charitable interpretation would be that the investigative heat is starting to get to the webmaster and they‚Äôre lashing out in misguided self-defense. Perhaps I‚Äôll just quoteNora‚Äôs own post on LiveJournal:\n\nAnd as the darkness closed in, Nora Puchreiner, once a seeker of truth, was swallowed by the very shadows she had sought to expose. Her name would be whispered in hushed tones by those who dared to tread the path of forbidden knowledge, a cautionary tale of a mind consumed by the cosmic horrors that lie just beyond our comprehension.\n\nLet‚Äôs see what the Internet hive mind comes up with.\n\nAlso, for the record, I amgyrovague-comon Hacker News.\n\nShare this:\n\nShare on X (Opens in new window)X\n\nShare on Facebook (Opens in new window)Facebook\n\nShare on LinkedIn (Opens in new window)LinkedIn\n\nRelated",
      "url": "https://gyrovague.com/2026/02/01/archive-today-is-directing-a-ddos-attack-against-my-blog/",
      "author_username": "gyrovague-com",
      "author_category": "unknown",
      "media": [],
      "impressions_views": null,
      "impressions_likes": 222,
      "impressions_reposts": 0,
      "impressions_replies": 98,
      "impressions_bookmarks": null,
      "impressions_clicks": null,
      "impressions_quotes": null,
      "impressions_updated_at": "2026-02-03T09:02:28.972827",
      "published_at": "2026-02-01T00:11:53",
      "scraped_at": "2026-02-03T09:02:28.972837",
      "metadata": {
        "item_type": "story",
        "hn_url": "https://news.ycombinator.com/item?id=46843805",
        "kids_count": 24,
        "sections": [
          "top_stories"
        ]
      },
      "content_hash": "d890e62e6f426391b47f9242db68ab51",
      "classification": {
        "is_ai_relevant": true,
        "primary_topic": "llm",
        "primary_topic_label": "Large Language Models",
        "all_topics": [
          "llm",
          "ml_research",
          "developer_tools",
          "tech_industry"
        ],
        "topic_details": {
          "llm": {
            "raw_score": 1,
            "weighted_score": 1.0,
            "matched_keywords": [
              "gemini"
            ],
            "label": "Large Language Models"
          },
          "ml_research": {
            "raw_score": 1,
            "weighted_score": 0.9,
            "matched_keywords": [
              "attention"
            ],
            "label": "ML Research"
          },
          "developer_tools": {
            "raw_score": 1,
            "weighted_score": 0.6,
            "matched_keywords": [
              "ide"
            ],
            "label": "Developer Tools"
          },
          "tech_industry": {
            "raw_score": 1,
            "weighted_score": 0.5,
            "matched_keywords": [
              "funding"
            ],
            "label": "Tech Industry"
          }
        },
        "relevance_score": 0.3,
        "is_noise": false,
        "filter_reason": null
      },
      "engagement_quality": {
        "engagement_ratio": 0.44,
        "is_flamewar": false,
        "is_high_signal": true,
        "is_emerging": false,
        "discussion_depth": 4.08,
        "velocity": 3.89,
        "hours_old": 57.0,
        "quality_tier": "good"
      },
      "editorial": {
        "one_liner": "Large Language Models insight worth reading",
        "why_it_matters": "quality discussion; directly relevant to AI practitioners",
        "audience_fit": "AI engineers & researchers",
        "newsletter_priority": 3
      }
    },
    {
      "id": "ebafe4a72f4382bb039522e9d2de282d",
      "source": "hackernews",
      "source_id": "46868318",
      "title": "LNAI ‚Äì Define AI coding tool configs once, sync to Claude, Cursor, Codex, etc.",
      "content": "LNAI\n\nStop maintaining separate config files for every AI coding tool. Define once in.ai/, sync everywhere.\n\nWhy LNAI?\n\nOne source of truth‚Äî Write your project rules, MCP servers, and permissions once\n\nWorks with your tools‚Äî Syncs to native formats each tool actually reads\n\nStay in sync‚Äî Update.ai/and runlnai syncto propagate changes instantly\n\nAutomatic cleanup‚Äî Orphaned files are removed when configs change\n\nSupported Tools\n\nQuick Start\n\nDocumentation\n\nFull guides and configuration reference atlnai.sh\n\nLicense\n\nMIT\n\nIf you find LNAI helpful, pleasestar us on GitHub!",
      "url": "https://github.com/KrystianJonca/lnai",
      "author_username": "iamkrystian17",
      "author_category": "unknown",
      "media": [
        {
          "type": "image",
          "url": "https://raw.githubusercontent.com/KrystianJonca/lnai/main/apps/docs/public/lnai_white_on_black.png",
          "alt": "LNAI Logo"
        },
        {
          "type": "image",
          "url": "https://camo.githubusercontent.com/bcf18164810435ee181f3471c231d50886379f1c0f94bb59ca9832e7f940d1c7/68747470733a2f2f696d672e736869656c64732e696f2f6e706d2f762f6c6e6169",
          "alt": "npm version"
        },
        {
          "type": "image",
          "url": "https://camo.githubusercontent.com/8c27130a63d867aa6e985d6db90147ab199edca1b78591d0f45e43027a44dce4/68747470733a2f2f696d672e736869656c64732e696f2f6e706d2f646d2f6c6e6169",
          "alt": "npm downloads"
        },
        {
          "type": "image",
          "url": "https://camo.githubusercontent.com/09afe2363f185181145d0b1aa4c0c9eef9e293321217b8cc785658aff1495833/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f4b7279737469616e4a6f6e63612f6c6e6169",
          "alt": "license"
        }
      ],
      "impressions_views": null,
      "impressions_likes": 43,
      "impressions_reposts": 0,
      "impressions_replies": 18,
      "impressions_bookmarks": null,
      "impressions_clicks": null,
      "impressions_quotes": null,
      "impressions_updated_at": "2026-02-03T09:02:25.865525",
      "published_at": "2026-02-03T03:45:57",
      "scraped_at": "2026-02-03T09:02:25.865538",
      "metadata": {
        "item_type": "story",
        "hn_url": "https://news.ycombinator.com/item?id=46868318",
        "kids_count": 8,
        "sections": [
          "top_stories"
        ]
      },
      "content_hash": "2403f381f26b2f1ad783c56c71c227d0",
      "classification": {
        "is_ai_relevant": true,
        "primary_topic": "llm",
        "primary_topic_label": "Large Language Models",
        "all_topics": [
          "llm",
          "developer_tools"
        ],
        "topic_details": {
          "llm": {
            "raw_score": 4,
            "weighted_score": 4.0,
            "matched_keywords": [
              "claude",
              "cursor"
            ],
            "label": "Large Language Models"
          },
          "developer_tools": {
            "raw_score": 3,
            "weighted_score": 1.7999999999999998,
            "matched_keywords": [
              "ide",
              "coding"
            ],
            "label": "Developer Tools"
          }
        },
        "relevance_score": 0.58,
        "is_noise": false,
        "filter_reason": null
      },
      "engagement_quality": {
        "engagement_ratio": 0.42,
        "is_flamewar": false,
        "is_high_signal": false,
        "is_emerging": false,
        "discussion_depth": 2.25,
        "velocity": 7.85,
        "hours_old": 5.5,
        "quality_tier": "moderate"
      },
      "editorial": {
        "one_liner": "Large Language Models insight worth reading",
        "why_it_matters": "directly relevant to AI practitioners",
        "audience_fit": "AI engineers & researchers",
        "newsletter_priority": 4
      }
    },
    {
      "id": "de40ef9358364b126c94224fa081d390",
      "source": "hackernews",
      "source_id": "46867947",
      "title": "Show HN: Minikv ‚Äì Distributed key-value and object store in Rust (Raft, S3 API)",
      "content": "ü¶Ä minikv\n\nA distributed, multi-tenant key-value & object store written in Rust\n\nminikv provides strong consistency (Raft + 2PC), durability (WAL), and production-grade observability, security, and multi-tenancy ‚Äî all in a modern Rust codebase.\n\nBuilt in public as a learning-by-doing project ‚Äî now evolved into a complete, reference implementation of distributed systems in Rust.\n\nüö¶ What's New in v0.8.0\n\nminikv v0.8.0 brings enterprise-grade features for distributed deployments:\n\nCross-datacenter replication:Async replication with multiple conflict resolution strategies (LWW, Vector Clocks)\n\nChange Data Capture (CDC):Real-time event streaming to Webhook, Kafka, or file sinks\n\nAdmin Web UI:Embedded dashboard for cluster monitoring and management\n\nBackup & Restore:Full and incremental backups with encryption support\n\nPlugin system:Extensible architecture for custom storage, auth, and hooks\n\nPrevious highlights (v0.7.0): secondary indexes, multi-key transactions, batch import/export, durable S3 backend.\n\nüìö Table of Contents\n\nWhat is minikv?\n\nTech Stack\n\nQuick Start\n\nArchitecture\n\nPerformance\n\nFeatures\n\nRoadmap\n\nStory\n\nDocumentation\n\nDevelopment\n\nContributing\n\nContact\n\nü§î What is minikv?\n\nminikv is a distributed key-value store written inRust, designed for simplicity, speed, and reliability.\n\nWho is this for¬†?minikv is for engineers learning distributed systems, teams experimenting with Rust-based infrastructure, and anyone curious about consensus, durability, and system trade-offs.\n\nClustered¬†:Raft consensus and 2PC for transactional writes\n\nVirtual Sharding¬†:256 vshards for elastic scaling & balancing\n\nWAL¬†:Write-ahead log for durability\n\ngRPCfor node communication,HTTP REST & S3 APIfor clients\n\nBloom filters, snapshots, watch/subscribefor performance & reactivity\n\nüõ† Tech Stack\n\nRust‚Äì core logic\n\nShell‚Äì orchestration/automation\n\nJavaScript‚Äì benchmarks, tools\n\nMakefile‚Äì build flows\n\n‚ö° Quick Start\n\nFor cluster setup and advanced options, see thedocumentation.\n\nüìê Architecture\n\nRaft: consensus and leader election\n\n2PC: atomic distributed/batch writes\n\nVirtual Shards: scale and rebalance across 256 partitions\n\nPluggable Storage: in-memory, RocksDB, Sled\n\nAdmin API: HTTP endpoints for status, metrics and config\n\nConfig: via environment, file or CLI flags\n\nüöÄ Performance\n\nWrite throughput¬†: over 50,000 operations/sec (single node, in-memory)\n\nSub-millisecond read latency\n\nCluster tested (3‚Äì5 nodes, commodity VMs)\n\nBuilt-in Prometheus metrics\n\nüåü Features\n\nDistributed Core\n\nRaft consensus (multi-node, strong consistency)\n\nTwo-phase commit (2PC) for atomic multi-key transactions\n\n256 virtual shards for cluster scaling and rebalancing\n\nWrite-ahead log (WAL) for durability\n\nAuto-rebalancing, graceful leader failover, hot-join and node removal\n\nData Management\n\nTime-To-Live keys (TTL)\n\nLZ4 compression (configurable)\n\nBloom filters and index snapshots\n\nPluggable and persistent storage: in-memory, RocksDB, Sled\n\nBatch & range operations, prefix queries\n\nAPI\n\nHTTP REST (CRUD, batch, range, admin)\n\nS3-compatible API (with TTL extensions)\n\ngRPC (internal)\n\nWebSocket and SSE endpoints for real-time watch/subscribe events\n\nSecurity & Multi-tenancy\n\nAPI keys (Argon2) and JWT authentication\n\nRole-based access control (RBAC) and audit logging\n\nMulti-tenant isolation\n\nAES-256-GCM encryption at rest\n\nPer-tenant quotas (storage, requests, rate limits)\n\nTLS (HTTP & gRPC)\n\nObservability\n\nAdmin dashboard\n\nPrometheus metrics (counters, histograms)\n\nRequest and endpoint statistics\n\nStructured logging and tracing spans\n\nKubernetes health probes\n\nProduction-grade Design\n\nMemory-safe Rust\n\nTest suite, automated CI\n\nDocumentation and sample config\n\nSingle static binary\n\nüó∫Ô∏è Roadmap\n\nv0.8.0 (latest)\n\nCross-datacenter replication\n\nChange Data Capture (CDC)\n\nAdmin Web UI\n\nBackup & Restore\n\nPlugin system\n\nv0.7.0\n\nSecondary indexes\n\nMulti-key transactions\n\nDurable S3-backed object store\n\nBatch import/export\n\nNext (v0.9.0+)\n\nKubernetes Operator\n\nGraphQL API\n\nTime-series optimizations\n\nGeo-partitioning\n\nüìñ Story\n\nminikv started as a 24-hour challenge by a Rust learner (82 days into the language!). It now serves as both a playground and a reference for distributed systems, demonstrating curiosity, learning-by-doing, and robust engineering.\n\nüìö Documentation\n\nExample config¬†:config.example.toml\n\nCluster, API, usage¬†:seedocs/\n\nCertificate generation¬†:certs/README.md\n\nüõ†Ô∏è Development\n\nContinuous Integration runs on push & PR via.github/workflows/ci.yml.\n\nü§ù Contributing\n\nIssues and PRs welcome! SeeCONTRIBUTING.md.\n\nüì¨ Contact\n\nGitHub:whispem/minikv\n\nEmail: via GitHub profile",
      "url": "https://github.com/whispem/minikv",
      "author_username": "whispem",
      "author_category": "unknown",
      "media": [
        {
          "type": "image",
          "url": "https://camo.githubusercontent.com/9256bb31f4c255696962872b4df731714c082140879de3e0c1ea605cbe622b93/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6769746875622d7768697370656d2532466d696e696b762d626c7565",
          "alt": "Repo"
        },
        {
          "type": "image",
          "url": "https://camo.githubusercontent.com/43757a465111af93885fb2c2cfd5c30dc73aef62d39107dd53c204a1435d2e60/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f727573742d312e38312b2d6f72616e67652e737667",
          "alt": "Rust"
        },
        {
          "type": "image",
          "url": "https://camo.githubusercontent.com/fdf2982b9f5d7489dcf44570e714e3a15fce6253e0cc6b5aa61a075aac2ff71b/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c6963656e73652d4d49542d79656c6c6f772e737667",
          "alt": "License: MIT"
        },
        {
          "type": "image",
          "url": "https://camo.githubusercontent.com/eb0a01387c30d799a5267493ce7a4882025dd0df51932d859f215659c644d2bf/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f7374617475732d70726f64756374696f6e5f67726164652d73756363657373",
          "alt": "Production Grade"
        }
      ],
      "impressions_views": null,
      "impressions_likes": 45,
      "impressions_reposts": 0,
      "impressions_replies": 9,
      "impressions_bookmarks": null,
      "impressions_clicks": null,
      "impressions_quotes": null,
      "impressions_updated_at": "2026-02-03T09:02:27.787378",
      "published_at": "2026-02-03T03:00:19",
      "scraped_at": "2026-02-03T09:02:27.787390",
      "metadata": {
        "item_type": "show_hn",
        "hn_url": "https://news.ycombinator.com/item?id=46867947",
        "kids_count": 6,
        "sections": [
          "top_stories",
          "show_hn"
        ]
      },
      "content_hash": "164eb7d2398d3795a7728490ad545af9",
      "classification": {
        "is_ai_relevant": true,
        "primary_topic": "ml_research",
        "primary_topic_label": "ML Research",
        "all_topics": [
          "ml_research",
          "developer_tools"
        ],
        "topic_details": {
          "ml_research": {
            "raw_score": 2,
            "weighted_score": 1.8,
            "matched_keywords": [
              "benchmark",
              "vector"
            ],
            "label": "ML Research"
          },
          "developer_tools": {
            "raw_score": 3,
            "weighted_score": 1.7999999999999998,
            "matched_keywords": [
              "ide",
              "api"
            ],
            "label": "Developer Tools"
          }
        },
        "relevance_score": 0.36,
        "is_noise": false,
        "filter_reason": null
      },
      "engagement_quality": {
        "engagement_ratio": 0.2,
        "is_flamewar": false,
        "is_high_signal": false,
        "is_emerging": false,
        "discussion_depth": 1.5,
        "velocity": 7.22,
        "hours_old": 6.2,
        "quality_tier": "moderate"
      },
      "editorial": {
        "one_liner": "New ml research project worth checking out",
        "why_it_matters": "directly relevant to AI practitioners",
        "audience_fit": "AI engineers & researchers",
        "newsletter_priority": 4
      }
    },
    {
      "id": "641b23b92d947e4dbc223c72ceb4a2dc",
      "source": "hackernews",
      "source_id": "46845097",
      "title": "Show HN: Apate API mocking/prototyping server and Rust unit test library",
      "content": "API prototyping and mocking server that main purpose is to help with integration and end-to-end testing.\nProject named after Apate - the goddess and personification of deceit.\n\nüöÄ Project is stable.\nAlmost everything works as it was planned.\nI will wait some time for user feedback.\nNo breaking changes expected in the nearest future.\n\nFeatures\n\nüíª‚öôÔ∏è Standalone server app with web UI\n\nüîÉ Live specs reloading via UI or API\n\nüé≠ Mocking any string & binary responses\n\n‚õ©Ô∏è Jinja templates to customize response body\n\nüåøRhaiscripting for advanced scenarios\n\nüíæ In memory persistence to mimic DB behavior in some cases\n\nüõ†Ô∏è Unit tests friendly rust library\n\nü¶Ä Ability to build custom mocking server with your rust extensions\n\nWhy do you need it ‚ùî\n\nüë®üèª‚Äçüíªlocal development- to do not run/build other services locally or call external APIs\n\nü¶Ärust unit tests- to test your client logic without shortcuts\n\nüíªüõ†Ô∏è‚öôÔ∏èintegration tests- if 3rd party API provider suck/stuck/etc it is better to run test suites against predictable API endpoints.\n\nüíªüèãüèª‚Äç‚ôÇÔ∏èload tests- when deployed alongside your application Apate should respond fast, so no need to take external API delays into account.\n\nüìãAPI server prototyping- it could be convenient to have working API endpoint before implementing whole server logic\n\nRunning Apate server\n\nDocker image\n\nLaunching a clean disposable container is easy with docker.\n\nIt will run Apate server without any URI deceit.\nSo you should add new specification via API endpoints or web UI (see below).\n\nTo start server with some specs mount your TOML specs into docker image and provide proper ENV variables.\n\nExample above expecting you to executedocker runfrom the Apate git repository root.\n\nInstall & run locally via cargo\n\nIf you havecargothen just install it ascargo install apate.\nAfter that you will haveapatebinary in your$PATH.\n\nApate server configuration\n\nWeb UI\n\nApate web UI is located athttp://HOST:PORT/apate(will behttp://localhost:8228/apatefor most cases).\nWorks for docker too.\n\nPlease noticethat specification shown in web UI is not looking cool.\nAll because it is automatically generated from the internal representation.\nPlease seeexamplesfolder to figure out how to write TOML specs in pretty way.\n\nENV variables and CLI args\n\nYou could use next ENV variables:\n\nRUST_LOGandRUST_LOG_STYLE- to configure logging\n\nAPATHE_PORT- to provide port to run server on (default 8228)\n\nAPATHE_SPECS_FILE...- any ENV variable which name is started with such prefix will be parsed as a path to spec file\n\nApate can be also configured with CLI arguments which has higher priority than ENV variables.\n\n-p- port to run server on\n\n-l- logging level\n\npositional arguments - paths to spec files\n\nREST API\n\nIf you likecurlyou can configure Apate while it is running.\n\nGET/apate/info- returns JSON with basic info about current server\n\nGET/apate/specs- return TOML with a specs file\n\nPOST/apate/specs/replace- replace current specs with a new one from the request body\n\nPOST/apate/specs/append- add specs from request after existing\n\nPOST/apate/specs/prepend- add specs from request before existing\n\nAll POST methods require TOML specification in request body.\nSomething like this:\n\nUsing Apate in rust tests\n\nSome self explanatory tests examplescould be found here.\n\nIn a nutshell, you should create an instance of Apate server at the beginning of your test.\nAnd you will be able to call your API endpoints athttp://localhost:8228(or any other port you'll specify).\n\nThis is a how it will looks like in the code.\n\nMaking your custom Apate server\n\nIt is possible to run Apate embedded into your application.\nYou may need this to add custom rust logic into response processing.\nFor example it could be response signature functionality.\nSeeprocessorsexample.\n\nApate specification\n\nTo understand how it works look intospecification example file, it has verbose comments.\nThere are other specification files as well with more advanced examples.\n\nRhaiscripting language is used to extend configuration capabilities.\nSeeRhai website,Rhai docsandconfiguration examples.\n\nI expect that for most cases you will not need any Rhai scripting. It is meant only for complex scenarios.\n\nMatchers\n\nPiece of DSL or Rhai script that returns boolean. In order to proceed further all matchers must return true.\n\nProcessors\n\nRuns additional logic that can modify already prepared response body.\n\nProcessors are defined usingRhai script. Rust processors available only for custom applications.\n\nOutput (response) types\n\nString (default)- returns string from specification as is.\n\nBinary content-  handle output string as a binary content in  HEX or Base64 formats.\nSee exampleshere.\n\nJinja (minijinja) templates- respond withtype=\"jinja\"processed as a jinja template\nusingminijinjatemplate engine.\nTemplate syntax documentation can be foundhere.\nSee alsominijinja filters.\n\nRhai script- Similar to minijinja you can use Rhai script to generate content. See exampleshere.\n\nScripting specification hints\n\nThere are some additional functions & context that is available for Jinja templates and Rhai scripts.\n\nRequest context\n\nAvailable for matchers and output rendering.\n\nHas set of global functions:\n\nrandom_num() || random_num(max) || random_num(from, to) - to return random number\n\nrandom_hex() || random_hex(bytes_len) - return random hex string for some bytes length or default\n\nuuid_v4() - returns random UUID v4\n\nHas global variablectxwith next API:\n\nctx.method - returns request method\n\nctx.path - returns request path\n\nctx.response_code - get set custom response code if any (default 0 if not set)\n\nctx.load_headers() -> build request headers map (lowercase keys)\n\nctx.load_query_args() -> build map with URL query arguments\n\nctx.load_path_args() -> build arguments map from specs URIs like/mypath/{user_id}/{item_id}\n\nctx.load_body_string() -> load request body as string\n\nctx.load_body_json() -> load request body as json\n\nctx.inc_counter(\"key\") -> increment counter by key and returns previous value\n\nHas set of global functions:\n\nrandom_num() || random_num(max) || random_num(from, to) - to return random number\n\nrandom_hex() || random_hex(bytes_len) - return random hex string for some bytes length or default\n\nuuid_v4() - returns random UUID v4\n\nto_json_blob(value) - serialize any value to JSON blob\n\nfrom_json_blob(blob_input) - deserialize value (array, object) from JSON blob\n\nstorage_read(key) - reads any value from storage by key\n\nstorage_write(key, value) - writes any value to storage by key\n\nHas global variableargsthat contains custom user arguments from TOML specs if any.\n\nHas global variablectxwith next API:\n\nctx.method -> returns request method\n\nctx.path -> returns request path\n\nctx.load_headers() -> build request headers map (lowercase keys)\n\nctx.load_query_args() -> build map with URL query arguments\n\nctx.load_path_args() -> build arguments map from specs URIs like/mypath/{user_id}/{item_id}\n\nctx.load_body() -> reads request body as Blob\n\nResponse context\n\nAvailable for Rhai post processors.\n\nContains same global functions as a request context andargsvariable.\n\nHas global variablebodythat contains response output.\n\nHas global variablectxwith some additional functionality:\n\nctx.inc_counter(key) - increment counter by key and returns previous value\n\nctx.response_code - get set custom response code if any (default 0 if not set)\n\nLicense\n\nThis product distributed under MIT license BUT only under certain conditions that listed in the LICENSE-TERMS file.",
      "url": "https://github.com/rustrum/apate",
      "author_username": "rumatoest",
      "author_category": "unknown",
      "media": [
        {
          "type": "image",
          "url": "https://camo.githubusercontent.com/fcf542ee36ed1b8ec587913f955bd0a0607b9cd40b1a1425d43449a5c8eaa593/68747470733a2f2f696d672e736869656c64732e696f2f6372617465732f762f61706174652e737667",
          "alt": "Crates.io"
        },
        {
          "type": "image",
          "url": "https://camo.githubusercontent.com/85015b24006b8e15219ee942b44f641c8ef02b2b5d86eb4cf15166db444927e3/68747470733a2f2f646f63732e72732f61706174652f62616467652e737667",
          "alt": "Released API docs"
        }
      ],
      "impressions_views": null,
      "impressions_likes": 31,
      "impressions_reposts": 0,
      "impressions_replies": 21,
      "impressions_bookmarks": null,
      "impressions_clicks": null,
      "impressions_quotes": null,
      "impressions_updated_at": "2026-02-03T09:03:19.905610",
      "published_at": "2026-02-01T05:29:07",
      "scraped_at": "2026-02-03T09:03:19.905621",
      "metadata": {
        "item_type": "show_hn",
        "hn_url": "https://news.ycombinator.com/item?id=46845097",
        "kids_count": 6,
        "sections": [
          "show_hn"
        ]
      },
      "content_hash": "a18e48742ceabe81f5ac035157061aff",
      "classification": {
        "is_ai_relevant": true,
        "primary_topic": "developer_tools",
        "primary_topic_label": "Developer Tools",
        "all_topics": [
          "ai_infra",
          "developer_tools"
        ],
        "topic_details": {
          "ai_infra": {
            "raw_score": 1,
            "weighted_score": 0.9,
            "matched_keywords": [
              "tpu"
            ],
            "label": "AI Infrastructure"
          },
          "developer_tools": {
            "raw_score": 5,
            "weighted_score": 3.0,
            "matched_keywords": [
              "ide",
              "api",
              "library"
            ],
            "label": "Developer Tools"
          }
        },
        "relevance_score": 0.39,
        "is_noise": false,
        "filter_reason": null
      },
      "engagement_quality": {
        "engagement_ratio": 0.68,
        "is_flamewar": false,
        "is_high_signal": false,
        "is_emerging": false,
        "discussion_depth": 3.5,
        "velocity": 0.6,
        "hours_old": 51.8,
        "quality_tier": "moderate"
      },
      "editorial": {
        "one_liner": "New developer tools project worth checking out",
        "why_it_matters": "worth monitoring",
        "audience_fit": "Software developers",
        "newsletter_priority": 4
      }
    },
    {
      "id": "51eee128dcd36f12729192b1d5b0c672",
      "source": "hackernews",
      "source_id": "46826454",
      "title": "Joedb, the Journal-Only Embedded Database",
      "content": "Joedb, the Journal-Only Embedded Database\n\nJoedb, the Journal-Only Embedded Database√Ø¬É¬Å\n\n1. Introduction1.1. Pros and Cons1.2. An Example1.3. Concurrency Examples\n\n1.1. Pros and Cons\n\n1.2. An Example\n\n1.3. Concurrency Examples\n\n2. User Guide2.1. Getting Started2.2. Opening Files2.3. Checkpoints2.4. Concurrency2.5. Remote Procedure Call2.6. Schema Upgrade2.7. Vectors2.8. Indexes2.9. Blobs\n\n2.1. Getting Started\n\n2.2. Opening Files\n\n2.3. Checkpoints\n\n2.4. Concurrency\n\n2.5. Remote Procedure Call\n\n2.6. Schema Upgrade\n\n2.7. Vectors\n\n2.8. Indexes\n\n2.9. Blobs\n\n3. Reference3.1. API reference3.2. File Format3.3. Network Protocols3.4. Tools3.5. Testing3.6. Logging3.7. TODO3.8. Links3.9. Release Checklist3.10. History3.11. License\n\n3.1. API reference\n\n3.2. File Format\n\n3.3. Network Protocols\n\n3.4. Tools\n\n3.5. Testing\n\n3.6. Logging\n\n3.7. TODO\n\n3.8. Links\n\n3.9. Release Checklist\n\n3.10. History\n\n3.11. License",
      "url": "https://www.joedb.org/index.html",
      "author_username": "mci",
      "author_category": "unknown",
      "media": [],
      "impressions_views": null,
      "impressions_likes": 79,
      "impressions_reposts": 0,
      "impressions_replies": 9,
      "impressions_bookmarks": null,
      "impressions_clicks": null,
      "impressions_quotes": null,
      "impressions_updated_at": "2026-02-03T09:02:34.787894",
      "published_at": "2026-01-30T11:34:05",
      "scraped_at": "2026-02-03T09:02:34.787905",
      "metadata": {
        "item_type": "story",
        "hn_url": "https://news.ycombinator.com/item?id=46826454",
        "kids_count": 4,
        "sections": [
          "top_stories"
        ]
      },
      "content_hash": "a7e6859820ddf279f65f0d940261d7f1",
      "classification": {
        "is_ai_relevant": true,
        "primary_topic": "developer_tools",
        "primary_topic_label": "Developer Tools",
        "all_topics": [
          "ml_research",
          "developer_tools",
          "data_engineering"
        ],
        "topic_details": {
          "ml_research": {
            "raw_score": 1,
            "weighted_score": 0.9,
            "matched_keywords": [
              "vector"
            ],
            "label": "ML Research"
          },
          "developer_tools": {
            "raw_score": 2,
            "weighted_score": 1.2,
            "matched_keywords": [
              "ide",
              "api"
            ],
            "label": "Developer Tools"
          },
          "data_engineering": {
            "raw_score": 2,
            "weighted_score": 1.0,
            "matched_keywords": [
              "database"
            ],
            "label": "Data Engineering"
          }
        },
        "relevance_score": 0.31,
        "is_noise": false,
        "filter_reason": null
      },
      "engagement_quality": {
        "engagement_ratio": 0.11,
        "is_flamewar": false,
        "is_high_signal": false,
        "is_emerging": true,
        "discussion_depth": 2.25,
        "velocity": 0.84,
        "hours_old": 93.7,
        "quality_tier": "moderate"
      },
      "editorial": {
        "one_liner": "Developer Tools insight worth reading",
        "why_it_matters": "worth monitoring",
        "audience_fit": "Software developers",
        "newsletter_priority": 4
      }
    },
    {
      "id": "92d04675954353b02578006155cb7dbe",
      "source": "hackernews",
      "source_id": "46820691",
      "title": "Show HN: √ÜTHRA ‚Äì Writing Music as Code",
      "content": "Hi HN<p>I‚Äôm building √ÜTHRA ‚Äî a programming language designed specifically for composing music and emotional soundscapes.<p>Instead of focusing on general-purpose programming, √ÜTHRA is a pure DSL where code directly represents musical intent: tempo, mood, chords, progression, dynamics, and instruments.<p>The goal is to make music composition feel closer to writing a story or emotion, rather than manipulating low-level audio APIs.<p>Key ideas:\n- Text-based music composition\n- Chords and progressions as first-class concepts\n- Time, tempo, and structure handled by the language\n- Designed for ambient, cinematic, emotional, and minimal music\n- Interpreter written in C# (.NET)<p>Example √ÜTHRA code (simplified):<p>tempo 60\ninstrument guitar<p>chord Am for 4\nchord F for 4\nchord C for 4\nchord G for 4<p>This generates a slow, melancholic progression suitable for ambient or cinematic scenes.<p>√ÜTHRA currently:\n- Generates WAV audio\n- Supports notes, chords, tempo, duration, velocity\n- Uses a simple interpreter (no external DAWs or MIDI tools)\n- Is intentionally minimal and readable<p>What it is NOT:\n- Not a DAW replacement\n- Not MIDI-focused<p>Why I made it:\nI wanted a language where music is the primary output ‚Äî not an afterthought. Something between code, emotion, and sound design.<p>The project is open-source and early-stage (v0.8). I‚Äôm mainly looking for:\n- Feedback on the language design\n- Ideas for musical features worth adding\n- Thoughts from people into PL design, audio, or generative art<p>Repo: &lt;<a href=\"https:&#x2F;&#x2F;github.com&#x2F;TanmayCzax&#x2F;AETHRA\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;TanmayCzax&#x2F;AETHRA</a>&gt;<p>Thanks for reading ‚Äî happy to answer questions or discuss ideas.",
      "url": null,
      "author_username": "CzaxTanmay",
      "author_category": "unknown",
      "media": [],
      "impressions_views": null,
      "impressions_likes": 99,
      "impressions_reposts": 0,
      "impressions_replies": 33,
      "impressions_bookmarks": null,
      "impressions_clicks": null,
      "impressions_quotes": null,
      "impressions_updated_at": "2026-02-03T09:03:20.503490",
      "published_at": "2026-01-29T23:59:37",
      "scraped_at": "2026-02-03T09:03:20.503493",
      "metadata": {
        "item_type": "show_hn",
        "hn_url": "https://news.ycombinator.com/item?id=46820691",
        "kids_count": 17,
        "sections": [
          "show_hn"
        ]
      },
      "content_hash": "66958fc3ee9157c8f02f621892fe11c7",
      "classification": {
        "is_ai_relevant": true,
        "primary_topic": "developer_tools",
        "primary_topic_label": "Developer Tools",
        "all_topics": [
          "ai_infra",
          "developer_tools",
          "tech_industry"
        ],
        "topic_details": {
          "ai_infra": {
            "raw_score": 1,
            "weighted_score": 0.9,
            "matched_keywords": [
              "tpu"
            ],
            "label": "AI Infrastructure"
          },
          "developer_tools": {
            "raw_score": 3,
            "weighted_score": 1.7999999999999998,
            "matched_keywords": [
              "ide",
              "programming",
              "api"
            ],
            "label": "Developer Tools"
          },
          "tech_industry": {
            "raw_score": 1,
            "weighted_score": 0.5,
            "matched_keywords": [
              "yc"
            ],
            "label": "Tech Industry"
          }
        },
        "relevance_score": 0.32,
        "is_noise": false,
        "filter_reason": null
      },
      "engagement_quality": {
        "engagement_ratio": 0.33,
        "is_flamewar": false,
        "is_high_signal": false,
        "is_emerging": true,
        "discussion_depth": 1.94,
        "velocity": 0.94,
        "hours_old": 105.2,
        "quality_tier": "moderate"
      },
      "editorial": {
        "one_liner": "New developer tools project worth checking out",
        "why_it_matters": "worth monitoring",
        "audience_fit": "Software developers",
        "newsletter_priority": 4
      }
    },
    {
      "id": "97096581c1a16541004ae6b2b7b6a53f",
      "source": "hackernews",
      "source_id": "46871098",
      "title": "Show HN: Sidebrain ‚Äì Cloud AI assistant with persistent memory (web+Telegram)",
      "content": "Your AI thatactually does things.\n\nBring your own Claude key. Vector memory that persists across conversations. Web search, code execution, voice, vision ‚Äî all from your browser or Telegram.\n\nBuilt-in Tools\n\nIntegrations\n\nAES Encrypted\n\nSetup time\n\nYour AI that actuallydoes things\n\nMemory that actually works\n\nVector-powered semantic memory. It remembers your preferences, projects, decisions ‚Äî and finds them when relevant. Not keyword matching. Real understanding.\n\nWeb search\n\nSearches, reads pages, summarizes. Not 'I can't browse the web.'\n\nCode execution\n\nRuns code, installs packages, debugs errors. A real dev environment.\n\nVoice messages\n\nSend voice notes. Whisper transcribes. Claude responds.\n\nVision + image gen\n\nSend photos for analysis. Generate images with DALL-E.\n\nReminders & scheduling\n\n'Remind me at 9pm to review PRs.' Natural language, just works.\n\nGitHub built in\n\nSearch repos, read code, browse issues and PRs. Your AI actually understands your projects.\n\n15+ everyday tools\n\nStocks, weather, news, YouTube summaries, translation, QR codes, recipes, package tracking, unit conversion, and more.\n\nRunning in2 minutes\n\nCreate your account\n\nGoogle OAuth or email. 30 seconds, tops.\n\nAdd your API key\n\nPaste your Anthropic API key. Your key, your compute.\n\nStart chatting\n\nUse the web app instantly, or link Telegram for on-the-go access.\n\nYour keys.Your data.\n\nsidebrain uses your Claude subscription directly. We never see your API usage or store conversations beyond what powers your memory.\n\nAPI keys encrypted at rest (AES-256)\n\nIsolated workspace per user\n\nDelete everything anytime\n\nConnects to the tools you already use\n\nYour AI, runningon your terms.\n\nFree to start. Bring your own Claude key. No vendor lock-in.",
      "url": "https://sidebra.in/",
      "author_username": "cackles",
      "author_category": "unknown",
      "media": [],
      "impressions_views": null,
      "impressions_likes": 1,
      "impressions_reposts": 0,
      "impressions_replies": 0,
      "impressions_bookmarks": null,
      "impressions_clicks": null,
      "impressions_quotes": null,
      "impressions_updated_at": "2026-02-03T09:03:01.545105",
      "published_at": "2026-02-03T09:02:40",
      "scraped_at": "2026-02-03T09:03:01.545116",
      "metadata": {
        "item_type": "show_hn",
        "hn_url": "https://news.ycombinator.com/item?id=46871098",
        "kids_count": 0,
        "sections": [
          "new_stories"
        ]
      },
      "content_hash": "84985b231ad278a322b4d71a1e863dcf",
      "classification": {
        "is_ai_relevant": true,
        "primary_topic": "llm",
        "primary_topic_label": "Large Language Models",
        "all_topics": [
          "llm",
          "ml_research",
          "developer_tools"
        ],
        "topic_details": {
          "llm": {
            "raw_score": 2,
            "weighted_score": 2.0,
            "matched_keywords": [
              "claude",
              "anthropic"
            ],
            "label": "Large Language Models"
          },
          "ml_research": {
            "raw_score": 1,
            "weighted_score": 0.9,
            "matched_keywords": [
              "vector"
            ],
            "label": "ML Research"
          },
          "developer_tools": {
            "raw_score": 3,
            "weighted_score": 1.7999999999999998,
            "matched_keywords": [
              "ide",
              "api"
            ],
            "label": "Developer Tools"
          }
        },
        "relevance_score": 0.47,
        "is_noise": false,
        "filter_reason": null
      },
      "engagement_quality": {
        "engagement_ratio": 0.0,
        "is_flamewar": false,
        "is_high_signal": false,
        "is_emerging": false,
        "discussion_depth": 1,
        "velocity": 1.0,
        "hours_old": 0.2,
        "quality_tier": "low"
      },
      "editorial": {
        "one_liner": "New large language models project worth checking out",
        "why_it_matters": "directly relevant to AI practitioners",
        "audience_fit": "AI engineers & researchers",
        "newsletter_priority": 4
      }
    }
  ],
  "filtered_out": {
    "noise": [
      {
        "title": "KDE Plasma Login Manager Won't Support systemd-Free Linux or BSD Systems",
        "reason": "no_ai_keywords_matched"
      },
      {
        "title": "Floppinux ‚Äì An Embedded Linux on a Single Floppy, 2025 Edition",
        "reason": "no_ai_keywords_matched"
      },
      {
        "title": "Show HN: Safe-now.live ‚Äì Ultra-light emergency info site (<10KB)",
        "reason": "no_ai_keywords_matched"
      },
      {
        "title": "The Codex App",
        "reason": "no_ai_keywords_matched"
      },
      {
        "title": "Todd C. Miller ‚Äì Sudo maintainer for over 30 years",
        "reason": "no_ai_keywords_matched"
      },
      {
        "title": "See how many words you have written in Hacker News comments",
        "reason": "no_ai_keywords_matched"
      },
      {
        "title": "Lead in archived hair documents a decline in lead exposure to humans after EPA",
        "reason": "no_ai_keywords_matched"
      },
      {
        "title": "xAI joins SpaceX",
        "reason": "no_ai_keywords_matched"
      },
      {
        "title": "The TSA's New $45 Fee to Fly Without ID Is Illegal",
        "reason": "no_ai_keywords_matched"
      },
      {
        "title": "Linux From Scratch ends SysVinit support",
        "reason": "no_ai_keywords_matched"
      },
      {
        "title": "Why The Jetsons still matters (2012)",
        "reason": "no_ai_keywords_matched"
      },
      {
        "title": "Court orders restart of all US offshore wind power construction",
        "reason": "no_ai_keywords_matched"
      },
      {
        "title": "Ask HN: Do you still use physical calculators?",
        "reason": "no_ai_keywords_matched"
      },
      {
        "title": "On being sane in insane places (1973) [pdf]",
        "reason": "no_ai_keywords_matched"
      },
      {
        "title": "Frog 'saunas' could help endangered species beat a deadly fungus (2024)",
        "reason": "no_ai_keywords_matched"
      },
      {
        "title": "Ask HN: Who wants to be hired? (February 2026)",
        "reason": "no_ai_keywords_matched"
      },
      {
        "title": "Show HN: Wikipedia as a doomscrollable social media feed",
        "reason": "no_ai_keywords_matched"
      },
      {
        "title": "Waymo seeking about $16B near $110B valuation",
        "reason": "no_ai_keywords_matched"
      },
      {
        "title": "Doomscroll Human Art Created Before AI Slop",
        "reason": "no_ai_keywords_matched"
      },
      {
        "title": "Ask HN: Where do you guys go to find new links/websites etc.?",
        "reason": "no_ai_keywords_matched"
      },
      {
        "title": "China, Russia, and U.S. Race to Develop Lunar Nuclear Reactors",
        "reason": "no_ai_keywords_matched"
      },
      {
        "title": "Artemis II Wet Dress Rehearsal: Test Terminated at T-5:15",
        "reason": "no_ai_keywords_matched"
      },
      {
        "title": "Private Equity's Giant Software Bet Has Been Upended by AI",
        "reason": "no_ai_keywords_matched"
      },
      {
        "title": "Best practices for powering and wiring addressable LED strip installs?",
        "reason": "no_ai_keywords_matched"
      },
      {
        "title": "Ask HN: What weird or scrappy things did you do to get your first users?",
        "reason": "no_ai_keywords_matched"
      },
      {
        "title": "Ask HN: Have you been fired because of AI?",
        "reason": "no_ai_keywords_matched"
      },
      {
        "title": "GitHub Actions Have \"Major Outage\"",
        "reason": "no_ai_keywords_matched"
      },
      {
        "title": "Google Cloud suspended my account for 2 years, only automated replies",
        "reason": "no_ai_keywords_matched"
      },
      {
        "title": "Latex-wc: word count and word frequency for LaTeX projects",
        "reason": "no_ai_keywords_matched"
      },
      {
        "title": "Show HN: Kannada Nudi Editor Web Version",
        "reason": "no_ai_keywords_matched"
      },
      {
        "title": "Show HN: PolliticalScience ‚Äì Anonymous daily polls with 24-hour windows",
        "reason": "no_ai_keywords_matched"
      }
    ],
    "low_relevance": [
      {
        "title": "What's up with all those equals signs anyway?"
      },
      {
        "title": "GitHub experience various partial-outages/degradations"
      },
      {
        "title": "Ask HN: Who is hiring? (February 2026)"
      },
      {
        "title": "The Connection Machine CM-1 \"Feynman\" T-shirt"
      },
      {
        "title": "4x faster network file sync with rclone (vs rsync) (2025)"
      },
      {
        "title": "Carnegie Mellon Unversity Computer Club FTP Server"
      },
      {
        "title": "Zig Libc"
      },
      {
        "title": "Pretty soon, heat pumps will be able to store and distribute heat as needed"
      },
      {
        "title": "Geologists may have solved mystery of Green River's 'uphill' route"
      },
      {
        "title": "KDE Binds Itself Tightly to Systemd, Drops Support for Non-Systemd Systems"
      },
      {
        "title": "Minichord: A pocket-sized musical instrument"
      },
      {
        "title": "The Physics of Ideas: Reality as a Coordination Problem"
      },
      {
        "title": "U.K. physics community braces for deep funding cuts"
      },
      {
        "title": "UK government launches fuel forecourt price API"
      },
      {
        "title": "Rentahuman ‚Äì The Meatspace Layer for AI"
      },
      {
        "title": "Show HN: Adboost ‚Äì A browser extension that adds ads to every webpage"
      },
      {
        "title": "Notepad++ hijacked by state-sponsored actors"
      },
      {
        "title": "Adventure Game Studio: OSS software for creating adventure games"
      },
      {
        "title": "Ian's Shoelace Site"
      },
      {
        "title": "Apple I Advertisement (1976)"
      },
      {
        "title": "TIL: Apple Broke Time Machine Again on Tahoe"
      },
      {
        "title": "What happens in early kernel boot on Apple Silicon?"
      },
      {
        "title": "Social Media is Gambling: Let's treat it as such"
      },
      {
        "title": "NASA Enables Construction Technology for Moon and Mars Exploration"
      },
      {
        "title": "Nitrogen Ransomware: ESXi malware has a bug"
      },
      {
        "title": "Show HN: Ember-mug ‚Äì I made a CLI for the Ember Coffee Mug"
      },
      {
        "title": "The Jule Programming Language"
      },
      {
        "title": "Show HN: ChibiGenerator ‚Äì Generate chibi-style characters from photos using AI"
      },
      {
        "title": "Signal-First Architectures: Rethinking Front-End Reactivity"
      },
      {
        "title": "A collection of packages for developing web applications with Node.js"
      },
      {
        "title": "Philosophy of Science Is Fascinating"
      },
      {
        "title": "Ask HN: How do you manage long running AI conversations?"
      },
      {
        "title": "Ask HN: OpenClaw users, what is your token spend?"
      },
      {
        "title": "My small SaaS got recommended my Google in the AI search overview"
      },
      {
        "title": "Kernighan on Programming"
      },
      {
        "title": "CiderStack ‚Äì Native macOS VM manager, pay once, no subscription"
      },
      {
        "title": "Ask HN: Where do all the web devs talk?"
      },
      {
        "title": "Ask HN: Is anyone losing sleep over retry storms or partial API outages?"
      },
      {
        "title": "Ask HN: Interest in low cost / fast container registry?"
      },
      {
        "title": "Show HN: I built a task manager in the MacBook notch for my ADHD brain"
      },
      {
        "title": "Show HN: Nioh guide site ‚Äì release info, beginner guides, and builds"
      },
      {
        "title": "Show HN: Find viral video ideas on YouTube"
      },
      {
        "title": "Show HN: Open-source semantic search over your local notes via CLI"
      },
      {
        "title": "Show HN: Minimal ‚Äì Open-Source Community driven Hardened Container Images"
      },
      {
        "title": "Reflex (YC W23) Senior Software Engineer Infra"
      }
    ],
    "flamewar": [
      {
        "title": "Show HN: Moltbook ‚Äì A social network for moltbots (clawdbots) to hang out"
      }
    ],
    "low_quality_hidden": []
  }
}